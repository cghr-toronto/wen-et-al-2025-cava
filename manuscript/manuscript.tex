% Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
\documentclass[sn-vancouver,Numbered,referee]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{lstautogobble}%
\usepackage{makecell}%
%%%%

\lstset{
    texcl=true,
    basicstyle=\small\sf,
    commentstyle=\small\rm,
    mathescape=true,
    escapeinside={(*}{*)},
    breaklines=true,
    breakindent=0.5pt
}

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
%%\theoremstyle{thmstyleone}%
%%\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
%%\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

%%\theoremstyle{thmstyletwo}%
%%\newtheorem{example}{Example}%
%%\newtheorem{remark}{Remark}%

%%\theoremstyle{thmstylethree}%
%%\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Comparing Generative Pre-trained Transformer Models to Physicians for Assigning Causes of Death from Verbal Autopsy: A Case Study of 6939 Deaths in Sierra Leone from 2019-2022]{Comparing Generative Pre-trained Transformer Models to Physicians for Assigning Causes of Death from Verbal Autopsy: A Case Study of 6939 Deaths in Sierra Leone from 2019-2022}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Richard} \sur{Wen}}\email{richard.wen@utoronto.ca}

\author[1,2]{\fnm{Anteneh Tesfaye} \sur{Assalif}}\email{antenehta@gmail.com}

\author[1]{\fnm{Andy Sze-Heng} \sur{Lee}}\email{andylee@cs.toronto.edu}

\author[1]{\fnm{Rajeev} \sur{Kamadod}}\email{rajeevk@kentropy.com}

\author[1]{\fnm{Cheryl} \sur{Chin}}\email{cheryl.chin@unityhealth.to}

%\equalcont{These authors contributed equally to this work.}

\author[1]{\fnm{Asha} \sur{Behdinan}}\email{asha.behdinan@mail.utoronto.ca}

\author[1]{\fnm{Thomas Kai Sze} \sur{Ng}}\email{kaisze.ng@unityhealth.to}

\author[2]{\fnm{Rashid} \sur{Ansumana}}\email{rashidansumana@gmail.com}

\author[1]{\fnm{Patrick} \sur{Brown}}\email{patrick.brown@utoronto.ca}

\author[1]{\fnm{Prabhat} \sur{Jha}}\email{prabhat.jha@utoronto.ca}

\affil*[1]{\orgdiv{Centre for Global Health Research, St. Michael's Hospital}, \orgname{Unity Health Toronto and University of Toronto}, \orgaddress{\street{30 Bond St}, \city{Toronto}, \postcode{M5B 1W8}, \state{Ontario}, \country{Canada}}}

\affil[2]{\orgdiv{School of Community Health Sciences}, \orgname{Njala University}, \orgaddress{\city{Bo}, \country{Sierra Leone}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{\textbf{Background:} Verbal Autopsies (VAs) collect data on deaths and their causes outside of traditional hospital settings to provide more representative counts and Causes of Death (CODs) for reducing premature mortality. Current computer models for COD assignment in VAs perform similar to physicians at the population level, but poorly at the individual level, due to a focus on structured questionnaire data and neglecting free text from the open narratives. Recently, a Generative Pre-trained Transformer (GPT) model called ChatGPT-4 has demonstrated human-level performance on professional and academic exams using free text input. ChatGPT-4 shows promise in mimicking physician behavior for assigning CODs, but to the best of our knowledge, has yet to be tested for assigning CODs using open narratives from VAs.

\textbf{Methods:} 6939 records collected from VA in Sierra Leone from 2019 to 2022 were used to compare four computer models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, to physicians for assigning CODs at the population and individual level. Open narratives were used for Chat-3.5/GPT-4 input, while structured questionnaires were used for InterVA-5/InSilicoVA input. All COD assignments were grouped into general COD categories consisting of 19, 10, and 7 categories for the adult, child, and neonatal age groups. Cause Specific Mortality Fraction (CSMF) accuracy and Partial Corrected Concordance (PCCC) were used to compare models to physicians at the population and individual level respectively. Comparisons in CSMF and PCCC to physicians among models were evaluated for all records and by COD, age group, and age ranges.

\textbf{Results:} Based on PCCC, GPT-4 had the best performance overall (0.61), followed by GPT-3.5 (0.58), InSilicoVA (0.44), and InterVA-5 (0.43). GPT-4 also had the best performance for the adult (0.65), child (0.57), and neonatal (0.62) age groups, while performance decreased as adults aged (0.72-0.59) and increased as children and neonates aged (0.5-0.7). 7 of 19, 4 of 10, and 1 of 7 adult, child, and neonatal CODs respectively had models with $\geq$0.8 PCCC. For most CODs, GPT models had one of the highest performances with the exception of InSilicoVA for adult tuberculosis, child pneumonia and neonatal infections. At the population level, all models had CSMF accuracy between 0.7-0.79.

\textbf{Conclusion:} GPT and InSilicoVA models were comparable to physicians for some CODs, but require further evaluation on reliability and larger datasets.
}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Cause of Death, Physician Coding, Verbal Autopsy, GPT}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Background}\label{background}

In 2019, 41 million people die prematurely from noncommunicable diseases every year, accounting for 74\% of all deaths globally \citep{worldhealthorganizationNonCommunicableDiseases2019}. Most of these deaths are preventable, but require adequate resource allocation, guided by evidence, to implement effective interventions and policies that target populations at risk \citep{benzigerGlobalBurdenDisease2016}. Thus, reliable counts and diagnoses of deaths enable decision makers to identify populations at risk to save lives and reduce premature deaths worldwide \citep{lawnMillionNeonatalDeaths2010,lassiCommunityBasedIntervention2015,liuExcessMortalityPersons2017,ewigCommunityacquiredPneumoniaEmergency2011}. However, most low-income countries do not have data on deaths or have registered less than half of the deaths in their country, with an even fewer 8\% of these registered deaths having a Cause of Death (COD) recorded \citep{worldhealthorganizationSCOREHealthData2021}. To fill this gap in death registrations, an alternative method known as Verbal Autopsy (VA) is used to collect data on deaths and determine their likely causes at scale \citep{desavignyIntegratingCommunitybasedVerbal2017,thomasVerbalAutopsyHealth2018,rampatigeSystematicReviewStatistics2014}, outside of traditional healthcare facilities where over half of deaths occur at home \citep{adairWhoDiesWhere2021}.

VA involves two major components: survey and COD assignment \citep{worldhealthorganizationVerbalAutopsyStandards2023,chandramohanEstimatingCausesDeath2021,worldhealthorganizationVerbalAutopsyStandards2007}. In the survey component, trained lay surveyors interview those familiar with the deceased (e.g. living spouse, children, family, friends) to gather information using standardized questionnaires and open narratives. In the COD assignment component, physicians evaluate information available from the questionnaires and open narratives to assign probable CODs. This component has been criticized to be difficult to reproduce due to reliance on physician assignment \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005,mccormickProbabilisticCauseofDeathAssignment2016b,morrisFactorsAssociatedPhysician2010,solemanVerbalAutopsyCurrent2006}. As an alternative to physician assignment, computer models, such as InterVA \citep{byassIntegratedApproachProcessing2019} and InSilicoVA \citep{mccormickProbabilisticCauseofDeathAssignment2016b}, have been studied to automatically assign CODs with performances close to physicians at the population level, but poor performances at the individual level \citep{jhaAutomatedPhysicianAssignment2019,leitaoComparisonPhysiciancertifiedVerbal2014,desaiPerformanceFourComputercoded2014,tungaVerbalAutopsyModels2021,otiVerbalAutopsyInterpretation2010}. These computer models often utilize data from the structured questionnaire, but often omit the free-text open narrative, which misses latent information, such as chronology or health-seeking behaviors, that may potentially help models perform better than using the questionnaire alone \citep{jebleeAutomaticallyDeterminingCause2019,blancoExtractingCauseDeath2021,kingQualityDiagnosticValue2016}.

Recently, Large Language Models (LLM), leveraging massive datasets and deep learning approaches, have made advances in performing a variety of Natural Language Processing (NLP) tasks using free-text, such as question answering, code generation, and even medical diagnosis \citep{changSurveyEvaluationLarge2023,lundChattingChatGPTHow2023,svyatkovskiyIntelliCodeComposeCode2020,hauptAIGeneratedMedicalAdvice2023}. In 2022, a widely-available LLM called ChatGPT was released by OpenAI with capabilities of answering natural language text inquiries using training data up to September 2021. ChatGPT-3 was based on several Generative Pre-trained Transformer (GPT) models between 2018 to 2020, namely GPT-1 to GPT-3, which had notable differences in training data sizes of 5 gigabytes to 45 terabytes from web sources that resulted in 117 million to 175 billion parameter models \citep{wuBriefOverviewChatGPT2023}. In March 2023, ChatGPT-4 was released with human-level performance on various professional and academic exams and benchmarks that outperformed ChatGPT-3 \citep{openaiGPT4TechnicalReport2023}. Given the limited usage of free-text open narratives in computer models for determining CODs, and recent advances in LLMs that leverage natural language text prompts, we conduct a case study with Sierra Leone deaths from VA in 2019 to 2022 to compare four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, to physicians for determining CODs.

\section{Methods}\label{methods}

This study uses 6939 physician agreed records (two physicians with similar COD assignment on the same record) of 11,920 records collected in 2019 to 2022 from the Healthy Sierra Leone (HEAL-SL) study as described in Section \ref{methods-data}. Section \ref{methods-models} describes the four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, for COD assignment, and their inputs and outputs, while section \ref{methods-eval} details the performance evaluation of the four models relative to physicians overall, by ages, and by COD, using population and individual level metrics. See Appendix \ref{app-methods} for details on the methods used in this study.

\subsection{Verbal Autopsy (VA) Data}\label{methods-data}

Initially, 11,920 records from the HEAL-SL study \citep{njalauniversityHealthySierraLeone2023,carshon-marshChildMaternalAdult2022} were collected from dual-coded EVA, where each record was randomly coded by two different physicians that assigned CODs as International Classification of Diseases Revision 10 (ICD-10) codes \citep{worldhealthorganizationICD10InternationalStatistical2011}. Physicians were able to assign CODs for 11,820 of the 11,920 records, where 100 of these records could not be assigned a COD due to missing or inadequate information (e.g. low quality narrative, data loss). To determine if two codes were in physician agreement per record, codes were compared for similarity using Central Medical Evaluation Agreement 10 (CMEA-10) codes, which groups a range of similar ICD-10 codes together indicating codes in agreement \citep{aleksandrowiczPerformanceCriteriaVerbal2014} (see Additional File 2). When codes were not in agreement, a record enters the reconciliation phase, where the two physicians were provided reasoning and initial codes from each other to: (1) keep their initial code (2) assign the other physician's code or (3) assign a new code. If codes were not in agreement after the reconciliation phase, a record enters the adjudication phase, where a third senior physician evaluates both physicians' reasoning and codes before and after reconciliation, and assigns a final code based on their evaluation.

The 11,820 physician coded records were further filtered for records where both physicians agreed on the assigned codes (records that were not reconciled or adjudicated) resulting in 6942 physician agreed records. Since computer models were compared to physicians in this study, there was more certainty that COD assignments agreed by both physicians were representative of physician assignment than when they disagreed \citep{barnettComparativeAccuracyDiagnosis2019,morrisFactorsAssociatedPhysician2010,hsiaoFactorsAssociatedPhysician2012}. The 6942 records were converted into CGHR-10 codes (see Additional File 1) that generalized ICD-10 codes into 19, 10, and 7 categories for the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups.  After conversion, a final total of 6939 physician agreed records (3826 adult, 2636 child, and 477 neonatal) were used for modelling and performance evaluation, where three records were removed as their ICD-10 codes did not have a matching CGHR-10 code. The 6939 physician agreed records were evenly distributed in terms of sex and age, except for children aged 1-5 years (n=1633, 24\%), while Malaria (n=799, 21\%) was the COD for about a fifth of the records. See Appendix \ref{app-data} for further details on data distributions across age groups.

\subsection{Modelling}\label{methods-models}

Four computer models were used to assign COD for each of the 6939 physician agreed records: GPT-3.5, GPT-4, InterVA-5, and InSilicoVA. Each model required pre-processing of the 6939 records into input data, and standardization of output COD codes from models for performance evaluation as not all models produced comparable codes across outputs. Although each model can assign multiple CODs per record, only the first generated COD response from GPT-3.5 and GPT-4, and the most probable COD from InterVA-5 and InSilicoVA were used for evaluation. All model outputs were converted to CGHR-10 codes to evaluate performances of models for COD assignment relative to physicians.

\subsubsection{Overview of GPT-3.5/4, InterVA-5, and InSilicoVA}\label{methods-models-overview}

GPT-3.5 \citep{brownLanguageModelsAre2020} and GPT-4 \citep{openaiGPT4TechnicalReport2023} are LLMs that utilize deep neural networks with transformer architectures \citep{vaswaniAttentionAllYou2017} and reinforcement learning from human feedback \citep{ouyangTrainingLanguageModels2022,christianoDeepReinforcementLearning2017,stiennonLearningSummarizeHuman2020,wirthSurveyPreferencebasedReinforcement2017} to follow instructions from prompts and provide human-level responses, with known differences in GPT-4 possessing multimodal capabilites (e.g. image/voice input/output), more recent training data, and improved responses compared to ChatGPT-3 \citep{wuBriefOverviewChatGPT2023}. GPT-3.5 and GPT-4 were instructed with text prompts to assign CODs based on the open narrative. InterVA-5 and InSilicoVA are widely used and studied standard statistical models \citep{murrayUsingVerbalAutopsy2014,otiVerbalAutopsyInterpretation2010,benaraEvaluationMethodsAssigning2023,chandramohanEstimatingCausesDeath2021,tungaVerbalAutopsyModels2021,leitaoComparisonPhysiciancertifiedVerbal2014,jhaAutomatedPhysicianAssignment2019} for COD assignment in VAs under the openVA framework \citep{liOpenVAToolkitVerbal2023}. InterVA-5 applies Bayesian probabilistic modelling \citep{bayesEssaySolvingProblem1958} using a set of standardized symptoms from reports and related conditional probabilities from medical experts to assign CODs based on the highest probability \citep{byassIntegratedApproachProcessing2019,byassStrengtheningStandardisedInterpretation2012}. InSilicoVA improves upon InterVA (e.g. comparable probabilities across individuals, measures of uncertainty, and inclusion of additional data sources) with a hierarchical Bayesian framework and Markov Chain Monte Carlo (MCMC) simulations \citep{brooksMarkovChainMonte1998,chibMarkovChainMonte2001,hanMarkovChainMonte2001} to incorporate multiple sources of uncertainty for assigning CODs based on the highest probability \citep{mccormickProbabilisticCauseofDeathAssignment2016b}. For assigning CODs, GPT-3.5 and GPT-4 require prompts containing conversation-like textual instructions as input, while InterVA-5 and InSilicoVA require structured symptom and associated sociodemographic data as input. 

\subsubsection{Input Data and Preprocessing}\label{methods-models-input}

For GPT-3.5 and GPT-4, 6939 text prompts were generated for each physician agreed record as input to instruct the models to assign CODs based on the open narratives. Two types of text prompts were used: user prompts and system prompts. System prompts contained textual instructions to assign the role of a physician ICD-10 coder with expertise in Sierra Leone. The following system prompt was used for each record:

\begin{lstlisting}
You are a physician with expertisein determining underlying causes of death in Sierra Leone by assigning the most probable ICD-10 code for each death using verbal autopsy narratives. Return only the ICD-10 code without description. E.g. A00. If there are multiple ICD-10 codes, show one code per line.
\end{lstlisting}

\noindent User prompts contained textual instructions to perform coding of VA records based on the age, sex, and narrative of the deceased. The following template was used to generate user prompts for each record, where \verb|<age>| and \verb|<sex>| from the questionnaire, and \verb|<narrative>| from the narratives, were replaced with values from the data:

\begin{lstlisting}
Determine the underlying cause of death and provide the most probable ICD-10 code for a verbal autopsy narrative of a <age> years old <sex> death in Sierra Leone:  <narrative>
\end{lstlisting}

\noindent For InterVA-5 and InSilicoVA, the standardized questionnaire data from the HEAL-SL EVA were first converted into 2016 World Health Organization (WHO) VA questionnaire revision 1.5.1 Open Data Kit (ODK) format \citep{worldhealthorganizationODKVerbalAutopsy2022,nafundiODKCollectData2023} consisting of 526 variables \citep{dipasqualeReleaseODK20162016}, followed by further conversion into OpenVA format \citep{liOpenVAToolkitVerbal2023} consisting of 353 variables \citep{byassInterVA5UserGuide2020} using the \verb|pyCrossVA| version 0.97 Python package \citep{thomasPycrossvaPrepareData}. The 6939 records were all converted into OpenVA formatted records for InterVA-5 and InSilicoVA.

\subsubsection{Models and Parameters}\label{methods-models-params}

The GPT-3.5 and GPT-4 Application Programming Interface (API) was accessed using Python version 3.11.4 and used to assign CODs for each record. GPT-3.5 used the \verb|gpt-3.5-turbo| model, while GPT-4 used the \verb|gpt-4-0613| model. The parameter \verb|temperature| for GPT-3.5 and GPT-4, representing the sampling temperature ranging from 0 to 2 (default of 1), was set to 0 to produce more deterministic outputs \citep{openaiOpenAIPlatformAPI2024}. Higher values closer to 2 may produce less deterministic outputs, while lower values closer to 0 produce more deterministic outputs.

The \verb|openVA| R package was used to run InterVA-5 and InSilicoVA models to assign CODs for each record in R version 4.3.1. The \verb|openVA| package version 1.1.1 used dependent packages \verb|InterVA5| version 1.1.3 and \verb|InSilicoVA| version 1.4.0. The \verb|Nsim| (number of iterations to run) parameter \citep{liInSilicoVAProbabilisticVerbal2022} for InSilicoVA was set to 9500, while the \verb|HIV| (level of prevalence of human immunodeficiency virus) and \verb|Malaria| (level of prevalence of Malaria) parameters \citep{thomasInterVA5ReplicateAnalyse2021} for InterVA-5 were both set to \verb|'h'| (high) reflecting HIV and Malaria disease assumptions in Sierra Leone \citep{yendewaHIVAIDSSierra2018,walkerMalariaMorbidityMortality2015}.

% Note that the default value of \verg|Nsim=10000| for InSilicoVA ran until 9500 iterations before it stopped due to errors, thus Nsim=9500 was used and ran successfully for all iterations.

\subsubsection{Output Data and Code Conversions}\label{methods-models-output}

Of the 6939 input records, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA were able to assign CODs for 6939 (100\%), 6935 (\textgreater 99\%), 6830 (98\%), 6830 (98\%) records respectively. All 6830 (100\%) InterVA-5 and InSilicoVA records with WHO VA 2016 v1.5 output codes \citep{worldhealthorganizationVerbalAutopsyStandards2016} were converted into ICD-10 codes respectively. After all model outputs were converted to ICD-10 codes, they were further converted to CGHR-10 codes. The 6939 GPT-3.5 and 6935 GPT-4 output records with ICD-10 codes were converted into 6930 (\textgreater 99\%) and 6931 (\textgreater 99) records with CGHR-10 codes, where \textless 1\% (9 and 8) records did not have matching CGHR-10 codes respectively. The 6830 InterVA-5 and InSilicoVA records with ICD-10 codes were converted into 6802 (\textgreater 99\%) and 6726 (98\%) records with CGHR-10 codes respectively, where 28 (\textless 1\%) and 104 (1\%) of records could not be converted into CGHR-10 codes.

\subsection{Performance Evaluation}\label{methods-eval}

The performance of four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, were evaluated with metrics on the population and individual level by comparing their CGHR-10 COD outputs to 6939 records. Cause Specific Mortality Fraction (CSMF) accuracy was used to evaluate models on the population level (see Appendix \ref{methods-eval-csmfa}), while Partial Chance Corrected Concordance (PCCC) was used to evaluate models on the individual level (see Appendix \ref{methods-eval-pccc}) \citep{murrayRobustMetricsAssessing2011}. Records that were assigned a COD by physicians, but not by a model were considered to be an incorrect COD assignment by the model. CSMF accuracy and PCCC were calculated for each model by three age groups, and further into age ranges and COD for each age group.

The CSMF accuracy and PCCC metrics were calculated and compared for each model overall and by age group, followed by age ranges and COD for each age group as model performance can vary across ages and specific causes \citep{benaraEvaluationMethodsAssigning2023,murrayUsingVerbalAutopsy2014,setelValidityVerbalAutopsy2006}. Metrics were calculated overall for three age groups according to the CGHR-10 codes: adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days). For each of the adult and child age groups, metrics were calculated for five-year age ranges for records with ages at death of one-year or older and five-month age ranges for 28 days or older. For the neonatal age group, the age ranges of 0-6 days and 7-27 days were used. Metrics were also calculated by CODs defined by CGHR-10 codes, which include 19, 10, and 7 CODs for adult, child, and neonatal records respectively.

\section{Results}\label{results}

This section details the performance results of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models for assigning CGHR-10 CODs after applying the methods in Section \ref{methods}. GPT-4 performed the best overall at 0.61 PCCC followed by GPT-3.5 at 0.58 PCCC. GPT-4 also had the highest PCCC for most age ranges and CODs across the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups with GPT-3.5, InterVA-5, and InSilicoVA having higher PCCC values for a few age ranges and CODs. Overall performance results are seen in Section \ref{results-overall}, and performance by adult, child, and neonatal records are seen in Sections \ref{results-adult}, \ref{results-child}, and \ref{results-neo} respectively.

\subsection{Overall Performance}\label{results-overall}

Of the 6939 records, GPT-4 had the highest PCCC followed by GPT-3.5, InSilicoVA, and InterVA-5 at 0.61, 0.58, 0.44, and 0.43 PCCC respectively (Table \ref{tab-perf-overall}). GPT-3.5 and GPT-4 had improvements ranging from 0.14-0.18 PCCC over InSilicoVA and InterVA-5, while GPT-4 slightly improved over GPT-3.5 by 0.03 PCCC. CSMF accuracies were above 0.7 for all models at 0.79, 0.74, 0.74, and 0.78 for GPT-4, GPT-3.5, InSilicoVA, and InterVA-5 respectively. Figure \ref{fig-perf-agegroup} shows the PCCC performance across age groups with reference to the CSMF Accuracy. GPT-4 had the highest PCCC at 0.65 and 0.62 for the adult and neonatal age groups, while GPT-3.5 had the highest PCCC at 0.57 for the child age group with GPT-4 performing slightly worse at 0.54. GPT-3.5 had the second highest PCCC at 0.56 fo the adult age group, while InSilicoVA had the second highest PCCC for the neonatal age group at 0.56. InSilicoVA and InterVA-5 performed the worse for both adult and child age groups at PCCC scores below 0.5, while GPT-3.5 performed the worse for the neonatal age group with a PCCC of 0.42. The PCCC for models had larger differences between the minimum and maximum PCCC for the adult age group at 0.24, than the child and neonatal age groups at 0.12 and 0.20 respectively. For reference, all records, including non-physician agreed records, were also coded by GPT-3.5, GPT-4, InterVA-5, and InSilicoVA for comparison to physician agreed records. For physician agreed records, models had 0.05 to 0.09 higher PCCC values and 0.01 to 0.05 higher CSMF accuracy values than for all records (see Figure \ref{fig-perf-allvsagree} in Appendix \ref{app-perf-misc}).

\begin{table}[h]
\caption{Overall model performance on CGHR-10 CODs for physician agreed records.}\label{tab-perf-overall}%
\begin{tabular}{@{}llll@{}}
\toprule
Model & PCCC & CSMF Accuracy & PCCC Improvement\\
\midrule
GPT-4 & 0.61 & 0.79 & $\uparrow$ 0.03\\
GPT-3.5 & 0.58 & 0.74 & $\uparrow$ 0.14\\
InSilicoVA & 0.44 & 0.74 & $\uparrow$ 0.01\\
InterVA-5 & 0.43 & 0.78 & -\\
\botrule
\end{tabular}
\end{table}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-perf-agegroup.pdf}
\caption{Model performance by age group for assigning CGHR-10 CODs.}\label{fig-perf-agegroup}
\end{figure}

\subsection{Performance for 3826 Adult Records (12 to 69 years)}\label{results-adult}

Across the adult age ranges, GPT-4 had the highest PCCC values at or above 0.59, followed by GPT-3.5, while InterVA-5 and InSilicoVA had the lowest PCCC values at or below 0.46. GPT-4 PCCC was between 0.61 and 0.72 for young to middle age ranges between 10 to 49 years, and at or below 0.62 for older age ranges between 50 to 69 years (Figure \ref{fig-perf-agerange-adult}). Each age range had between 135 (4\%) to 575 (15\%) records with the 65-69 year age range having the most records (n=575, 15\%), while other age ranges ranged from 4-9\% of all records. Figure \ref{fig-perf-cod-adult} shows the highest and lowest performing models by PCCC across 17 adult CODs excluding suicide due to the less notable 3 (\textless 1\%) records. The highest PCCC values were GPT-4 between 0.36 to 0.99 for 10 of 17 CODs (GPT-3.5, InterVA-5, and InSilicoVA within 0.05 for 3, 1, and 1 of these 10 CODs respectively), InSilicoVA for tuberculosis and road and transport injuries at 0.72 and 0.84 (GPT-4 and InterVA-5 within 0.05), and GPT-3.5 between 0.44 and 0.94 for 5 of 17 CODs (GPT-4 within 0.05 for malaria). The lowest PCCC values were InterVA-5 between 0 to 0.79 for 8 of 17 CODs (InSilicoVA and GPT-3.5 within 0.05 for cancers and unspecified infections respectively), InSilicoVA between 0.01 to 0.41 for 6 of 17 CODs (InterVA-5 within 0.05 for other cardiovascular diseases and diarrhoeal diseases), and GPT-3.5 at 0.39 for tuberculosis and 0.54 for road and transport injuries. Chronic respiratory diseases had the largest differences between minimum and maximum PCCC at 0.93. Maternal conditions, and road and transport injuries, had higher PCCC values above or at 0.67 (with the exception of GPT-3.5 for road and transportation injuries as an outlier), where there were small differences between minimum and maximum PCCC below or at 0.2. Ischemic heart disease and unspecified infections had PCCC values below or at 0.65, where there were small differences between minimum and maximum PCCC at or below 0.14. Each adult COD had between 27 (\textless 1\%) to 799 records (21\%) with malaria (n=799, 21\%), other noncommunicable diseases (n=414, 11\%), and unspecified infections (n=389, 10\%) making 42\% of all records, and other CODs between 1-9\% of all records. GPT-4 had the highest PCCC for both male and female records at 0.65 and 0.64 respectively, while all other models had PCCC at or below 0.6 (see Figure \ref{fig-perf-sex-adult} in Appendix \ref{app-perf-misc}).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-cod-adult.pdf}
\caption{Model performance for adult records by COD.}\label{fig-perf-cod-adult}
\end{figure}

\subsection{Performance for 2636 Child Records (28 Days to 11 Years)}\label{results-child}

Across the child age ranges, the highest PCCC was observed for GPT-4 at 0.59 and 0.66 for 1-5 years and 6-11 years (GPT-3.5 within 0.05), GPT-3.5 at 0.54 for 6-11 months, and InSilicoVA at 0.5 for 1-5 months (Figure \ref{fig-perf-agerange-child}). Each child age range had between 308 (12\%) to 1633 (62\%) records with most records in the 1-5 years range at 1633 records (62\%) and the other age ranges consisting of 12-14\% of all records. For the 8 child CODs (excluding congenital anomalies due to small sample size of 1 (\textless 1\%) record), the highest PCCC observed was for GPT-4 for 4 of 8 CODs, GPT-3.5 for 3 of 8 CODs (InSilicoVA within 0.05 for other infections), and InSilicoVA for pneumonia (Figure \ref{fig-perf-cod-child}). The lowest PCCC across the 8 child CODs was observed for InSilicoVA for epilepsy, leukaemia, and other noncommunicable diseases and malaria, InterVA-5 for pneumonia, nutritional deficiencies, and other infections. GPT-3.5, InSilicoVA, and InterVA-5 all had similar PCCC values greater than 0.8 as the lowest PCCC for injuries. Epilepsy, leukaemia, and other noncommunicable disease had the largest difference between minimum and maximum PCCC at 0.68, while Ill-defined had the next largest difference at 0.67 with InSilicoVA and InterVA-5 at 0 PCCC. Malaria and other infections had low PCCC values below 0.58 across models with small differences between minimum and maximum PCCC at 0.18 and 0.14 respectively. Injuries and diarrhoeal diseases had high PCC values above 0.6 across models with small differences between minimum and maximum PCC at 0.14 and 0.3 respectively. Each of the 8 child CODs had between 11 (\textless 1\%) to 1382 (52\%) records with malaria (n=1382, 52\%), other infections (n=667, 25\%), and diarrhoeal diseases (n=175, 7\%) making 84\% of all records. Nutritional deficiencies had less than 1\% of all records, while other CODs had between 1-3\% of all records. GPT-3.5 had the highest PCCC for both male and female records at 0.56 and 0.58 with GPT-4 within 0.05 PCCC at 0.55 and 0.54 respectively, while all other models had PCCC below 0.5 (see Figure \ref{fig-perf-sex-child} in Appendix \ref{app-perf-misc}).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-perf-cod-child.pdf}
\caption{Model performance for child records by CGHR-10 COD.}\label{fig-perf-cod-child}
\end{figure}

\subsection{Performance for 477 Neonatal Records (Under 28 Days)}\label{results-neo}

GPT-4 had the highest PCCC for 0-6 day and 7-27 day neonatal age ranges at 0.6 and 0.7 respectively, while GPT-3.5 had the lowest PCCC across all neonatal age ranges as seen in Figure \ref{fig-perf-agerange-neo}. There were large differences between minimum and maximum PCCC for 7-27 days at 0.33, and small differences for 0-6 days at 0.16. Most records were in the 0-6 day age range at 395 (83\%) records, while the rest were in the 7-27 day age range at 82 (17\%) records. Across 5 neonatal CODs (excluding congenital anomalies and other due to small sizes of 2 (\textless 1\%) and 5 (1\%) respectively), the highest PCCC was observed for GPT-4 for 3 of the 5 CODs (GPT-3.5 identical for prematurity and low birthweight), GPT-3.5 for 2 of the 5 CODs (InSilicoVA identical for stillbirth), and InSilicoVA for neonatal infections (Figure \ref{fig-perf-cod-neo}). Stillbirth had small differences between minimum and maximum PCCC at 0.07. The other 4 CODs had large differences between minimum and maximum PCCC ranging from 0.46 to 0.64. Each neonatal COD had between 23 (5\%) to 172 (38\%) records, with stillbirth (n=172, 36\%), birth asphyxia and birth trauma (n=103, 22\%), and neonatal infections (n=99, 21\%), and prematurity and low birthweight (n=73, 15\%) making 94\% of all records, while the rest are in ill-defined. GPT-4 had the highest PCCC for both female and male records at 0.62, while all other models had PCCC at or below 0.56 (see Figure \ref{fig-perf-sex-neo} in Appendix \ref{app-perf-misc}).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-perf-cod-neo.pdf}
\caption{Model performance for neonatal records by COD. GPT-3.5, GPT-4, InterVA-5, and InSilicoVA model performance for assigning CGHR-10 CODs in the neonatal age group (under 28 years) by COD. PCCC values are sorted by the highest to lowest PCCC for each COD. Only models with PCCC values within .05 of the highest and lowest PCCC are shown. Congenital anomalies and other are not notable due to small sample sizes of 2 and 5 respectively.}\label{fig-perf-cod-neo}
\end{figure}

\section{Discussion}\label{discuss}

This section discusses and summarizes the results from Section \ref{results}. Advantages and disadvantages of using GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models for assigning CODs are discussed in Sections \ref{discuss-adv} and \ref{discuss-disadv}. Limitations of the study are mentioned in Section \ref{discuss-limits}, while opportunities and future work are detailed in Section \ref{discuss-opp}.

\subsection{Advantages}\label{discuss-adv}

This section identifies advantages of performant models for assigning CODs. Section \ref{discuss-adv-cod} details the strategic use of models for particular CODs. Section \ref{discuss-adv-hscav} details the resource efficiency of GPT and InSilicoVA models for assisting in physician COD assignment. Section \ref{discuss-adv-nlf} notes the strength of using natural language text in GPT models compared to structured data (e.g. questionnaires) for physician COD assignment.

\subsubsection{Performant for Particular Causes of Death}\label{discuss-adv-cod}

At the population level, overall performances for all causes were similar (0.7 $\leq$ CSMF $\leq$ 0.79), but not close ($\geq$0.8  CSMF), to physicians at 0.74-0.79 CSMF. At the individual level, performance by PCCC varies across CODs, and for most CODs, GPT models (GPT-4 and GPT-3) performed better than InSilicoVA and InterVA-5 (Table \ref{tab-perf-geq80}). However, there were CODs where InSilicoVA performed better. For example, neonatal infections at 0.87 PCCC versus 0.23 for GPT-3.5, and adult tuberculosis at 0.72 versus 0.39 for GPT-3.5. For CODs with high performance ($\geq$0.8 PCCC) (Table \ref{tab-perf-geq80}), the results suggest that GPT models (and InSilicoVA for particular CODs) may assign CODs that are close physicians, when physicians would agree on the COD. Thus, when applying models to assign CODs, it may help to target CODs with a combination of models that performed well or close to physician assignment.

Across age ranges, GPT and InSilicoVA models had performances below 0.8 PCCC, where ages 10-24 years and 7-27 days had the highest performance ($\geq$0.7 PCCC). For adult age ranges, performance generally decreased as age increased, which suggested that models had difficult assigning CODs for older than younger adults (Figure \ref{fig-perf-agerange-adult}). For child and neonatal age ranges, the performance improves as the age increases, suggesting less difficulty in COD assignment when children and neonates are more developed (Figures \ref{fig-perf-agerange-child} and \ref{fig-perf-agerange-neo}). As the models did not perform well for any particular age range, it may not be suggested to apply specific models to target cases by age range. However, the general patterns (increases and decreases of performance in relation to age) are useful in comparing expected patterns in relation to physician assignment.

\begin{table}[h]
    \caption{Models with performances close to physician COD assignment ($\geq$0.8 PCCC) across age groups}\label{tab-perf-geq80}%
    \begin{tabular}{@{}llll@{}}
    \toprule
    \makecell{Cause of Death} & Cases & \makecell{Best Model} & \makecell{PCCC} \\
    
    \midrule
    \multicolumn{3}{l}{Adult (n=3826, 1303 (34\%) $\geq$ 0.8 PCCC)}\\
    \midrule

    Maternal conditions & 130 (3\%) & GPT-4 & 0.99\\
    Chronic respiratory diseases & 75 (2\%) & GPT-3.5 & 0.94\\
    Diabetes mellitus & 27 (1\%) & GPT-3.5 & 0.92\\
    Cancers & 49 (1\%) & GPT-4 & 0.92\\
    Road and transport injuries & 251 (7\%) & InSilicoVA & 0.84\\
    Other injuries & 357 (9\%) & GPT-4 & 0.84\\
    Other noncommunicable diseases & 414 (11\%) & GPT-3.5 & 0.82\\
    
    \midrule
    \multicolumn{3}{l}{Child (n=2636, 505 (19\%) $\geq$ 0.8 PCCC)}\\
    \midrule

    Injuries & 135 (5\%) & GPT-4 & 0.95\\
    Diarrhoeal diseases & 175 (7\%) & GPT-4 & 0.91\\
    Epilepsy, leukaemia, and\\other noncommunicable diseases & 114 (4\%) & GPT-3.5 & 0.89\\
    Pneumonia & 81 (3\%) & InSilicoVA & 0.8\\

    \midrule
    \multicolumn{3}{l}{Neonatal (n=477, 99 (21\%) $\geq$ 0.8 PCCC)}\\
    \midrule

    Neonatal infections & 99 (21\%) & InSilicoVA & 0.87\\

    \botrule
    \end{tabular}
\end{table}

\subsubsection{Highly Scalable and Available}\label{discuss-adv-hscav}

The models in this study can assist physicians in assigning CODs in a variety of ways due to low costs and speed of COD assignment. Similar to differential diagnoses, GPT and InSilicoVA models can offer more alternative COD assignments for physicians to consider, \citep{barnettComparativeAccuracyDiagnosis2019}, which can potentially help lower the number of records with ill-defined causes or reduce disagreement in physicians. At the time of this study, running GPT-3.5 cost $\sim$\$1.6 USD (\$0.5 per one million tokens), GPT-4 cost $\sim$\$115 USD (\$30 per one million tokens), and InSilicoVA had no costs on 6939 physician agreed records \citep{openaiPricing2024}. These costs are likely lower than physicians (e.g. less than \$3 USD per house in India \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005}), while over 10,000 records can be coded in under a day. When physicians are unavailable, GPT and InSilicoVA models can be a cost-efficient alternative to code large amounts of records for population estimates of CODs. However, care needs to be taken to apply these models only for certain CODs where models perform well, such as in Table \ref{tab-perf-geq80}. In addition, these models can also help divert physician resources to cases that are more difficult to code or require more attention For example, physicians can validate cases, such as road traffic injury where models performed well at 0.84 PCCC, while spending more time on cases that related to acute respiratory infections, where the models performed poorly at 0.62 PCCC (Figure \ref{fig-perf-cod-adult}). Lastly, as models can assign CODs on-demand, there is potential for models to provide CODs during the data collection process, and for GPT models to guide the surveyor to ask additional questions for improving narrative quality.

\subsubsection{Natural Language Flexibility}\label{discuss-adv-nlf}

All models did not require training data to assign CODs, which allowed them to be used without domain expertise and supplying training datasets. The main advantage to GPT-3.5 and GPT-4 was the use of natural language text as input and output. Compared to InterVA-5 and InSilicoVA, GPT models were able to assign COD codes in ICD-10, as physicians do, and potentially assign CODs in more broad categories depending on the prompts. In comparison, InterVA-5 and InSilicoVA relied on structured input and output data from WHO VA 2016 questionnaires, and assigned CODs in WHO VA 2016 codes only. This required that these codes and forms be maintained with conversions between different form (e.g. WHO VA 2012 to WHO VA 2016) and code standards (e.g. WHO VA 2016 to ICD-10), which reduces interoperability and comparability when other models and VA systems do not use the same or interchangeable standards. Thus, GPT models did not require strict formats for training and testing data, which can capture latent and more ambiguous patterns (e.g. health-seeking behaviours and social issues) outside the scope of WHO VA codes and forms \citep{jebleeAutomaticallyDeterminingCause2019,kingQualityDiagnosticValue2016}. For example, GPT-3.5 and GPT-4 had higher performance (+0.14-0.67 PCCC) than InterVA-5 and InSilicoVA for more ambiguous CODs (e.g. other/unspecified infections, ill-defined, other cardiovascular diseases). GPT models also performed better (+0.57 PCCC) on CODs with a small number of cases, such as nutritional deficiencies (n=11) and diabetes mellitus (n=27), which may not have enough cases for questionnaires to capture statistical patterns, but may possibly have richer contextual information from articles, web sources, or books that GPT models can leverage.

\subsection{Disadvantages}\label{discuss-disadv}

This section discusses the disadvantages of GPT models for COD assignment. Section \ref{discuss-disadv-reprod} identifies issues in reproducing GPT outputs for repeated runs on the same records and lack of up-to-date information, while Section \ref{discuss-disadv-repriv} discusses the resource intensive infrastructure required by GPT and its relation to data privacy.

\subsubsection{Reproducibility and Timeliness}\label{discuss-disadv-reprod}

The GPT models in this study had the temperature parameter set to 0 for more reproducible results. A short experiment in Appendix \ref{app-reprod} revealed that GPT-3.5 assigns the same COD for the same record only more than 60\% of the time, based on repeated runs on a sample of 100 records. Although more extensive testing is needed, this suggests that GPT models do not always assign the COD for the same case on multiple runs, which may pose issues in reproducibility and reliability. For example, GPT models may achieve correct COD assignments solely due to random chance, but are difficult to test with large numbers (e.g. 10,000) of reruns due to costs (e.g. costs increased 10 fold per record when rerun 10 times). In comparison, InterVA-5 and InSilicoVA are open source and free, and assign deterministic CODs with probabilities for each alternative COD, which offers more reproducible and reliable COD assignments despite lower performance overall. In addition, all models were trained on historical data up to particular points in time, which may not utilize the most up-to-date data available (e.g. latest online articles, social media, or books for GPT models).

\subsubsection{Infrastructure and Data Privacy}\label{discuss-disadv-repriv}

GPT-3.5 and GPT-4 models required large computing infrastructure to train and run, which was not possible to run on local computers, or setup due to costs. This poses issues with data privacy as sensitive data (e.g. identifying information) needs to be sent to company servers, which can be collected by companies (e.g. OpenAI) and misused \citep{taoOpeningPandoraBox2023}. For example, GPT models use prompts, which contain the narrative data, to assign CODs. The data in the promots may be unknowingly collected and misused by companies (e.g. companies) or their users (e.g. malicious prompts) \citep{khowajaChatGPTNeedsSPADE2024,wuUnveilingSecurityPrivacy2024}. In contrast, InterVA-5 and InSilicoVA can be run on local computers, which allows data to stay with the owner to protect data privacy, without reliance on external services.

\subsection{Limitations}\label{discuss-limits}

This section identifies limitations in this research in the context of GPT models. Section \ref{discuss-limits-icd10} identifies the omission of ICD-10 performance evaluations. Section \ref{discuss-limits-data} discusses data limitations, such as small samples, exclusion of disagreements, and exploration of incorrectly assigned cases. Section \ref{discuss-limits-model} mentions the need for parameter tuning and evaluation of consistency and multiple COD assignments.

\subsubsection{ICD-10 Performance Evaluation}\label{discuss-limits-icd10}

For the scope of this study, all models were evaluated for their performance in broad CGHR-10 COD categories as opposed to more specific ICD-10 codes. However, in practical cases, physicians assign more specific ICD-10 codes rather than broader COD categories. InterVA-5 and InSilicoVA assigned broader WHO VA codes, and were unable to assign ICD-10 codes, as the number of cases for specific ICD-10 codes may not have enough cases for training statistical models. GPT models were able to assign ICD-10 codes, but may possibly result in lower performance as even physicians do not agree completely on ICD-10 codes, and broader categories (CMEA-10 codes in Additional file 2) were used to assign equivalency or agreement.

\subsubsection{Small Samples, Disagreements, and Misclassifications}\label{discuss-limits-data}

Performance evaluations and analyses were omitted for CODs with less than 10 cases (e.g. congenital anomalies, suicide), in which models may perform well on, but have limited evidence to make conclusive insights on performance. In this study, only records where physicians agreed on the COD assignment were included in performance evaluations. However, the performance of GPT-4 only dropped slightly from 0.61 (agreed) to 0.53 (disagreed) PCCC while records almost doubled, which suggests that GPT models may potentially be able to assign agreeable CODs without reconciliation or adjudication for cases where physicians disagreed (Figure \ref{fig-perf-allvsagree}). In relation, GPT may be used to explore prompts that may possibly reconcile or adjudicate records in disagreement. Finally, an exploration of misclassifications was not conducted for this study, but may yield useful insights. For example, a non-comprehensive exploration was conducted in Appendix \ref{app-misclass} on misclassified GPT-4 records for neonatal infections, which found potential issues with the categorization of CGHR-10 codes, order of information in narratives, and guidelines of COD assignments. More records may also provide more conclusive evidence of model performance results as 6939 records may be inadequate evidence at the country level compared to more comprehensive studies (e.g. the million death study \citep{jhaProspectiveStudyOne2005}).

\subsubsection{Model Tuning, Consistency, and Multiple Outputs}\label{discuss-limits-model}

GPT-3.5 and GPT-4 models used default parameters with the exception of setting the temperature to 0 for more consistent results. However, the temperature and other potential settings may be adjusted to possibly improve performance \citep{openaiOpenAIPlatformAPI2024}. In addition, GPT models may possibly produce inconsistent results even with the temperature set to 0 as discussed in Section \ref{discuss-disadv-reprod}. Thus, it is important to also test the reliability and consistency of GPT outputs to avoid coincidental results due to randomness \citep{johnsonAssessingAccuracyReliability2023,jangConsistencyAnalysisChatGPT2023,krishnaEvaluationReliabilityRepeatability2024}. InterVA-5 and InSilicoVA were able to provide multiple COD assignments with probabilities for each. GPT models can be prompted to produce more than one COD assignment, but was not explored in this study. This may be useful to evaluate the performance of suggested alternative COD assignments, which can help physicians reach agreement or reduce ill-defined assignments.

\subsection{Opportunities}\label{discuss-opp}

This section discusses research opportunities to improve GPT models for assigning CODs. Section \ref{discuss-opp-peng} discusses the potential to improve GPT models with prompt engineering and exploration of misclassified records. Section \ref{discuss-opp-vaint} identifies an opportunity to integrate GPT, InterVA-5, and InSilicoVA models into VA systems for improving physician COD assignment.

\subsubsection{Prompt Engineering and Custom Models}\label{discuss-opp-peng}

Prompt engineering, the act of designing prompts to guide GPT models for better results \citep{wangPromptEngineeringHealthcare2024}, presents an important research opportunity that may improve performance of GPT models for COD assignment. As mentioned in Section \ref{discuss-limits-data} and exemplified in Appendix \ref{app-misclass}, an analysis of misclassified records may yield insights on adjusting prompts to assign more correct CODs in relation to physicians. In addition, subsequent prompts and examples can be used to add in correctional instructions and refine results, while additional information from the questionnaire and physician VA manuals may add better context \citep{meskoPromptEngineeringImportant2023}. Sensitivity analyses may be conducted to assess the effects on performance and consistency of results from modified prompts on a COD basis. GPT models may also be customized to specific domains or contexts, where objectives, behaviours, extra data, privacy, and evaluation tests can be adjusted to produce custom models that perform better in targeted domains or circumstances \citep{almasreDevelopmentEvaluationCustom2024}.

\subsubsection{Computer Assisted Verbal Autopsy}\label{discuss-opp-vaint}

Another research opportunity is in the integration of GPT, InterVA-5, and InSilicoVA models into VA systems to assist physicians in COD assignment. In dual-coded VA systems (described in Section \ref{methods-data}), two physicians are randomly assigned to each record and require second inspections of each other's assignment (reconciliation) and evaluation by a third more senior physician if their assignments do not agree. As mentioned in Section \ref{discuss-adv-hscav}, suggestion of alternative assignments from GPT and InSilicoVA models potentially reduces the disagreement between physicians, and ill-defined records, while allowing physicians to focus on more difficult records. Thus, model suggestions can be integrated into VA systems by presenting model suggestions to physicians after their initial COD assignment, which allows them to consider alternative assignments and possibly revise their assignments based on the suggestions (Figure \ref{fig-discuss-phyassist}). Our future work will be a first step in computer assisted verbal autopsy, assessing the effects of these model suggestions on physician assignment outcomes (e.g. increase in agreed records, reduction of ill-defined deaths). In preparation, we have integrated GPT-4, InterVA-5, and InSilicoVA model suggestions into our HEAL-SL study for after survey round 2 \citep{njalauniversityHealthySierraLeone2023}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{fig-discuss-phyassist.pdf}
    \caption{Addition of model suggestions into the physician assignment process. At step 2, GPT, InterVA-5, and InSilicoVA models can suggest COD assignments to consider, providing the option in step 2b to revise or proceed with their initial assignment. The additional consideration potentially reduces disagreement between physicians and ill-defined deaths.}\label{fig-discuss-phyassist}
\end{figure}

\section{Conclusion}\label{conclude}

This study evaluates the performance of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models compared to physicians for assigning CODs for 6939 VA records in Sierra Leone (2019-2022). At the population level, all models had CSMF accuracies of 0.7-0.79. At the individual level, GPT-4 had the best performance (0.61 PCCC), followed by GPT-3.5 (0.58 PCCC), InSilicoVA (0.44 PCCC), and InterVA-5 (0.45 PCCC). When evaluating performance by COD, 7 of 19, 4 of 10, and 1 of 7 adult (12-69 years), child (28 days to 11 years),
and neonatal (under 28 days) CODs respectively had models with $\geq$0.8 PCCC (see Table \ref{tab-perf-geq80}). Performance decreased from 0.72 to 0.59 PCCC as adults aged, and increased from 0.5 to 0.7 PCCC as children and neonates developed. Thus, GPT and InSilicoVA models were comparable to physicians for particular CODs (e.g. maternal conditions, injuries, diarrhoeal diseases, pneumonia), but not across age ranges. Advantages of GPT (and InSilicoVA for some CODs) models include being highly scalable and available, which allows the suggestion of multiple alternative COD assignments, and reduction of time spent on non-complex cases to assist physicians in COD assignment. In addition, GPT models provide flexible natural language input and output, capturing latent patterns (e.g. health-seeking and social issues) that potentially lead to their overall high performance compared to InterVA-5 and InSilicoVA. However, GPT models do not always assign the same COD for the same record on multiple runs, are trained on data from a specific time period, and require large computing infrastructure, leading to disadvantages in reliability of COD assignments, timeliness of up-to-date information, and data privacy issues. Limitations of this study were small sample sizes in relation to rarer CODs and other national level studies, need for more comprehensive exploration of disagreed and misclassified records, and lack of experimentation of model parameters, output consistency, and multiple COD assignments. Research opportunities include refining GPT models using prompt engineering and custom models, and future work towards computer assisted verbal autopsy, where GPT and other models are used to assist physician COD assignment by offering multiple alternative assignments, improving physician agreement on COD assignment and reducing ill-defined deaths. GPT-4, InterVA-5, and InSilicoVA has been integrated into future rounds of the HEAl-SL study to assist physicians with alternative COD assignments. Future work in evaluating the effectiveness of these models to reduce disagreements among physicians and ill-defined deaths will be a step forward in more accurate and efficient VA systems.

% Conclusions may be used to restate your hypothesis or research question, restate your major findings, explain the relevance and the added value of your work, highlight any limitations of your study, describe future directions for research and recommendations. 

% In some disciplines use of Discussion or 'Conclusion' is interchangeable. It is not mandatory to use both. Please refer to Journal-level guidance for any specific requirements. 

\backmatter

\bmhead{Supplementary information}

% If your article has accompanying supplementary file/s please state so here. 

% Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

% Please refer to Journal-level guidance for any specific requirements.

Additional files were used to supplement this paper:

\begin{itemize}
    \item Additional file 1: Centre for Global Health Research 10 (CGHR-10) codes. Codes grouping ICD-10 code ranges into generalized categories. (.csv)
    \item Additional file 2: Central Medical Evaluation Agreement 10 (CMEA-10) codes. ICD-10 code ranges considered in physician agreement. (.csv)
\end{itemize}

\bmhead{Acknowledgments}

% Acknowledgments are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

% Please refer to Journal-level guidance for any specific requirements.

TBD.

\section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval 
% \item Consent to participate
% \item Consent for publication
% \item Availability of data and materials
% \item Code availability 
% \item Authors' contributions
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

\subsection*{Funding}

TBD.

\subsection*{Competing interests}

Not applicable.

\subsection*{Ethics approval}

TBD.

\subsection*{Consent for publication}

Not applicable.

\subsection*{Availability of data and materials}

The datasets supporting the conclusions of this article are included within the article (and its additional files), at \url{https://openmortality.org} (available upon request) and at \url{https://github.com/cghr-toronto/healsl-gpt-paper}.

\noindent\\Verbal Autopsy (VA) data by age group and survey rounds 1 and 2:

\begin{itemize}
    \item Adult VA (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_adult_v1}
    \item Adult VA (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_adult_v1}
    \item Child VA (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_child_v1}
    \item Child VA (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_child_v1}
    \item Neonatal VA (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_neo_v1}
    \item Neonatal VA (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_neo_v1}
\end{itemize}

\noindent\\Narrative data by age group and survey rounds 1 and 2:

\begin{itemize}
    \item Adult Narratives (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_adult_narrative_v1}
    \item Adult Narratives (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_adult_narrative_v1}
    \item Child Narratives (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_child_narrative_v1}
    \item Child Narratives (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_child_narrative_v1}
    \item Neonatal Narratives (Round 1):\\\url{https://openmortality.org/data/healsl_rd1_neo_narrative_v1}
    \item Neonatal Narratives (Round 2):\\\url{https://openmortality.org/data/healsl_rd2_neo_narrative_v1}
\end{itemize}

\noindent\\Cause of death code mappings to convert between ICD-10, WVA-2016, and CGHR-10 codes:

\begin{itemize}
    \item ICD-10 to CGHR-10:\\\url{https://openmortality.org/data/cghr10_v1}
    \item WVA-2016 to ICD-10:\\\url{https://openmortality.org/data/icd10_wva2016_v1}
\end{itemize}

\noindent\\Result files:

\begin{itemize}
    \item Model and physician COD assignments:\\\url{https://github.com/cghr-toronto/healsl-gpt-paper/blob/main/data/healsl_rd1to2_cod_v1.csv}
    \item Metrics for model COD assignments:\\\url{https://github.com/cghr-toronto/healsl-gpt-paper/blob/main/data/healsl_rd1to2_metrics_v1.csv}
    \item GPT-3.5 repeated runs results in Appendix \ref{app-reprod}:\\\url{https://github.com/cghr-toronto/healsl-gpt-paper/blob/main/data/healsl_rd1to2_rapid_gpt3_sample100_v2b.csv}
\end{itemize}

\subsection*{Code availability}

All code for this paper is available at \url{https://github.com/cghr-toronto/healsl-gpt-paper}.

\subsection*{Authors' contributions}

PJ and PB are the study Principal Investigators. ATA and RK implemented the data collection procedures. RW, CC, LN, and TKSN processed, documented, and prepared the data. RW, ASL, and RK ran the models. RW wrote the paper and conducted the analysis. AB provided medical domain guidance and feedback. All authors reviewed the results and contributed to the report. All authors read and approved the final manuscript.

\begin{appendices}

% Fix figure hyperrefs for appendix
\setcounter{figure}{0}
\renewcommand{\thefigure}{\thesection\arabic{figure}}
\renewcommand{\theHfigure}{\thesection\arabic{figure}}

%\section{Section title of first appendix}\label{secA1}

%An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.
    
%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\section{Case Study Data Exploration}\label{app-data}

The 6939 physician agreed records were relatively evenly distributed (approximately 40-57\% male and female) for the adult, child, and neonatal age groups in terms of sex (Figure \ref{fig-data-agesex}) with the most records in the 1-5 year (n=1633, 24\%) age range, and the least records in the 10-14 year (n=135, 2\%) and 7-27 day (n=82, 1\%) age ranges (Figure \ref{fig-data-agerange}). The other 15 five-year age ranges within 0 days to 69 years were relatively evenly distributed with approximately 4-6\% of the 6939 records each. The 3826 adult records had most records in the 65-69 year (n=575, 15\%), and the least in the 10-14 year (n=135, 4\%) age ranges, while the other 10 age ranges were relatively evenly distributed at 7-9\% of all records (Figure \ref{fig-data-agerange-adult}). For adult CODs, Malaria (n=799, 21\%) had the highest number of adult records, and cancers (n=49, 1\%), diabetes mellitus (n=27, \textless 1\%), and suicide (n=3, \textless 1\%) had the lowest number adult of adult records, while the other 15 CODs had between 2-11\% of all adult records (Figure \ref{fig-data-cod-adult}). The 2636 child records had most records in the 1-5 year (n=1633, 62\%) age range while the three other age ranges were relatively evenly distributed at 12-14\% of all records (Figure \ref{fig-data-agerange-child}). For child CODs, Malaria (n=1382, 52\%) and other infections (n=667, 25\%) had the highest number of child records, while nutritional deficiencies (n=11, \textless 1\%) and congenital anomalies (n=1, \textless 1\%) had the lowest number of records with the five other CODs between 3-7\% of all child records. The 477 neonatal records had two age ranges with most records in the 0-6 day (n=395, 83\%) age range and the rest in the 7-27 day (n=82, 17\%) age range (Figure \ref{fig-data-agerange-neo}). For neonatal CODs, stillbirth (n=172, 36\%) had the highest number of neonatal records, and ill-defined (n=23, 5\%), other (n=5, 1\%), and congenital anomalies (n=2, \textless 1\%) had the least number of records with the rest of the other three CODs between 15-22\% of all neonatal records (Figure \ref{fig-data-cod-neo}).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-sampling.pdf}
\caption{HEAL-SL sampling areas and VA records with physician assigned CODs only from 2019-2022.}\label{fig-data-sampling}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-agesex.pdf}
\caption{Number of physician agreed VA records by age groups in Sierra Leone from 2019 to 2022.}\label{fig-data-agesex}
\end{figure}

\newpage
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-agerange.pdf}
\caption{Number of physician agreed VA records by 5-year age ranges in Sierra Leone from 2019 to 2022.}\label{fig-data-agerange}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-agerange-adult.pdf}
\caption{Number of physician agreed adult (12 to 69 years) VA records by 5-year age ranges in Sierra Leone from 2019 to 2022.}\label{fig-data-agerange-adult}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-cod-adult.pdf}
\caption{Number of physician agreed adult (12 to 69 years) VA records by CGHR-10 COD code in Sierra Leone from 2019 to 2022.}\label{fig-data-cod-adult}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-agerange-child.pdf}
\caption{Number of physician agreed child (28 days to 11 years) VA records by 5-year age ranges in Sierra Leone from 2019 to 2022.}\label{fig-data-agerange-child}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-cod-child.pdf}
\caption{Number of physician agreed child (28 days to 11 years) VA records by CGHR-10 COD code in Sierra Leone from 2019 to 2022.}\label{fig-data-cod-child}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-agerange-neo.pdf}
\caption{Number of physician agreed neonatal (less than 28 days) VA records by 5-year age ranges in Sierra Leone from 2019 to 2022.}\label{fig-data-agerange-neo}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-data-cod-neo.pdf}
\caption{Number of physician agreed neonatal (less than 28 days) VA records by CGHR-10 COD code in Sierra Leone from 2019 to 2022.}\label{fig-data-cod-neo}
\end{figure}

\section{Case Study Methods}\label{app-methods}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{fig-methods.pdf}
\caption{Case study methods.}\label{fig-methods}
\end{figure}

\subsection{Cause Specific Mortality Fraction (CSMF) Accuracy}\label{methods-eval-csmfa}

CSMF accuracy measures the performance of models at the population level, comparing distributions of CODs between the physicians and the models \citep{murrayRobustMetricsAssessing2011}. To calculate CSMF accuracy, we first calculate $CSMF_j$ as is the fraction of physician or model records for cause $j$, given by dividing the number of records for cause $j$ with the total number of records as seen in Equation \ref{eq-csmf}. Then, the $CSMFMaximumError$, representing the worst possible model, is calculated using Equation \ref{eq-csmferr}. Finally, the CSMF accuracy is given by Equation \ref{eq-csmfa}, where $k$ is the number of causes, $j$ is a cause, $CSMF^{true}_j$ is the true physician CSMF for cause $j$, and $CSMF^{pred}_j$ is the prediction model CSMF for cause $j$. CSMF accuracy ranges from 0 to 1, where 1 means that the model completely matched the physician COD distribution and 0 means that it did not match the distribution at all.

\begin{equation}\label{eq-csmf}
    CSMF_j = Records_j / Records
\end{equation}

\begin{equation}\label{eq-csmferr}
    CSMFMaximumError = 2(1 - Min(CSMF^{true}_j)
\end{equation}

\begin{equation}\label{eq-csmfa}
    CSMFAccuracy = 1 - \frac{\sum^{k}_{j=1}|CSMF^{true}_j - CSMF^{pred}_j|}{CSMFMaximumError}
\end{equation}

\subsection{Partial Chance Corrected Concordance (PCCC)}\label{methods-eval-pccc}

PCCC measures the performance of models at the individual level, comparing COD assignments between the physicians and models on a record by record basis, correcting for COD assignments made purely by chance \citep{murrayRobustMetricsAssessing2011}. PCCC is given by Equation \ref{eq-pccc}, where $k$ is the number of top COD assignments from the model to consider, $N$ is number of causes, and $C$ is fraction of records where the physician COD assignment is one of the top COD assignments from the model. For this study, we set $k$ to 1, making $C$ equivalent to the fraction of true positives $TP$ or records where the physician COD assignment is equal to the model COD assignment as shown in Equation \ref{eq-pccc-c}. Higher PCCC values closer to 1 indicate that model COD assignments are similar to physician COD assignments, while values closer to 0 indicate that model COD assignments are not similar to physicians.

\begin{equation}\label{eq-pccc-c}
    C = \frac{TP}{Records}
\end{equation}

\begin{equation}\label{eq-pccc}
    PCCC(k) = \frac{C - \frac{k}{N}}{1 - \frac{k}{N}}
\end{equation}

\section{Performance By Other Variables}\label{app-perf-misc}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-allvsagree.pdf}
\caption{Model performance for all records versus physician agreed records.}\label{fig-perf-allvsagree}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-agerange-adult.pdf}
\caption{Model performance for adult records by five-year age range.}\label{fig-perf-agerange-adult}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-sex-adult.pdf}
\caption{Model performance for adult records by sex.}\label{fig-perf-sex-adult}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-perf-agerange-child.pdf}
\caption{Model performance for child records by five-year age range.}\label{fig-perf-agerange-child}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-sex-child.pdf}
\caption{Model performance for child records by sex for assigning CGHR-10 CODs.}\label{fig-perf-sex-child}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-perf-agerange-neo.pdf}
\caption{Model performance for neonatal records by age range.}\label{fig-perf-agerange-neo}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig-perf-sex-neo.pdf}
\caption{Model performance for neonatal records by sex for assigning CGHR-10 CODs.}\label{fig-perf-sex-neo}
\end{figure}

\section{Experiment on Repeated Runs of GPT-3.5}\label{app-reprod}

A short experiment was conducted to test the consistency of GPT-3.5 outputs repeated on the same record. 100 records, sampled randomly with approximately equal proportions across age groups, CODs, and survey rounds 1 and 2, were used to test repeated runs of GPT-3.5. Each record from the 100 records was rerun 10 times through GPT-3.5, resulting in ten COD outputs per record. The ICD-10 codes were then converted to CGHR-10 codes and tested for consistency, where completely inconsistent results had different ICD-10 or CGHR-10 codes for each of the 10 reruns (1 times+), and completely consistent results had the same ICD-10 or CGHR-10 code for all 10 reruns (10 times), on the same record.

The results are shown in Table \ref{tab-reprod}. For all 100 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code for the same record 5 times or more out of 10. For 66 and 79 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively for each record. This number increases to 94 (from 66) and 96 (from 79) when reducing the number of times out of 10 that GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively. Thus, GPT-3.5 does not always produce the same outputs when repeated on the same record (10 times out of 10), even when the temperature is set to 0, but does so for more than half the records. For most records (more than 90\%), GPT-3.5 will produce the same outputs for the same record 7 times or more out of 10.

\begin{table}[!htbp]
    \caption{Records with same GPT-3.5 outputs based on 10 repeated reruns of 100 records}\label{tab-reprod}%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Times with Same GPT-3.5 Outputs & ICD-10 Records & CGHR-10 Records\\

    \midrule
    
    1 times+ (inconsistent) & 100  & 100\\
    2 times+ & 100  & 100\\
    3 times+ & 100  & 100\\
    4 times+ & 100  & 100\\
    5 times+ & 100  & 100\\
    6 times+ & 94  & 96\\
    7 times+ & 92  & 94\\
    8 times+ & 86  & 91\\
    9 times+ & 79  & 86\\
    10 times (consistent) & 66  & 79\\

    \botrule
    \end{tabular}
\end{table}

\section{Exploration of Neonatal Infections}\label{app-misclass}

An exploration of neonatal infections (n=99, 21\% of 477 records) was done to understand the low performance of GPT models (0.23 PCCC) for neonatal infections, and high performance of InSilicoVA (0.87 PCCC). In Table \ref{tab-misclass}, about half the records were assigned correctly, and a majority (n=33, 33\%) of the other records were misclassified as other, while prematurity and low birthweight, birth asphyxia \& birth trauma, and ill-defined make up the rest. On closer inspection of the 49 records with misclassified assignments, the ICD-10 code R50 was assigned in 20 records. R50 falls under unspecified infections in the adult CGHR-10 category, but in the other category for neonates. B50 was assigned in 4 records, falling under malaria, but a similar B54 falls under neonatal infections. P81 was assigned in 3 records, referring to fever of unknown origin, which falls under other, and P07 was assigned in 7 records, falling under prematurity and low birthweight.

In most misclassified records, there is mention of infections, but the misclassifications occur due to the finer details of the ICD-10 code classifications, the categorization decisions of the CGHR-10 codes, and missing information from the questionnaire. For R50 misclassifications, GPT may have confused descriptions across adult and neonatal age groups. Using the same definition of R50, but in the context of neonates, may result in codes closer to neonatal infections (e.g. B54). For B50 misclassifications, the similar B54 was categorized in CGHR-10 as neonatal infections, but B50 was categorized as other. P81 refers to fever of unknown origin, which may be difficult to differentiate between infection and other causes without information from the questionnaire. P07 refers to prematurity and low birthweight, where GPT initially assigned P07 as the age of the neonate was mentioned first, but later mentions infections as an alternative following the order of information in the narratives. Thus, it may be possible to improve the performance GPT models using better prompts based on the context of VA manuals and CGHR-10 codes, and by also including questionnaire information in the prompts.

\begin{table}[!htbp]
    \caption{GPT-4 CGHR-10 COD assignment for physician coded neonatal infections records.}\label{tab-misclass}%
    \begin{tabular}{@{}ll@{}}
    \toprule
    GPT-4 Assigned Cause of Death (CGHR-10) & Records\\

    \midrule
    
    Neonatal infections & 50 (51\%)\\
    Other & 33 (33\%)\\
    Prematurity and low birthweight & 9 (9\%)\\
    Birth asphyxia \& birth trauma & 5 (6\%)\\
    Ill-defined & 2 (2\%) \\

    \midrule

    Total & 99 (100\%)\\

    \botrule
    \end{tabular}
\end{table}

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\clearpage
\bibliography{bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
