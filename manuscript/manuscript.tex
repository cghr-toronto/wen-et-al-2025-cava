% Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
\documentclass[sn-vancouver,Numbered,referee]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{lstautogobble}%
\usepackage{makecell}%
%%%%

\lstset{
    texcl=true,
    basicstyle=\small\sf,
    commentstyle=\small\rm,
    mathescape=true,
    escapeinside={(*}{*)},
    breaklines=true,
    breakindent=0.5pt
}

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
%%\theoremstyle{thmstyleone}%
%%\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
%%\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

%%\theoremstyle{thmstyletwo}%
%%\newtheorem{example}{Example}%
%%\newtheorem{remark}{Remark}%

%%\theoremstyle{thmstylethree}%
%%\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Comparing Generative Pre-trained Transformer Models to Physicians for Assigning Causes of Death from Verbal Autopsy: A Case Study of 6939 Deaths in Sierra Leone from 2019-2022]{Comparing Generative Pre-trained Transformer Models to Physicians for Assigning Causes of Death from Verbal Autopsy: A Case Study of 6939 Deaths in Sierra Leone from 2019-2022}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Richard} \sur{Wen}}\email{richard.wen@utoronto.ca}

\author[1,2]{\fnm{Anteneh Tesfaye} \sur{Assalif}}\email{antenehta@gmail.com}

\author[1]{\fnm{Andy Sze-Heng} \sur{Lee}}\email{andylee@cs.toronto.edu}

\author[1]{\fnm{Rajeev} \sur{Kamadod}}\email{rajeevk@kentropy.com}

%\equalcont{These authors contributed equally to this work.}

\author[1]{\fnm{Asha} \sur{Behdinan}}\email{asha.behdinan@mail.utoronto.ca}

\author[1]{\fnm{Ronald} \sur{Carshon-Marsh}}\email{ronald.carshonmarsh@mail.utoronto.ca}

\author[1]{\fnm{Thomas Kai Sze} \sur{Ng}}\email{kaisze.ng@unityhealth.to}

\author[2]{\fnm{Rashid} \sur{Ansumana}}\email{rashidansumana@gmail.com}

\author[1]{\fnm{Patrick} \sur{Brown}}\email{patrick.brown@utoronto.ca}

\author[1]{\fnm{Prabhat} \sur{Jha}}\email{prabhat.jha@utoronto.ca}

\affil*[1]{\orgdiv{Centre for Global Health Research, St. Michael's Hospital}, \orgname{Unity Health Toronto and University of Toronto}, \orgaddress{\street{30 Bond St}, \city{Toronto}, \postcode{M5B 1W8}, \state{Ontario}, \country{Canada}}}

\affil[2]{\orgdiv{School of Community Health Sciences}, \orgname{Njala University}, \orgaddress{\city{Bo}, \country{Sierra Leone}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{\textbf{Background:} Verbal Autopsies (VAs) collect data on deaths and their causes outside of traditional hospital settings to provide more representative counts and Causes of Death (CODs) for reducing premature mortality. Current computer models for COD assignment in VAs perform similar to physicians at the population level, but poorly at the individual level, due to a focus on structured questionnaire data and neglecting free text from the open narratives. Recently, a Generative Pre-trained Transformer (GPT) model called ChatGPT-4 has demonstrated human-level performance on professional and academic exams using free text input. ChatGPT-4 shows promise in mimicking physician behavior for assigning CODs, but to the best of our knowledge, has yet to be tested for assigning CODs using open narratives from VAs.

\textbf{Methods:} 6939 records collected from VA in Sierra Leone from 2019 to 2022 were used to compare four computer models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, to physicians for assigning CODs at the population and individual level. Open narratives were used for GPT-3.5/4 input, while structured questionnaires were used for InterVA-5/InSilicoVA input. All COD assignments were grouped into general COD categories consisting of 19, 10, and 7 categories for adult, child, and neonatal age groups. Cause Specific Mortality Fraction (CSMF) accuracy and Partial Corrected Concordance (PCCC) were used to compare models to physicians at the population and individual level respectively. Comparisons in CSMF and PCCC to physicians among models were evaluated overall and by COD, age group, and age ranges.

\textbf{Results:} GPT-4 had the best performance overall (0.61 PCCC), followed by GPT-3.5 (0.56 PCCC), and InSilicoVA/InterVA-5 (0.44 PCCC). GPT-4 had the best performance for adult and neonatal records (0.64 and 0.58 PCCC), with GPT-3.5 for child records (0.54 PCCC). All models' performances trended upwards from 1 month to 14 years ($~$0.1-0.75 PCCC) and downwards from 15-69 years ($~$0.7-0.35) of age. GPT-4, GPT-3.5, ad InSilicoVA had the highest performances for 17, 9, and 4 of all 30 CODs respectively. At the population level, all models had CSMF accuracies between 0.7-0.79.

\textbf{Conclusion:} All models performed well at the population level, while GPT-3.5/4 and InSilicoVA performed well for some CODs. GPT models have yet to replace physician coding, but have made improvements over InSilicoVA and InterVA-5. Thus, our research lays the foundation for future opportunities in computer assisted VA, where physicians are presented with alternative COD assignments from computer models to help reduce ill-defined codes and physician disagreement.
}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Cause of Death, Physician Coding, Verbal Autopsy, GPT, AI, LLM}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Background}\label{background}

In 2019, 41 million people die prematurely from noncommunicable diseases every year, accounting for 74\% of all deaths globally \citep{worldhealthorganizationNonCommunicableDiseases2019}. Most of these deaths are preventable, but require adequate resource allocation, guided by evidence, to implement effective interventions and policies that target populations at risk \citep{benzigerGlobalBurdenDisease2016}. Thus, reliable counts and diagnoses of deaths enable decision makers to identify populations at risk to save lives and reduce premature deaths worldwide \citep{lawnMillionNeonatalDeaths2010,lassiCommunityBasedIntervention2015,liuExcessMortalityPersons2017,ewigCommunityacquiredPneumoniaEmergency2011}. However, most low-income countries do not have data on deaths or have registered less than half of the deaths in their country, with an even fewer 8\% of these registered deaths having a Cause of Death (COD) recorded \citep{worldhealthorganizationSCOREHealthData2021}. To fill this gap in death registrations, an alternative method known as Verbal Autopsy (VA) is used to collect data on deaths and determine their likely causes at scale \citep{desavignyIntegratingCommunitybasedVerbal2017,thomasVerbalAutopsyHealth2018,rampatigeSystematicReviewStatistics2014}, outside of traditional healthcare facilities where over half of deaths occur at home \citep{adairWhoDiesWhere2021}.

VA involves two major components: survey and COD assignment \citep{worldhealthorganizationVerbalAutopsyStandards2023,chandramohanEstimatingCausesDeath2021,worldhealthorganizationVerbalAutopsyStandards2007}. In the survey component, trained lay surveyors interview those familiar with the deceased (e.g. living spouse, children, family, friends) to gather information using standardized questionnaires and open narratives. In the COD assignment component, physicians evaluate information available from the questionnaires and open narratives to assign probable CODs. This component has been criticized to be difficult to reproduce due to reliance on physician assignment \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005,mccormickProbabilisticCauseofDeathAssignment2016b,morrisFactorsAssociatedPhysician2010,solemanVerbalAutopsyCurrent2006}. As an alternative to physician assignment, computer models, such as InterVA \citep{byassIntegratedApproachProcessing2019} and InSilicoVA \citep{mccormickProbabilisticCauseofDeathAssignment2016b}, have been studied to automatically assign CODs with performances close to physicians at the population level, but poor performances at the individual level \citep{jhaAutomatedPhysicianAssignment2019,leitaoComparisonPhysiciancertifiedVerbal2014,desaiPerformanceFourComputercoded2014,tungaVerbalAutopsyModels2021,otiVerbalAutopsyInterpretation2010}. These computer models often utilize data from the structured questionnaire, but often omit the free-text open narrative, which misses latent information, such as chronology or health-seeking behaviors, that may potentially help models perform better than using the questionnaire alone \citep{jebleeAutomaticallyDeterminingCause2019,blancoExtractingCauseDeath2021,kingQualityDiagnosticValue2016}.

Recently, Large Language Models (LLM), leveraging massive datasets and deep learning approaches, have made advances in performing a variety of Natural Language Processing (NLP) tasks using free-text, such as question answering, code generation, and even medical diagnosis \citep{changSurveyEvaluationLarge2023,lundChattingChatGPTHow2023,svyatkovskiyIntelliCodeComposeCode2020,hauptAIGeneratedMedicalAdvice2023}. In 2022, a widely-available LLM called ChatGPT was released by OpenAI with capabilities of answering natural language text inquiries using training data up to September 2021. ChatGPT-3 was based on several Generative Pre-trained Transformer (GPT) models between 2018 to 2020, namely GPT-1 to GPT-3, which had notable differences in training data sizes of 5 gigabytes to 45 terabytes from web sources that resulted in 117 million to 175 billion parameter models \citep{wuBriefOverviewChatGPT2023}. In March 2023, ChatGPT-4 was released with human-level performance on various professional and academic exams and benchmarks that outperformed ChatGPT-3 \citep{openaiGPT4TechnicalReport2023}. Given the limited usage of free-text open narratives in computer models for determining CODs, and recent advances in LLMs that leverage natural language text prompts, we conducted a case study with Sierra Leone deaths from VA in 2019 to 2022 to compare four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, to physicians for determining CODs.

\section{Methods}\label{methods}

This study uses 6939 physician agreed records (two physicians with similar COD assignment on the same record) of 11,920 records collected in 2019 to 2022 from the Healthy Sierra Leone (HEAL-SL) study as described in Section \ref{methods-data}. Section \ref{methods-models} describes the four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, for COD assignment, and their inputs and outputs, while section \ref{methods-eval} details the performance evaluation of the four models relative to physicians overall, by ages, and by COD, using population and individual level metrics. See Appendix \ref{app-methods} for additional details on the methods used in this study.

\subsection{Verbal Autopsy (VA) Data}\label{methods-data}

Initially, 11,920 records from the HEAL-SL study \citep{njalauniversityHealthySierraLeone2023,carshon-marshChildMaternalAdult2022} were collected from dual-coded EVA, where each record was randomly coded by two different physicians that assigned CODs as International Classification of Diseases Revision 10 (ICD-10) codes \citep{worldhealthorganizationICD10InternationalStatistical2011}. For each record, two codes were assigned by two different randomly selected physicians, where codes were evaluated for agreement using Central Medical Evaluation Agreement 10 (CMEA-10) codes. CMEA-10 groups a range of similar ICD-10 codes together, where if they are in agreement if they are within the same group \citep{aleksandrowiczPerformanceCriteriaVerbal2014} (see Additional File 2). When codes were not in agreement, a record enters the reconciliation phase, where the two physicians were provided reasoning and initial codes from each other to: (1) keep their initial code (2) assign the other physician's code or (3) assign a new code. If codes were not in agreement after the reconciliation phase, a record enters the adjudication phase, where a third senior physician evaluates both physicians' reasoning and codes before and after reconciliation, and assigns a final code based on their evaluation.

Since computer models were compared to physicians in this study, there was more certainty that COD assignments agreed by both physicians were representative of physician assignment than when they disagreed \citep{barnettComparativeAccuracyDiagnosis2019,morrisFactorsAssociatedPhysician2010,hsiaoFactorsAssociatedPhysician2012}. Thus, we used 6942 physician agreed records of the 11,920 total records. For better comparison, we standardized all codes to CGHR-10 codes (see Additional File 1) that generalized ICD-10 codes into 19, 10, and 7 categories for the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups. After conversion, a final total of 6939 physician agreed records (3826 adult, 2636 child, and 477 neonatal) were used for modelling and performance evaluation. See Appendix \ref{app-methods-data} for further details on data preprocessing and characteristics of the physician agreed records.

\subsection{Modelling}\label{methods-models}

Four computer models were used to assign COD for each of the 6939 physician agreed records: GPT-3.5, GPT-4, InterVA-5, and InSilicoVA. InterVA-5 and InSilicoVA are widely used and studied standard statistical models \citep{murrayUsingVerbalAutopsy2014,otiVerbalAutopsyInterpretation2010,benaraEvaluationMethodsAssigning2023,chandramohanEstimatingCausesDeath2021,tungaVerbalAutopsyModels2021,leitaoComparisonPhysiciancertifiedVerbal2014,jhaAutomatedPhysicianAssignment2019} for COD assignment in VAs under the openVA framework \citep{liOpenVAToolkitVerbal2023}. InterVA-5 applies Bayesian probabilistic modelling \citep{bayesEssaySolvingProblem1958} using a set of standardized symptoms from reports and related conditional probabilities from medical experts to assign CODs based on the highest probability \citep{byassIntegratedApproachProcessing2019,byassStrengtheningStandardisedInterpretation2012}. InSilicoVA improves upon InterVA (e.g. comparable probabilities across individuals, measures of uncertainty, and inclusion of additional data sources) with a hierarchical Bayesian framework and Markov Chain Monte Carlo (MCMC) simulations \citep{brooksMarkovChainMonte1998,chibMarkovChainMonte2001,hanMarkovChainMonte2001} to incorporate multiple sources of uncertainty for assigning CODs based on the highest probability \citep{mccormickProbabilisticCauseofDeathAssignment2016b}. GPT-3.5 \citep{brownLanguageModelsAre2020} and GPT-4 \citep{openaiGPT4TechnicalReport2023} are LLMs that utilize deep neural networks with transformer architectures \citep{vaswaniAttentionAllYou2017} and reinforcement learning from human feedback \citep{ouyangTrainingLanguageModels2022,christianoDeepReinforcementLearning2017,stiennonLearningSummarizeHuman2020,wirthSurveyPreferencebasedReinforcement2017} to follow instructions from prompts and provide human-level responses, with known differences in GPT-4 possessing multimodal capabilites (e.g. image/voice input/output), more recent training data, and improved responses compared to ChatGPT-3 \citep{wuBriefOverviewChatGPT2023}.

For GPT-3.5 and GPT-4, the following user prompt was used to instruct each model to produce COD assignments as ICD-10 codes, where \verb|<age>| and \verb|<sex>| from the questionnaire, and \verb|<narrative>| from the narratives, were replaced with values from the data:

\begin{lstlisting}
Determine the underlying cause of death and provide the most probable ICD-10 code for a verbal autopsy narrative of a <age> years old <sex> death in Sierra Leone:  <narrative>
\end{lstlisting}

\noindent For InterVA-5 and InSilicoVA, the standardized questionnaire data from EVA were converted into OpenVA format \citep{liOpenVAToolkitVerbal2023}, before being used as input for each model to produce COD assignments as WHO VA 2016 codes \citep{worldhealthorganizationVerbalAutopsyStandards2016}. All model outputs were converted to CGHR-10 codes to evaluate performances of models for COD assignment relative to physicians. See Appendix \ref{app-methods-model} for additional details regarding input parameters, output data, and code conversions for each model.

\subsection{Performance Evaluation}\label{methods-eval}

The performance of the four models were evaluated with metrics at the population and individual level by comparing their CGHR-10 COD outputs for 6939 records. Cause Specific Mortality Fraction (CSMF) accuracy was used to evaluate models on the population level (see Appendix \ref{app-methods-csmfa}), while Partial Chance Corrected Concordance (PCCC) was used to evaluate models on the individual level (see Appendix \ref{app-methods-pccc}) \citep{murrayRobustMetricsAssessing2011}. As model performance can vary across ages and specific causes \citep{benaraEvaluationMethodsAssigning2023,murrayUsingVerbalAutopsy2014,setelValidityVerbalAutopsy2006}, the CSMF accuracy and PCCC metrics were compared for each model overall, by age group (adult, child, neonatal), by CGHR-10 COD codes, and across age ranges. For each of the adult and child age groups, metrics were calculated for five-year age ranges for records with ages at death of one-year or older and five-month age ranges for 28 days or older. For the neonatal age group, the age ranges of 0-6 days and 7-27 days were used. See Appendix \ref{app-methods-eval} for more details on performance metrics and evaluation strategy for comparing each model.

\section{Results}\label{results}

This section details the performance results of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models for assigning CGHR-10 CODs after applying the methods in Section \ref{methods}. GPT-4 performed the best overall at 0.61 PCCC followed by GPT-3.5 at 0.56 PCCC. GPT-4 also had the highest PCCC for most age ranges and CODs across the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups with GPT-3.5, InterVA-5, and InSilicoVA having higher PCCC values for a few age ranges and CODs. Overall performance results are seen in Section \ref{results-overall}, and performance by adult, child, and neonatal records are seen in Sections \ref{results-adult}, \ref{results-child}, and \ref{results-neo} respectively.

\subsection{Overall Performance}\label{results-overall}

Of all 6939 records, GPT-4 (0.61 PCCC) had the highest individual performance followed by GPT-3.5 (0.56 PCCC), InSilicoVA (0.44 PCCC), and InterVA-5 (0.44 PCCC) (Figure \ref{fig-pccc-csmf}). GPT-3.5 and GPT-4 had improvements ranging from 0.14-0.18 PCCC over InSilicoVA and InterVA-5, while GPT-4 slightly improved over GPT-3.5 by 0.05 PCCC. Population level performances were similar for all models (0.74-0.79 CSMF). Figure \ref{fig-pccc} shows the PCCC performance across three age groups (adult, child, and neonate). GPT-4 had the best individual performance for adult and neonatal records (0.64 and 0.58 PCCC), while GPT-3.5 had the best performance for child records (0.54 PCCC) with GPT-4 performing slightly worse (0.51 PCCC). InSilicoVA and InterVA-5 performed the worse for adult and child records ($\leq$0.5 PCCC), while GPT-3.5 performed the worse for neonatal records (0.42 PCCC). Across age ranges, all models followed a similar pattern in individual performance (Figure \ref{fig-pccc-age}). PCCC trended upwards for 1 month to 14 years ($~$0.1-0.75), and downwards for ages 15 to 69 years ($~$0.7-0.35). The highest and lowest performances were observed for ages 10-29 years ($~$) and 1-11 months respectively. Performances varied more across models for ages 0 days to 5 years, while less variation was seen between GPT-3.5 and GPT-4, as well as InSilicoVA and InterVA-5, from 5 to 69 years.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-pccc-csmf.pdf}
\caption{Overall model performance.}\label{fig-pccc-csmf}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-pccc.pdf}
\caption{Model performance by age group.}\label{fig-pccc}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-pccc-age.pdf}
\caption{Model performance by age range.}\label{fig-pccc-age}
\end{figure}

\subsection{Performance for 3826 Adult Records (12 to 69 years)}\label{results-adult}

Figure \ref{fig-pccc-cod-adult} shows model performance by PCCC across 17 adult CODs excluding suicide due to low sample size (n=3, \textless 1\%). GPT-4 had the highest individual performance for 10 of 17 CODs (0.35 to 0.99 PCCC), GPT-3.5 for 5 CODs (0.43-0.94 PCCC), and InSilicoVA for 2 CODs (0.71 and 0.84 PCCC). InterVA-5 had the lowest performance for 8 of 17 CODs (0-0.79 PCCC), InSilicoVA for 6 CODs (0.01-0.41 PCCC), and GPT-3.5 for 2 CODs (0.38 and 0.53 PCCC). GPT-3.5/4 models improved over InSilicoVA/InterVA-5 the most for chronic respiratory diseases (0.74-0.94 PCCC difference), and the least for Malaria (0.09-0.17 PCCC difference). All models had \textgreater 0.7 PCCC for maternal conditions (0.79-0.99 PCCC), while unspecified infections, malaria, and ill-defined CODs models with \textless 0.5 PCCC. GPT-4 had performance improvements \textgreater 0.2 PCCC compared to all other models for cancers (+0.25-0.36 PCCC), stroke (+0.27-0.45 PCCC), and diarrhoeal diseases (+0.37-0.51 PCCC), while GPT-3.5 had similar improvements for liver and alcohol related diseases (+0.27-0.52 PCCC).

\begin{figure}[H]
\centering
\includegraphics[width=.9\textwidth]{fig-pccc-cod-adult.pdf}
\caption{Model performance for adult records by COD.}\label{fig-pccc-cod-adult}
\end{figure}

\subsection{Performance for 2636 Child Records (28 Days to 11 Years)}\label{results-child}

Figure \ref{fig-pccc-cod-child} presents individual performances for each of the models by 8 child CODs, excluding congenital anomalies due to low sample size (n=1, \textless 1\%). GPT-4 had the highest individual performance for 4 of 8 CODs (0.65-0.94 PCCC), GPT-3.5 for 3 CODs (0.44-0.88 PCCC), and InSilicoVA for 1 COD (0.78 PCCC). InterVA-5 had the lowest performance for 4 of 8 CODs (0.09-0.79 PCCC), InSilicoVA for 3 CODs (0-0.35 PCCC), and GPT-3.5 for 1 COD (0.58 PCCC). All models had \textgreater 0.7 PCCC for injuries (0.79-0.94 PCCC), and \textless 0.6 PCCC for malaria (0.35-0.54 PCCC) and other infections (0.29-0.44 PCCC). GPT-4 had improvements \textgreater 0.3 PCCC compared to other models for ill-defined CODs (+0.38-0.65 PCCC), and larger improvements over other models for injuries (+0.11-0.15 compared to +0.01-0.04 PCCC).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-pccc-cod-child.pdf}
\caption{Model performance for child records by COD.}\label{fig-pccc-cod-child}
\end{figure}

\subsection{Performance for 477 Neonatal Records (Under 28 Days)}\label{results-neo}

Model performance across 5 neonatal CODs, excluding congenital anomalies (n=2, \textless 1\%) and other (n=5, 1\%) due to small sample sizes is shown in Figure \ref{fig-pccc-cod-neo}. GPT-4 had the highest individual performance for 3 of 5 CODs (0.39-0.71 PCCC), GPT-3.5 for 1 COD (0.57 PCCC), and InSilicoVA for 1 COD (0.86 PCCC). GPT-3.5 had the lowest performance for 3 of 5 CODs (0-0.13 PCCC) and InterVA-5 for 2 CODs (0.01 and 0.48 PCCC). All models had similar performance for stillbirth deaths (0.48-0.57 PCCC), while only GPT-4 had a PCCC \textgreater 0 PCCC. InSilicoVA had improvements over all other models for neonatal infection deaths (+0.18-0.73 PCCC).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{fig-pccc-cod-neo.pdf}
\caption{Model performance for neonatal records by COD.}\label{fig-pccc-cod-neo}
\end{figure}

\section{Discussion}\label{discuss}

This section discusses and summarizes the results from Section \ref{results}. Advantages and disadvantages of using GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models for assigning CODs are discussed in Sections \ref{discuss-adv} and \ref{discuss-disadv}. Limitations of the study are mentioned in Section \ref{discuss-limits}, while opportunities and future work are detailed in Section \ref{discuss-opp}.

\subsection{Advantages}\label{discuss-adv}

This section identifies the advantages of models for assigning CODs. Section \ref{discuss-adv-cod} details the application of models for particular CODs and age ranges. Section \ref{discuss-adv-hscav} details the resource efficiency of computer models for assisting in physician COD assignment. Section \ref{discuss-adv-nlf} notes the strength of using natural language text in GPT models compared to structured questionnaire data for physician COD assignment.

\subsubsection{Cause-specific Models}\label{discuss-adv-cod}

At the population level, overall performances for all models were similar to physicians (0.74-0.79 CSMF), indicating potential for adequately estimating COD distributions for large populations. Although all models did not perform well for all records at the individual level (0.44-0.61 PCCC), several models performed well for certain CODs (0-0.99 PCCC). For most CODs, GPT-3.5/GPT-4 performed better than InSilicoVA/InterVA-5 (top PCCC for 15 of 17, 7 of 8, and 4 of 5 adult, child, and neonatal CODs respectively), while InSilicoVA performed better for particular CODs (road and transport injuries, tuberculosis, pneumonia, and neonatal infections with 0.84, 0.71, 0.78, and 0.86 PCCC respectively). For CODs with high performance (e.g. GPT-3.5/4 with 0.91-0.99 PCCC for maternal conditions, chronic respiratory disease, diabetes melitus, and cancers, InSilicoVA with 0.84 and 0.86 PCCC for road and transport injuries, and neonatal infections), the results suggest that GPT-3.5/4 and InSilicoVA may assign CODs that are very similar to physicians. Thus, it may be beneficial to evaluate performance at the COD level, and apply a combination of models that perform well in comparison to physicians for each COD. For example, different models perform well for various leading CODs as seen in Table \ref{tab-leadcod} \cite{worldhealthorganizationWorldHealthStatistics2024,worldhealthorganizationCausespecificMortality2000}.

\begin{table}[h]
    \caption{Leading causes globally in 2021 and most relevant models.}\label{tab-leadcod}%
    \begin{tabular}{@{}llll@{}}
    \toprule
    \makecell{Leading Causes of Death\\($\sim$53\% of 68M deaths)\footnotemark[1]} & \makecell{Deaths\\(\% of 68M)\footnotemark[2]} & \makecell{Best\\Model(s)} & \makecell{PCCC} \\
    \midrule

    Ischaemic heart disease & 9M (13\%) & GPT-4 & 0.65 (n=168)\\ 
    Stroke & 7M (10\%) & GPT-4 & 0.77 (n=331)\\
    Cancers & 4.3M (4\%) & GPT-4 & 0.91 (n=49)\\
    Lower respiratory infections & 2.4M (3\%) & GPT-3.5/4 & 0.78 (n=180)\footnotemark[3]\\
    Diabetes mellitus & 1.6M (2\%) & GPT-3.5 & 0.92 (n=27)\\
    Tuberculosis & 1.4M (2\%) & InSilicoVA & 0.71 (n=171)\\
    Hypertensive heart disease & 1.4M (2\%) & GPT-4 & 0.78 (n=107)\footnotemark[4]\\
    Cirrhosis of the liver & 1.3M (2\%) & GPT-3.5 & 0.78 (n=128)\footnotemark[5]\\ 
    Diarrhoeal diseases & 1.2M (2\%) & GPT-4 & 0.68 (n=205)\\ 
    Road injury & 1,183 (2\%) & InSilicoVA & 0.84 (n=357)\\
    Preterm birth complications & 0.9M (1\%) & GPT-4 & 0.71 (n=73)\\
    Falls & 0.7M (1\%) & GPT-4 & 0.89 (n=492)\footnotemark[6]\\

    \botrule
    \end{tabular}
    \footnotetext[1]{COVID-19, kidney disease, alzheimer disease, other dementias, and self-harm were excluded as a relevant CGHR-10 code was not present. Trachea, bronchus, lung, colon, rectum, stomache, and breast cancers were generalized into cancers.}
    \footnotetext[2]{Percentage of $\sim$68 Million (M) deaths globally. Numbers are rounded.}
    \footnotetext[3]{Mean of chronic and acute respiratory infections.}
    \footnotetext[4]{Derived from other cardiovascular diseases.}
    \footnotetext[5]{Derived from liver and alcohol related diseases.}
    \footnotetext[6]{Mean of adult and child injuries.}
\end{table}

\subsubsection{Age-specific Performance Patterns}\label{discuss-adv-age}

Across age ranges, all models followed a similar upward trend from 6 months to 14 years of age, and a downward trend from 15-69 years with GPT models having higher performance than InSilicoVA/InterVA-5 models, while more mixed trends were observed from 0 days to 5 months (recall Figure \ref{fig-pccc-age}). For adult age ranges, performance generally decreased as age increased, which suggested that models had difficult assigning CODs for older than younger adults with some improvements after the age of 59. For child and neonatal age ranges, the performance improves drastically as the age increases after 5 months, suggesting less difficulty in COD assignment when children and neonates are more developed. As the models did not perform particularly well ($\geq$ 0.8 PCCC) for any specific five-year age range, it is not recommended to apply specific models that target cases by age. However, the patterns of increases and decreases of performance in relation to age provide valuable insight for comparison to expected physician diagnosis patterns in well-studied medical literature and knowledge. For example, it may be expected that physicians are more uncertain in diagnosing diseases that are prevalent in neonatal patients \cite{rasmussenComplexityPhysiciansUnderstanding2019,faisonWhenUnknownUnknowable2023}, which are present in our findings from Figure \ref{fig-pccc-age}.

\subsubsection{Scalability and Availability}\label{discuss-adv-hscav}

The models in this study can assist physicians in assigning CODs in a variety of ways due to low costs and speed of COD assignment. Similar to differential diagnoses, GPT and InSilicoVA models offer alternative COD assignments for physicians to consider \citep{barnettComparativeAccuracyDiagnosis2019}, which can potentially help lower the number of records with ill-defined causes or reduce disagreement between physicians. At the time of this study, running GPT-3.5 cost $\sim$\$1.6 USD (\$0.5 per one million tokens), GPT-4 cost $\sim$\$115 USD (\$30 per one million tokens), and InSilicoVA was cost free on 6939 records \citep{openaiPricing2024}. These costs were lower than physicians (e.g. less than \$3 USD per house in India \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005}), while it is possible to code over 10,000 records in under a day. When physicians are unavailable, GPT and InSilicoVA models can be a cost-efficient alternative to code large amounts of records for population estimates of CODs. However, it is recommended to apply these models only for certain CODs where models perform well, such as in Table \ref{tab-leadcod}. In addition, these models can also help divert physician resources to cases that are more difficult to code or require more attention. For example, physicians can validate cases where models performed well (e.g. maternal conditions at 0.79-0.99 PCCC), while spending more time on cases where models performed poorly (e.g. acute respiratory infections at 0.25-0.61 PCCC).

\subsubsection{Natural Language Input and Output}\label{discuss-adv-nl}

Training data was not required to assign CODs for all models, which allowed application without domain expertise or supplying training datasets. The main advantage to GPT-3.5/4 was the use of natural language text as input and output. Compared to InterVA-5 and InSilicoVA, GPT models were able to assign COD codes in ICD-10 standard, as physicians do, and potentially assign CODs in more broad categories depending on the prompts. In comparison, InterVA-5 and InSilicoVA relied on structured input and output data from WHO VA 2016 questionnaires, and assigned CODs in WHO VA 2016 codes only. This required that these codes and forms be maintained with conversions between different form (e.g. WHO VA 2012 to WHO VA 2016) and code standards (e.g. WHO VA 2016 to ICD-10), which reduces interoperability and comparability with other incompatible models. GPT models did not require strict formats for training and testing data, which can capture latent and more ambiguous patterns (e.g. health-seeking behaviours and social issues) outside the scope of WHO VA codes and forms \citep{jebleeAutomaticallyDeterminingCause2019,kingQualityDiagnosticValue2016}. For example, GPT-3.5/4 had higher performance (+0.35-0.65 PCCC) than InterVA-5 and InSilicoVA for ambiguous ill-defined records across age groups. GPT models also performed better (+0.11-0.61 PCCC) on CODs with a rarer occurrence, such as nutritional deficiencies (n=11) and diabetes mellitus (n=27). Rarer CODs may be more difficult to capture by questionnaire due to lack of sample data, but it may possibly have richer contextual information from articles, web sources, or books that offer knowledge for GPT models to leverage.

\subsection{Disadvantages}\label{discuss-disadv}

This section discusses the disadvantages of GPT models for COD assignment. Section \ref{discuss-disadv-reprod} identifies issues in reproducing GPT outputs for repeated runs on the same records and lack of up-to-date information, while Section \ref{discuss-disadv-repriv} discusses the resource intensive infrastructure required by GPT and its relation to data privacy.

\subsubsection{Reproducibility and Timeliness}\label{discuss-disadv-reprod}

The GPT models in this study had the temperature parameter set to 0 for more reproducible results. A short experiment in Appendix \ref{app-reprod} revealed that GPT-3.5 assigns the same COD for the same record only more than 60\% of the time, based on repeated runs on a sample of 100 records. Although more extensive testing is needed, this suggests that GPT models do not always assign the COD for the same case on multiple runs, which may pose issues in reproducibility and reliability. For example, GPT models may achieve correct COD assignments solely due to random chance, but are difficult to test with large numbers (e.g. 10,000) of reruns due to costs (e.g. costs increased 10 fold per record when rerun 10 times). In comparison, InterVA-5 and InSilicoVA are open source and free, and assign deterministic CODs with probabilities for each alternative COD, which offers more reproducible and reliable COD assignments despite lower performance overall. In addition, all models were trained on historical data up to particular points in time, which may not utilize the most up-to-date data available (e.g. latest online articles, social media, or books for GPT models).

\subsubsection{Infrastructure and Data Privacy}\label{discuss-disadv-repriv}

GPT-3.5 and GPT-4 models required large computing infrastructure to train and run, which was not possible to run on local computers, or setup due to costs. This poses issues with data privacy as sensitive data (e.g. identifying information) needs to be sent to company servers, which can be collected by companies (e.g. OpenAI) and misused \citep{taoOpeningPandoraBox2023}. For example, GPT models use prompts, which contain the narrative data, to assign CODs. The data in the promots may be unknowingly collected and misused by companies (e.g. companies) or their users (e.g. malicious prompts) \citep{khowajaChatGPTNeedsSPADE2024,wuUnveilingSecurityPrivacy2024}. In contrast, InterVA-5 and InSilicoVA can be run on local computers, which allows data to stay with the owner to protect data privacy, without reliance on external services.

\subsection{Limitations}\label{discuss-limits}

This section identifies limitations in this research in the context of GPT models. Section \ref{discuss-limits-icd10} identifies the omission of ICD-10 performance evaluations. Section \ref{discuss-limits-data} discusses data limitations, such as small samples, exclusion of disagreements, and exploration of incorrectly assigned cases. Section \ref{discuss-limits-model} mentions the need for parameter tuning and evaluation of consistency and multiple COD assignments.

\subsubsection{ICD-10 Performance Evaluation}\label{discuss-limits-icd10}

For the scope of this study, all models were evaluated for their performance in broad CGHR-10 COD categories as opposed to more specific ICD-10 codes. However, in practical cases, physicians assign more specific ICD-10 codes rather than broader COD categories. InterVA-5 and InSilicoVA assigned broader WHO VA codes, and were unable to assign ICD-10 codes, as the number of cases for specific ICD-10 codes may not have enough cases for training statistical models. GPT models were able to assign ICD-10 codes, but may possibly result in lower performance as even physicians do not agree completely on ICD-10 codes, and broader categories (CMEA-10 codes in Additional file 2) were used to assign equivalency or agreement.

\subsubsection{Small Samples, Disagreements, and Misclassifications}\label{discuss-limits-data}

Performance evaluations and analyses were omitted for CODs with less than 10 cases (e.g. congenital anomalies, suicide), in which models may perform well on, but have limited evidence to make conclusive insights on performance. In this study, only records where physicians agreed on the COD assignment were included in performance evaluations. However, the performance of GPT-4 only dropped slightly from 0.61 (agreed) to 0.53 (disagreed) PCCC while records almost doubled, which suggests that GPT models may potentially be able to assign agreeable CODs without reconciliation or adjudication for cases where physicians disagreed (Figure \ref{fig-perf-allvsagree}). In relation, GPT may be used to explore prompts that may possibly reconcile or adjudicate records in disagreement. Finally, an exploration of misclassifications was not conducted for this study, but may yield useful insights. For example, a non-comprehensive exploration was conducted in Appendix \ref{app-misclass} on misclassified GPT-4 records for neonatal infections, which found potential issues with the categorization of CGHR-10 codes, order of information in narratives, and guidelines of COD assignments. More records may also provide more conclusive evidence of model performance results as 6939 records may be inadequate evidence at the country level compared to more comprehensive studies (e.g. the million death study \citep{jhaProspectiveStudyOne2005}).

\subsubsection{Model Tuning, Consistency, and Multiple Outputs}\label{discuss-limits-model}

GPT-3.5 and GPT-4 models used default parameters with the exception of setting the temperature to 0 for more consistent results. However, the temperature and other potential settings may be adjusted to possibly improve performance \citep{openaiOpenAIPlatformAPI2024}. In addition, GPT models may possibly produce inconsistent results even with the temperature set to 0 as discussed in Section \ref{discuss-disadv-reprod}. Thus, it is important to also test the reliability and consistency of GPT outputs to avoid coincidental results due to randomness \citep{johnsonAssessingAccuracyReliability2023,jangConsistencyAnalysisChatGPT2023,krishnaEvaluationReliabilityRepeatability2024}. InterVA-5 and InSilicoVA were able to provide multiple COD assignments with probabilities for each. GPT models can be prompted to produce more than one COD assignment, but was not explored in this study. This may be useful to evaluate the performance of suggested alternative COD assignments, which can help physicians reach agreement or reduce ill-defined assignments.

\subsection{Opportunities}\label{discuss-opp}

This section discusses research opportunities to improve GPT models for assigning CODs. Section \ref{discuss-opp-peng} discusses the potential to improve GPT models with prompt engineering and exploration of misclassified records, while Section \ref{discuss-opp-gsurveys} describes the application of GPT models for improving household surveys for better data quality. Section \ref{discuss-opp-cava} identifies an opportunity to integrate GPT, InterVA-5, and InSilicoVA models into VA systems for improving physician COD assignment.

\subsubsection{Prompt Engineering and Custom Models}\label{discuss-opp-peng}

Prompt engineering, the act of designing prompts to guide GPT models for better results \citep{wangPromptEngineeringHealthcare2024}, presents an important research opportunity that may improve performance of GPT models for COD assignment. As mentioned in Section \ref{discuss-limits-data} and exemplified in Appendix \ref{app-misclass}, an analysis of misclassified records may yield insights on adjusting prompts to assign more correct CODs in relation to physicians. In addition, subsequent prompts and examples can be used to add in correctional instructions and refine results, while additional information from the questionnaire and physician VA manuals may add better context \citep{meskoPromptEngineeringImportant2023}. Sensitivity analyses may be conducted to assess the effects on performance and consistency of results from modified prompts on a COD basis. GPT models may also be customized to specific domains or contexts, where objectives, behaviours, extra data, privacy, and evaluation tests can be adjusted to produce custom models that perform better in targeted domains or circumstances \citep{almasreDevelopmentEvaluationCustom2024}.

\subsubsection{Guided Household Surveys}\label{discuss-opp-gsurveys}

Finally, GPT models may also guide surveyors during VA interviews to probe households for better narrative information by suggesting better questions or questions that may have been missed by the surveyors. Lastly, as models can assign CODs on-demand, there is potential for models to provide immediate COD estimates during the data collection process to monitor data quality (e.g. comparing estimated to expected COD distributions for known areas as quality checks).

\subsubsection{Computer Assisted Verbal Autopsy}\label{discuss-opp-cava}

Another research opportunity is in the integration of GPT, InterVA-5, and InSilicoVA models into VA systems to assist physicians in COD assignment. In dual-coded VA systems (described in Section \ref{methods-data}), two physicians are randomly assigned to each record and require second inspections of each other's assignment (reconciliation) and evaluation by a third more senior physician if their assignments do not agree. As mentioned in Section \ref{discuss-adv-hscav}, suggestion of alternative assignments from GPT and InSilicoVA models potentially reduces the disagreement between physicians, and ill-defined records, while allowing physicians to focus on more difficult records. Thus, model suggestions can be integrated into VA systems by presenting COD suggestions to physicians after their initial COD assignment, which allows them to consider alternative assignments and possibly revise their assignments based on the suggestions. At step 2 in Figure \ref{fig-discuss-phyassist}, GPT, InterVA-5, and InSilicoVA models can suggest COD assignments to consider, providing the option in step 2b to revise or proceed with their initial assignment. Our future work will be a first step in computer assisted verbal autopsy, assessing the effects of these model suggestions on improve VA data quality (e.g. increase in agreed records, reduction of ill-defined deaths). In preparation, we have integrated GPT-4, InterVA-5, and InSilicoVA model suggestions into our on-going HEAL-SL study after survey round 2 \citep{njalauniversityHealthySierraLeone2023} with goals of increasing physician agreement and reducing ill-defined COD assignments.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{fig-discuss-phyassist.pdf}
    \caption{Model suggestions integrated in the physician assignment process.}\label{fig-discuss-phyassist}
\end{figure}

\section{Conclusion}\label{conclude}

This study evaluates the performance of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models compared to physicians for assigning CODs for 6939 VA records in Sierra Leone (2019-2022). At the population level, all models had CSMF accuracies of 0.7-0.79. At the individual level, GPT-4 had the best performance (0.61 PCCC), followed by GPT-3.5 (0.58 PCCC), InSilicoVA (0.44 PCCC), and InterVA-5 (0.45 PCCC). When evaluating performance by COD, 7 of 19, 4 of 10, and 1 of 7 adult (12-69 years), child (28 days to 11 years),
and neonatal (under 28 days) CODs respectively had models with $\geq$0.8 PCCC (see Table \ref{tab-perf-geq80}). Performance decreased from 0.72 to 0.59 PCCC as adults aged, and increased from 0.5 to 0.7 PCCC as children and neonates developed. Thus, GPT and InSilicoVA models were comparable to physicians for particular CODs (e.g. maternal conditions, injuries, diarrhoeal diseases, pneumonia), but not across age ranges. Advantages of GPT (and InSilicoVA for some CODs) models include being highly scalable and available, which allows the suggestion of multiple alternative COD assignments, and reduction of time spent on non-complex cases to assist physicians in COD assignment. In addition, GPT models provide flexible natural language input and output, capturing latent patterns (e.g. health-seeking and social issues) that potentially lead to their overall high performance compared to InterVA-5 and InSilicoVA. However, GPT models do not always assign the same COD for the same record on multiple runs, are trained on data from a specific time period, and require large computing infrastructure, leading to disadvantages in reliability of COD assignments, timeliness of up-to-date information, and data privacy issues. Limitations of this study were small sample sizes in relation to rarer CODs and other national level studies, need for more comprehensive exploration of disagreed and misclassified records, and lack of experimentation of model parameters, output consistency, and multiple COD assignments. Research opportunities include refining GPT models using prompt engineering and custom models, and future work towards computer assisted verbal autopsy, where GPT and other models are used to assist physician COD assignment by offering multiple alternative assignments, improving physician agreement on COD assignment and reducing ill-defined deaths. GPT-4, InterVA-5, and InSilicoVA has been integrated into future rounds of the HEAl-SL study to assist physicians with alternative COD assignments. Future work in evaluating the effectiveness of these models to reduce disagreements among physicians and ill-defined deaths will be a step forward in more accurate and efficient VA systems.

% Conclusions may be used to restate your hypothesis or research question, restate your major findings, explain the relevance and the added value of your work, highlight any limitations of your study, describe future directions for research and recommendations. 

% In some disciplines use of Discussion or 'Conclusion' is interchangeable. It is not mandatory to use both. Please refer to Journal-level guidance for any specific requirements. 

\backmatter

\bmhead{Supplementary information}

% If your article has accompanying supplementary file/s please state so here. 

% Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

% Please refer to Journal-level guidance for any specific requirements.

Additional files were used to supplement this paper:

\begin{itemize}
    \item Additional file 1: Centre for Global Health Research 10 (CGHR-10) codes. Codes grouping ICD-10 code ranges into generalized categories. (.csv)
    \item Additional file 2: Central Medical Evaluation Agreement 10 (CMEA-10) codes. ICD-10 code ranges considered in physician agreement. (.csv)
\end{itemize}

\bmhead{Acknowledgments}

% Acknowledgments are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

% Please refer to Journal-level guidance for any specific requirements.

TBD.

\section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval 
% \item Consent to participate
% \item Consent for publication
% \item Availability of data and materials
% \item Code availability 
% \item Authors' contributions
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

\subsection*{Funding}

TBD.

\subsection*{Competing interests}

Not applicable.

\subsection*{Ethics approval}

Not applicable.

\subsection*{Consent for publication}

Not applicable.

\subsection*{Availability of data and materials}

The datasets supporting the conclusions of this article are included within the article (and its additional files), at \url{https://openmortality.org} (available upon request) and at \url{https://github.com/cghr-toronto/healsl-gpt-paper}. Verbal Autopsy (VA) and narrative data by age group and survey rounds 1 and 2 available at \url{https://openmortality.org/dataset/heal-sl}. Cause of death code mappings to convert between ICD-10, WVA-2016, and CGHR-10 codes available at \url{https://openmortality.org/dataset/icd}. Model evaluation result files at \url{https://github.com/cghr-toronto/healsl-gpt-paper/tree/main/data}.

\subsection*{Code availability}

All code for this paper is available at \url{https://github.com/cghr-toronto/healsl-gpt-paper}.

\subsection*{Authors' contributions}

PJ and PB are the study Principal Investigators. ATA and RK implemented the data collection procedures. RW, and TKSN processed, documented, and prepared the data. RW, ASL, and RK ran the models. RW wrote the paper and conducted the analysis. AB and RCM provided medical domain guidance and feedback. All authors reviewed the results and contributed to the report. All authors read and approved the final manuscript.

\begin{appendices}

% Fix figure hyperrefs for appendix
\setcounter{figure}{0}
\renewcommand{\thefigure}{\thesection\arabic{figure}}
\renewcommand{\theHfigure}{\thesection\arabic{figure}}

%\section{Section title of first appendix}\label{secA1}

%An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.
    
%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\section{Details on Methods}\label{app-methods}

This section provides additional details on the methods described in Section \ref{methods}. An overview of the methods used in this study is seen in Figure \ref{fig-methods} as a five-step process. Section \ref{app-methods-data} provides details on the preprocessed data used for modelling. Section \ref{app-methods-model} describes the data and parameter inputs and outputs for each model, while Section \ref{app-methods-eval} details the evaluation of model outputs at the individual and population level across different CODs, age groups, and age ranges.

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{fig-methods.pdf}
\caption{Case study methods.}\label{fig-methods}
\end{figure}

\subsection{CGHR-10 Physician Agreed Records}\label{app-methods-data}

Initially, 11,920 records were collected from dual-coded EVA in the HEAL-SL study. Physicians were able to assign CODs for 11,820 of the 11,920 records, where 100 of these records could not be assigned a COD due to missing or inadequate information (e.g. low quality narrative, data loss). The 11,820 physician coded records were further filtered for records where both physicians agreed on the assigned codes (records that were not reconciled or adjudicated) resulting in 6942 physician agreed records (based on comparisons using CMEA-10 codes, see Additional File 2). The 6942 records were converted into CGHR-10 codes (see Additional File 1) that generalized ICD-10 codes into 19, 10, and 7 categories for the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups. After conversion, a final total of 6939 physician agreed records (3826 adult, 2636 child, and 477 neonatal) were used for modelling and performance evaluation, where three records were removed as their ICD-10 codes did not have a matching CGHR-10 code.

The 6939 physician agreed records were collected using VA from the HEAL-SL study between 2019-2022, where records were collected using nation wide samples across Sierra Leone provinces seen in Figure \ref{fig-map}. More populous areas (e.g. southern and north east provinces with $~$197,000 and $~$135,000 population respectively) had more sampling areas versus less populous areas (e.g. north west and eastern provinces with $~$50,000 and $~$69,000 people respectively). The distribution of the case study data are shown by CGHR-10 causes of death in Table \ref{tab-data-cod}. All age groups had relatively evenly distributed female and male records (44-55\% of 6939 records each). Across CODs, there were noticeably more female records for cancers (65\%), and maternal conditions (100\%), while more male records for chronic respiratory diseases (61\%), other noncommunicable diseases (61\%), other injuries (77\%), road and transport injuries (71\%), and tuberculosis (68\%). Most records were coded by physicians as malaria for adults (20\%) and children (52\%), and stillbirth (36\%) and neonatal infections (21\%) for neonates. Suicide, congenital anomalies, nutritional deficiencies, and other had low sample sizes for each age group (\textless 1\% of total records for each age group). Table \ref{tab-data-age} shows the distribution of the study data by age ranges. Across age ranges, there were more male records for 50-59 years (60-62\%), while all other records had between 49-59\% female and male records. Most records were in the 65-69 years age range for adults (15\%), 1-5 years for children (62\%), and 0-6 days for neonates (83\%).

\begin{figure}[H]
\centering
\includegraphics[width=.75\textwidth]{fig-map.pdf}
\caption{Case study data sampling areas.}\label{fig-map}
\end{figure}

\begin{sidewaystable}
\caption{Case study data by cause of death.}\label{tab-data-cod}
\begin{tabular*}{\textheight}{@{\extracolsep\fill}lllll}
    \toprule%
    Age Group  &  CGHR-10 Cause of Death (COD)  &  Female  &  Male  &  Total  \\
    \midrule
    \makecell[l]{\\Adult (n=3826, 55.1\%, 18 CODs)\\Adult Female (n=1681, 43.9\%)\\Adult Male (n=2145, 56.1\%)}  &  Acute Respiratory Infections  &  48 (45.7\%)  &  57 (54.3\%)  &  105 (2.7\%)  \\ 
        &  Cancers  &  32 (65.3\%)  &  17 (34.7\%)  &  49 (1.3\%)  \\ 
        &  Chronic Respiratory Diseases  &  29 (38.7\%)  &  46 (61.3\%)  &  75 (2\%)  \\ 
        &  Diabetes Mellitus  &  14 (51.9\%)  &  13 (48.1\%)  &  27 (0.7\%)  \\ 
        &  Diarrhoeal Diseases  &  102 (49.8\%)  &  103 (50.2\%)  &  205 (5.4\%)  \\ 
        &  Ill-Defined  &  56 (47.9\%)  &  61 (52.1\%)  &  117 (3.1\%)  \\ 
        &  Ischemic Heart Disease  &  89 (53\%)  &  79 (47\%)  &  168 (4.4\%)  \\ 
        &  Liver And Alcohol Related Diseases  &  58 (45.3\%)  &  70 (54.7\%)  &  128 (3.3\%)  \\ 
        &  Malaria  &  372 (46.6\%)  &  427 (53.4\%)  &  799 (20.9\%)  \\ 
        &  Maternal Conditions  &  130 (100\%)  &  N/A  &  130 (3.4\%)  \\ 
        &  Other Cardiovascular Diseases  &  59 (55.1\%)  &  48 (44.9\%)  &  107 (2.8\%)  \\ 
        &  Other Noncommunicable Diseases  &  160 (38.6\%)  &  254 (61.4\%)  &  414 (10.8\%)  \\ 
        &  Other Injuries  &  83 (23.2\%)  &  274 (76.8\%)  &  357 (9.3\%)  \\ 
        &  Road And Transport Injuries  &  73 (29.1\%)  &  178 (70.9\%)  &  251 (6.6\%)  \\ 
        &  Stroke  &  147 (44.4\%)  &  184 (55.6\%)  &  331 (8.7\%)  \\ 
        &  Suicide  &  N/A  &  3 (100\%)  &  3 (0.1\%)  \\ 
        &  Tuberculosis  &  54 (31.6\%)  &  117 (68.4\%)  &  171 (4.5\%)  \\ 
        &  Unspecified Infections  &  175 (45\%)  &  214 (55\%)  &  389 (10.2\%)  \\ 
    \makecell[l]{\\Child (n=2636, 38\%, 9 CODs)\\Child Female (n=1290, 48.9\%)\\Child Male (n=1346, 51.1\%)}  &  Congenital Anomalies  &  1 (100\%)  &  N/A  &  1 (0\%)  \\ 
        &  Diarrhoeal Diseases  &  79 (45.1\%)  &  96 (54.9\%)  &  175 (6.6\%)  \\ 
        &  \makecell[l]{Epilepsy, Leukaemia, And\\Other Noncommunicable Diseases}  &  61 (53.5\%)  &  53 (46.5\%)  &  114 (4.3\%)  \\ 
        &  Ill-Defined  &  34 (48.6\%)  &  36 (51.4\%)  &  70 (2.7\%)  \\ 
        &  Injuries  &  51 (37.8\%)  &  84 (62.2\%)  &  135 (5.1\%)  \\ 
        &  Malaria  &  680 (49.2\%)  &  702 (50.8\%)  &  1382 (52.4\%)  \\ 
        &  Nutritional Deficiencies  &  7 (63.6\%)  &  4 (36.4\%)  &  11 (0.4\%)  \\ 
        &  Other Infections  &  338 (50.7\%)  &  329 (49.3\%)  &  667 (25.3\%)  \\ 
        &  Pneumonia  &  39 (48.1\%)  &  42 (51.9\%)  &  81 (3.1\%)  \\ 
    \makecell[l]{\\Neonate (n=477, 6.9\%, 7 CODs)\\Neonate Female (n=227, 47.6\%)\\Neonate Male (n=250, 52.4\%)}  &  Birth Asphyxia And Birth Trauma  &  38 (36.9\%)  &  65 (63.1\%)  &  103 (21.6\%)  \\ 
        &  Congenital Anomalies  &  2 (100\%)  &  N/A  &  2 (0.4\%)  \\ 
        &  Ill-Defined  &  11 (47.8\%)  &  12 (52.2\%)  &  23 (4.8\%)  \\ 
        &  Neonatal Infections  &  49 (49.5\%)  &  50 (50.5\%)  &  99 (20.8\%)  \\ 
        &  Other  &  2 (40\%)  &  3 (60\%)  &  5 (1\%)  \\ 
        &  Prematurity And Low Birthweight  &  39 (53.4\%)  &  34 (46.6\%)  &  73 (15.3\%)  \\ 
        &  Stillbirth  &  86 (50\%)  &  86 (50\%)  &  172 (36.1\%)  \\
    \botrule
\end{tabular*}
\end{sidewaystable}

\begin{table}
\caption{Case study data by age range.}\label{tab-data-age}
\begin{tabular}{@{}lllll@{}}
\toprule%
    Age Group  &  Age Range  &  Female  &  Male  &  Total  \\
    \midrule
        \makecell[l]{\\Adult (n=3826, 55.1\%)\\Adult Female (n=1681, 43.9\%)\\Adult Male (n=2145, 56.1\%)}  &  10-14 Years  &  51 (37.8\%)  &  84 (62.2\%)  &  135 (3.5\%)  \\ 
        &  15-19 Years  &  115 (42.8\%)  &  154 (57.2\%)  &  269 (7\%)  \\ 
        &  20-24 Years  &  146 (53.1\%)  &  129 (46.9\%)  &  275 (7.2\%)  \\ 
        &  25-29 Years  &  159 (45.2\%)  &  193 (54.8\%)  &  352 (9.2\%)  \\ 
        &  30-34 Years  &  174 (50.9\%)  &  168 (49.1\%)  &  342 (8.9\%)  \\ 
        &  35-39 Years  &  153 (45.4\%)  &  184 (54.6\%)  &  337 (8.8\%)  \\ 
        &  40-44 Years  &  134 (42\%)  &  185 (58\%)  &  319 (8.3\%)  \\ 
        &  45-49 Years  &  148 (47\%)  &  167 (53\%)  &  315 (8.2\%)  \\ 
        &  50-54 Years  &  134 (39.6\%)  &  204 (60.4\%)  &  338 (8.8\%)  \\ 
        &  55-59 Years  &  96 (37.6\%)  &  159 (62.4\%)  &  255 (6.7\%)  \\ 
        &  60-64 Years  &  128 (40.8\%)  &  186 (59.2\%)  &  314 (8.2\%)  \\ 
        &  65-69 Years  &  243 (42.3\%)  &  332 (57.7\%)  &  575 (15\%)  \\ 
        \makecell[l]{\\Child (n=2636, 38\%)\\Child Female (n=1290, 48.9\%)\\Child Male (n=1346, 51.1\%)}  &  1-5 Months  &  146 (47.4\%)  &  162 (52.6\%)  &  308 (11.7\%)  \\ 
        &  6-11 Months  &  160 (50.8\%)  &  155 (49.2\%)  &  315 (11.9\%)  \\ 
        &  1-5 Years  &  822 (50.3\%)  &  811 (49.7\%)  &  1633 (61.9\%)  \\ 
        &  6-11 Years  &  162 (42.6\%)  &  218 (57.4\%)  &  380 (14.4\%)  \\ 
        \makecell[l]{\\Neonate (n=477, 6.9\%)\\Neonate Female (n=227, 47.6\%)\\Neonate Male (n=250, 52.4\%)}  &  0-6 Days  &  184 (46.6\%)  &  211 (53.4\%)  &  395 (82.8\%)  \\ 
        &  7-27 Days  &  43 (52.4\%)  &  39 (47.6\%)  &  82 (17.2\%)  \\
    \botrule
\end{tabular}
\end{table}

\subsection{Modelling Details}\label{app-methods-model}

Each model (GPT-3.5, GPT-4, InSilicoVA, and InterVA-5) required pre-processing of the 6939 records into input data, and standardization of output COD codes from models for performance evaluation as not all models produced comparable codes across outputs. Although each model can assign multiple CODs per record, only the first generated COD response from GPT-3.5 and GPT-4, and the most probable COD from InterVA-5 and InSilicoVA were used for evaluation. Section \ref{app-methods-input} describes the input data and parameters for each model, while Section \ref{app-methods-output} details the outputs from running each model.

\subsubsection{Input Data and Preprocessing}\label{app-methods-input}

For GPT-3.5 and GPT-4, 6939 text prompts were generated for each physician agreed record as input to instruct the models to assign CODs based on the open narratives. Two types of text prompts were used: user prompts and system prompts. System prompts contained textual instructions to assign the role of a physician ICD-10 coder with expertise in Sierra Leone. The following system prompt was used for each record:

\begin{lstlisting}
You are a physician with expertise in determining underlying causes of death in Sierra Leone by assigning the most probable ICD-10 code for each death using verbal autopsy narratives. Return only the ICD-10 code without description. E.g. A00. If there are multiple ICD-10 codes, show one code per line.
\end{lstlisting}

\noindent User prompts contained textual instructions to perform coding of VA records based on the age, sex, and narrative of the deceased. The following template was used to generate user prompts for each record, where \verb|<age>| and \verb|<sex>| from the questionnaire, and \verb|<narrative>| from the narratives, were replaced with values from the data:

\begin{lstlisting}
Determine the underlying cause of death and provide the most probable ICD-10 code for a verbal autopsy narrative of a <age> years old <sex> death in Sierra Leone:  <narrative>
\end{lstlisting}

\noindent For InterVA-5 and InSilicoVA, the standardized questionnaire data from the HEAL-SL EVA were first converted into 2016 World Health Organization (WHO) VA questionnaire revision 1.5.1 Open Data Kit (ODK) format \citep{worldhealthorganizationODKVerbalAutopsy2022,nafundiODKCollectData2023} consisting of 526 variables \citep{dipasqualeReleaseODK20162016}, followed by further conversion into OpenVA format \citep{liOpenVAToolkitVerbal2023} consisting of 353 variables \citep{byassInterVA5UserGuide2020} using the \verb|pyCrossVA| version 0.97 Python package \citep{thomasPycrossvaPrepareData}. The 6939 records were all converted into OpenVA formatted records for InterVA-5 and InSilicoVA.

\subsubsection{Models and Parameters}\label{methods-models-params}

The GPT-3.5 and GPT-4 Application Programming Interface (API) was accessed using Python version 3.11.4 and used to assign CODs for each record. GPT-3.5 used the \verb|gpt-3.5-turbo| model, while GPT-4 used the \verb|gpt-4-0613| model. The parameter \verb|temperature| for GPT-3.5 and GPT-4, representing the sampling temperature ranging from 0 to 2 (default of 1), was set to 0 to produce more deterministic outputs \citep{openaiOpenAIPlatformAPI2024}. Higher values closer to 2 may produce less deterministic outputs, while lower values closer to 0 produce more deterministic outputs.

The \verb|openVA| R package was used to run InterVA-5 and InSilicoVA models to assign CODs for each record in R version 4.3.1. The \verb|openVA| package version 1.1.1 used dependent packages \verb|InterVA5| version 1.1.3 and \verb|InSilicoVA| version 1.4.0. The \verb|Nsim| (number of iterations to run) parameter \citep{liInSilicoVAProbabilisticVerbal2022} for InSilicoVA was set to 9500, while the \verb|HIV| (level of prevalence of human immunodeficiency virus) and \verb|Malaria| (level of prevalence of Malaria) parameters \citep{thomasInterVA5ReplicateAnalyse2021} for InterVA-5 were both set to \verb|'h'| (high) reflecting HIV and Malaria disease assumptions in Sierra Leone \citep{yendewaHIVAIDSSierra2018,walkerMalariaMorbidityMortality2015}. Note that the default value of \verb|Nsim=10000| for InSilicoVA ran until 9500 iterations before it stopped due to errors, thus \verb|Nsim=9500| was used and ran successfully for all iterations.

\subsubsection{Output Data and Code Conversion}\label{app-methods-output}

Of the 6939 input records, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA were able to assign CODs for 6939 (100\%), 6935 (\textgreater 99\%), 6830 (98\%), 6830 (98\%) records respectively. All 6830 (100\%) InterVA-5 and InSilicoVA records with WHO VA 2016 v1.5 output codes \citep{worldhealthorganizationVerbalAutopsyStandards2016} were converted into ICD-10 codes respectively. After all model outputs were converted to ICD-10 codes, they were further converted to CGHR-10 codes. The 6939 GPT-3.5 and 6935 GPT-4 output records with ICD-10 codes were converted into 6930 (\textgreater 99\%) and 6931 (\textgreater 99) records with CGHR-10 codes, where \textless 1\% (9 and 8) records did not have matching CGHR-10 codes respectively. The 6830 InterVA-5 and InSilicoVA records with ICD-10 codes were converted into 6802 (\textgreater 99\%) and 6726 (98\%) records with CGHR-10 codes respectively, where 28 (\textless 1\%) and 104 (1\%) of records could not be converted into CGHR-10 codes.

\subsection{Performance Evaluation Details}\label{app-methods-eval}

The performance of GPT-3.5, GPT-4, InSilicoVA, and InterVA-5 models were evaluated with metrics at the population and individual level by comparing their CGHR-10 COD outputs for 6939 records to physician COD assignments. Section \ref{app-methods-csmfa} describes CSMF accuracy in detail for evaluating models on the population level,  Section \ref{app-methods-pccc} describes PCCC for evaluating models on the individual level. Records that were assigned a COD by physicians, but not by a model were considered to be an incorrect COD assignment by the model. CSMF accuracy and PCCC were calculated for each model overall and by three age groups (adult, child, and neonatal), then further into age ranges and COD for each age group.

\subsubsection{Cause Specific Mortality Fraction (CSMF) Accuracy}\label{app-methods-csmfa}

CSMF accuracy measures the performance of models at the population level, comparing distributions of CODs between the physicians and the models \citep{murrayRobustMetricsAssessing2011}. To calculate CSMF accuracy, we first calculate $CSMF_j$ as is the fraction of physician or model records for cause $j$, given by dividing the number of records for cause $j$ with the total number of records as seen in Equation \ref{eq-csmf}. Then, the $CSMFMaximumError$, representing the worst possible model, is calculated using Equation \ref{eq-csmferr}. Finally, the CSMF accuracy is given by Equation \ref{eq-csmfa}, where $k$ is the number of causes, $j$ is a cause, $CSMF^{true}_j$ is the true physician CSMF for cause $j$, and $CSMF^{pred}_j$ is the prediction model CSMF for cause $j$. CSMF accuracy ranges from 0 to 1, where 1 means that the model completely matched the physician COD distribution and 0 means that it did not match the distribution at all.

\begin{equation}\label{eq-csmf}
    CSMF_j = Records_j / Records
\end{equation}

\begin{equation}\label{eq-csmferr}
    CSMFMaximumError = 2(1 - Min(CSMF^{true}_j)
\end{equation}

\begin{equation}\label{eq-csmfa}
    CSMFAccuracy = 1 - \frac{\sum^{k}_{j=1}|CSMF^{true}_j - CSMF^{pred}_j|}{CSMFMaximumError}
\end{equation}

\subsubsection{Partial Chance Corrected Concordance (PCCC)}\label{app-methods-pccc}

PCCC measures the performance of models at the individual level, comparing COD assignments between the physicians and models on a record by record basis, correcting for COD assignments made purely by chance \citep{murrayRobustMetricsAssessing2011}. PCCC is given by Equation \ref{eq-pccc}, where $k$ is the number of top COD assignments from the model to consider, $N$ is number of causes, and $C$ is fraction of records where the physician COD assignment is one of the top COD assignments from the model. For this study, we set $k$ to 1, making $C$ equivalent to the fraction of true positives $TP$ or records where the physician COD assignment is equal to the model COD assignment as shown in Equation \ref{eq-pccc-c}. Higher PCCC values closer to 1 indicate that model COD assignments are similar to physician COD assignments, while values closer to 0 indicate that model COD assignments are not similar to physicians.

\begin{equation}\label{eq-pccc-c}
    C = \frac{TP}{Records}
\end{equation}

\begin{equation}\label{eq-pccc}
    PCCC(k) = \frac{C - \frac{k}{N}}{1 - \frac{k}{N}}
\end{equation}

\section{Experiment on Repeated Runs of GPT-3.5}\label{app-reprod}

A short experiment was conducted to test the consistency of GPT-3.5 outputs repeated on the same record. 100 records, sampled randomly with approximately equal proportions across age groups, CODs, and survey rounds 1 and 2, were used to test repeated runs of GPT-3.5. Each record from the 100 records was rerun 10 times through GPT-3.5, resulting in ten COD outputs per record. The ICD-10 codes were then converted to CGHR-10 codes and tested for consistency, where completely inconsistent results had different ICD-10 or CGHR-10 codes for each of the 10 reruns (1 times+), and completely consistent results had the same ICD-10 or CGHR-10 code for all 10 reruns (10 times), on the same record.

The results are shown in Table \ref{tab-reprod}. For all 100 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code for the same record 5 times or more out of 10. For 66 and 79 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively for each record. This number increases to 94 (from 66) and 96 (from 79) when reducing the number of times out of 10 that GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively. Thus, GPT-3.5 does not always produce the same outputs when repeated on the same record (10 times out of 10), even when the temperature is set to 0, but does so for more than half the records. For most records (more than 90\%), GPT-3.5 will produce the same outputs for the same record 7 times or more out of 10.

\begin{table}[!htbp]
    \caption{Records with same GPT-3.5 outputs based on 10 repeated reruns of 100 records}\label{tab-reprod}%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Times with Same GPT-3.5 Outputs & ICD-10 Records & CGHR-10 Records\\

    \midrule
    
    1 times+ (inconsistent) & 100  & 100\\
    2 times+ & 100  & 100\\
    3 times+ & 100  & 100\\
    4 times+ & 100  & 100\\
    5 times+ & 100  & 100\\
    6 times+ & 94  & 96\\
    7 times+ & 92  & 94\\
    8 times+ & 86  & 91\\
    9 times+ & 79  & 86\\
    10 times (consistent) & 66  & 79\\

    \botrule
    \end{tabular}
\end{table}

\section{Exploration of Neonatal Infections}\label{app-misclass}

An exploration of neonatal infections (n=99, 21\% of 477 records) was done to understand the low performance of GPT models (0.23 PCCC) for neonatal infections, and high performance of InSilicoVA (0.87 PCCC). In Table \ref{tab-misclass}, about half the records were assigned correctly, and a majority (n=33, 33\%) of the other records were misclassified as other, while prematurity and low birthweight, birth asphyxia \& birth trauma, and ill-defined make up the rest. On closer inspection of the 49 records with misclassified assignments, the ICD-10 code R50 was assigned in 20 records. R50 falls under unspecified infections in the adult CGHR-10 category, but in the other category for neonates. B50 was assigned in 4 records, falling under malaria, but a similar B54 falls under neonatal infections. P81 was assigned in 3 records, referring to fever of unknown origin, which falls under other, and P07 was assigned in 7 records, falling under prematurity and low birthweight.

In most misclassified records, there is mention of infections, but the misclassifications occur due to the finer details of the ICD-10 code classifications, the categorization decisions of the CGHR-10 codes, and missing information from the questionnaire. For R50 misclassifications, GPT may have confused descriptions across adult and neonatal age groups. Using the same definition of R50, but in the context of neonates, may result in codes closer to neonatal infections (e.g. B54). For B50 misclassifications, the similar B54 was categorized in CGHR-10 as neonatal infections, but B50 was categorized as other. P81 refers to fever of unknown origin, which may be difficult to differentiate between infection and other causes without information from the questionnaire. P07 refers to prematurity and low birthweight, where GPT initially assigned P07 as the age of the neonate was mentioned first, but later mentions infections as an alternative following the order of information in the narratives. Thus, it may be possible to improve the performance GPT models using better prompts based on the context of VA manuals and CGHR-10 codes, and by also including questionnaire information in the prompts.

\begin{table}[!htbp]
    \caption{GPT-4 CGHR-10 COD assignment for physician coded neonatal infections records.}\label{tab-misclass}%
    \begin{tabular}{@{}ll@{}}
    \toprule
    GPT-4 Assigned Cause of Death (CGHR-10) & Records\\

    \midrule
    
    Neonatal infections & 50 (51\%)\\
    Other & 33 (33\%)\\
    Prematurity and low birthweight & 9 (9\%)\\
    Birth asphyxia \& birth trauma & 5 (6\%)\\
    Ill-defined & 2 (2\%) \\

    \midrule

    Total & 99 (100\%)\\

    \botrule
    \end{tabular}
\end{table}

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\clearpage
\bibliography{bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
