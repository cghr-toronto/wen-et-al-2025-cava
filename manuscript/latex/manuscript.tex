% Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
\documentclass[sn-vancouver,Numbered,referee]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>
\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{lstautogobble}%
\usepackage{makecell}%
%%%%

\lstset{
    texcl=true,
    basicstyle=\small\sf,
    commentstyle=\small\rm,
    mathescape=true,
    escapeinside={(*}{*)},
    breaklines=true,
    breakindent=0.5pt
}

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
%%\theoremstyle{thmstyleone}%
%%\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
%%\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

%%\theoremstyle{thmstyletwo}%
%%\newtheorem{example}{Example}%
%%\newtheorem{remark}{Remark}%

%%\theoremstyle{thmstylethree}%
%%\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Computer Assisted Verbal Autopsy: Comparing Large Language Models to Physicians for Assigning Causes to 6939 Deaths in Sierra Leone from 2019-2022]{Computer Assisted Verbal Autopsy: Comparing Large Language Models to Physicians for Assigning Causes to 6939 Deaths in Sierra Leone from 2019-2022}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Richard} \sur{Wen}}\email{richard.wen@utoronto.ca}

\author[1,2]{\fnm{Anteneh Tesfaye} \sur{Assalif}}\email{antenehta@gmail.com}

\author[1]{\fnm{Andy Sze-Heng} \sur{Lee}}\email{andylee@cs.toronto.edu}

\author[1]{\fnm{Rajeev} \sur{Kamadod}}\email{rajeevk@kentropy.com}

%\equalcont{These authors contributed equally to this work.}

\author[1]{\fnm{Asha} \sur{Behdinan}}\email{asha.behdinan@mail.utoronto.ca}

\author[1]{\fnm{Ronald} \sur{Carshon-Marsh}}\email{ronald.carshonmarsh@mail.utoronto.ca}

\author[1]{\fnm{Catherine} \sur{Meh}}\email{catherine.meh@unityhealth.to}

\author[1]{\fnm{Thomas Kai Sze} \sur{Ng}}\email{kaisze.ng@unityhealth.to}

\author[1]{\fnm{Patrick} \sur{Brown}}\email{patrick.brown@utoronto.ca}

\author[1]{\fnm{Prabhat} \sur{Jha}}\email{prabhat.jha@utoronto.ca}

\author[2]{\fnm{Rashid} \sur{Ansumana}}\email{rashidansumana@gmail.com}

\affil*[1]{\orgdiv{Centre for Global Health Research, St. Michael's Hospital}, \orgname{Unity Health Toronto and University of Toronto}, \orgaddress{\street{30 Bond St}, \city{Toronto}, \postcode{M5B 1W8}, \state{Ontario}, \country{Canada}}}

\affil[2]{\orgdiv{School of Community Health Sciences}, \orgname{Njala University}, \orgaddress{\city{Bo}, \country{Sierra Leone}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{
\textbf{Background:} Verbal autopsies (VAs) collect information on deaths occurring outside traditional healthcare settings to estimate representative Causes of Death (CODs). Current computer models assign CODs at population-level accuracy comparable to physicians, but perform poorly at the individual level, largely due to reliance on structured questionnaire data and neglect of narrative free text. Recently, the large language model ChatGPT-4 demonstrated human-level performance on professional and academic benchmarks. While ChatGPT-4 shows promise in COD assignment, its application to VA narratives has not yet been evaluated.

\textbf{Methods:} We analyzed 6,939 VA records from Sierra Leone (2019–2022) to compare four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, against physician-assigned CODs at population and individual levels. GPT models used narratives, whereas InterVA-5 and InSilicoVA relied on questionnaires. CODs were grouped into 19, 10, and 7 categories for adult, child, and neonatal deaths. Cause Specific Mortality Fraction (CSMF) accuracy and Partial Chance Corrected Concordance (PCCC) were used to assess population and individual level agreement with physician coding respectively, stratified by age and COD.

\textbf{Results:} GPT-4 outperformed all models overall (PCCC=0.61), followed by GPT-3.5 (0.56) and InSilicoVA/InterVA-5 (0.44). GPT-4 achieved the highest PCCC for adult and neonatal deaths (0.64 and 0.58), with GPT-3.5 for child deaths (0.54). Across ages, model performance increased from 1 month to 14 years ($\sim$0.10–0.75 PCCC) and declined from 15 to 69 years ($\sim$0.70–0.35). GPT-4, GPT-3.5, and InSilicoVA achieved the highest PCCC in 17, 9, and 4 of the 30 CODs, respectively. At the population level, all models achieved comparable CSMF accuracies (0.74–0.79).

\textbf{Conclusion:} All models performed similarly at the population level, but GPT models and InSilicoVA showed greater performance for specific CODs at the individual level. GPT models demonstrated improvements over InterVA-5 and InSilicoVA models. This study provides foundational evidence for integrating computer models to assist physicians with alternative diagnoses, helping reduce ill-defined codes and improve agreement in COD assignment.
}


%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Cause of Death, Physicians, Computer-Assisted Diagnosis, Artificial Intelligence, Natural Language Processing, Machine Learning, Mortality, Surveillance, Mathematical Models, Global Health}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Background}\label{background}

Every year, 41 million people died prematurely from noncommunicable diseases, accounting for 74\% of all deaths globally \citep{worldhealthorganizationNonCommunicableDiseases2019}. While most of these deaths are preventable, effective intervention requires evidence-based resource allocation that targets high-risk populations \citep{benzigerGlobalBurdenDisease2016}. Reliable mortality counts and accurate Cause of Death (COD) data are essential for guiding public health policy and reducing premature mortality \citep{lawnMillionNeonatalDeaths2010,lassiCommunityBasedIntervention2015,liuExcessMortalityPersons2017,ewigCommunityacquiredPneumoniaEmergency2011}. However, civil registration and vital statistics systems remain incomplete in many low-income countries. Fewer than half of all deaths are registered, and among these, only 8\% have an assigned COD \citep{worldhealthorganizationSCOREHealthData2021}. To address this gap, Verbal Autopsy (VA) has been deployed as a scalable method for collecting mortality data and assigning likely CODs, particularly for deaths that occur outside of healthcare facilities, which account for more than half of all deaths \citep{desavignyIntegratingCommunitybasedVerbal2017,thomasVerbalAutopsyHealth2018,rampatigeSystematicReviewStatistics2014,adairWhoDiesWhere2021}.

VA involves two major components: survey and COD assignment \citep{worldhealthorganizationVerbalAutopsyStandards2023,chandramohanEstimatingCausesDeath2021,worldhealthorganizationVerbalAutopsyStandards2007}. In the survey component, trained interviewers use structured questionnaires and open narrative prompts to gather data from relatives or close contacts of the deceased. In the COD assignment component, physicians review these data to determine the most likely COD. However, reliance on physician assignment has been criticized for limited reproducibility and subjectivity \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005,mccormickProbabilisticCauseofdeathAssignment2016b,morrisFactorsAssociatedPhysician2010,solemanVerbalAutopsyCurrent2006}. To overcome these limitations, automated Computer Coded Verbal Autopsy (CCVA) methods such as InterVA \citep{byassIntegratedApproachProcessing2019} and InSilicoVA \citep{mccormickProbabilisticCauseofdeathAssignment2016b} have been developed. These models offer scalable and reproducible alternatives and have demonstrated comparable performance to physicians at the population level. However, their performance at the individual level remains limited \citep{jhaAutomatedPhysicianAssignment2019,leitaoComparisonPhysiciancertifiedVerbal2014,desaiPerformanceFourComputercoded2014,tungaVerbalAutopsyModels2021,otiVerbalAutopsyInterpretation2010}, while their reliance on structured questionnaire data often omits open narrative text, which can contain additional contextual and chronological information that may improve diagnostic accuracy \citep{jebleeAutomaticallyDeterminingCause2019,blancoExtractingCauseDeath2021,kingQualityDiagnosticValue2016}.

Recent advances in large language models (LLMs), trained on vast textual datasets using deep learning methods, have significantly improved natural language processing (NLP) capabilities. These include tasks such as question answering, code generation, and medical reasoning based on free text \citep{changSurveyEvaluationLarge2023,lundChattingChatGPTHow2023,svyatkovskiyIntelliCodeComposeCode2020,hauptAIGeneratedMedicalAdvice2023}. ChatGPT, developed by OpenAI and released in 2022, is a widely accessible LLM capable of generating human-like responses to natural language queries. Earlier versions (GPT-1 to GPT-3) scaled from 117 million to 175 billion parameters and were trained on data ranging from 5 GB to 45 TB \citep{wuBriefOverviewChatGPT2023}. In 2023, ChatGPT-4 was introduced, achieving human-level performance on a range of academic and professional benchmarks \citep{openaiGPT4TechnicalReport2023}. Given the underutilization of narrative free text in VA analysis and the capabilities of LLMs in processing such data, we conducted a study using VA records from Sierra Leone (2019–2022) to compare four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, against physician-assigned CODs. This work aims to evaluate the potential of LLMs in enhancing COD assignment from narrative data in low-resource settings.

\section{Methods}\label{methods}

This study outlines the methodology used to compare cause of death (COD) assignments from four models, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA, with physician-determined CODs, as summarized in Figure \ref{fig-methods-brief}. The dataset was first filtered to include only records with physician agreement, as described in Section \ref{methods-data}. Section \ref{methods-models} details the input formats and output structures of the four models. Section~\ref{methods-eval} presents the evaluation framework, which compares model outputs to physician-assigned CODs using both population-level and individual-level performance metrics. Additional details are provided in Appendix \ref{app-methods}.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-methods-brief.pdf}
\caption{Study methods.}\label{fig-methods-brief}
\end{figure}

\subsection{Verbal Autopsy (VA) Data}\label{methods-data}

A total of 11,920 verbal autopsy (VA) records were obtained from the HEAL-SL study \citep{njalauniversityHealthySierraLeone2023,carshon-marshChildMaternalAdult2022}, which employed dual-coded Electronic Verbal Autopsy (EVA). Each record was independently reviewed by two randomly selected physicians, who assigned COD codes based on the International Classification of Diseases, 10th Revision (ICD-10) \citep{worldhealthorganizationICD10InternationalStatistical2011}. Agreement between physician-assigned CODs was evaluated using Central Medical Evaluation Agreement 10 (CMEA-10) codes, which group related ICD-10 codes into broader, clinically similar categories \citep{aleksandrowiczPerformanceCriteriaVerbal2014} (see Additional File 1). If both codes fell within the same CMEA-10 group, the record was considered in agreement. Disagreements entered a reconciliation phase, where each physician was shown both the assigned codes and the reasoning from the other physician. Physicians could then (1) retain their original code, (2) adopt the other physician’s code, or (3) assign a new code. Records that remained unresolved proceeded to adjudication, where a senior physician reviewed all reasoning and assignments and issued a final COD.

To ensure comparability with physician coding, only records with physician agreement were used in this study, as such cases provide higher confidence in the COD assignment \citep{barnettComparativeAccuracyDiagnosis2019,morrisFactorsAssociatedPhysician2010,hsiaoFactorsAssociatedPhysician2012}. From the original dataset, 6,942 records met this criterion. All ICD-10 codes were then standardized to CGHR-10 categories (see Appendix \ref{app-cghr10}), which group causes into 19, 10, and 7 categories for adults (12–69 years), children (28 days to 11 years), and neonates (under 28 days), respectively. After excluding three records without a valid CGHR-10 category, a total of 6,939 physician-agreed records (3,826 adult, 2,636 child, and 477 neonatal) were used for model comparison and performance evaluation. Further details on data preprocessing are provided in Appendix \ref{app-methods-data}, with COD and age group distributions summarized in Tables \ref{tab-data-cod} and \ref{tab-data-age}.

\subsection{Modelling}\label{methods-models}

Four computational models were used to assign causes of death (CODs) for each of the 6,939 physician-agreed verbal autopsy (VA) records: GPT-3.5, GPT-4, InterVA-5, and InSilicoVA. InterVA-5 and InSilicoVA are widely used statistical models within the OpenVA framework for COD assignment in VAs \citep{murrayUsingVerbalAutopsy2014, otiVerbalAutopsyInterpretation2010, benaraEvaluationMethodsAssigning2023, chandramohanEstimatingCausesDeath2021, tungaVerbalAutopsyModels2021, leitaoComparisonPhysiciancertifiedVerbal2014, jhaAutomatedPhysicianAssignment2019, liOpenVAToolkitVerbal2023}. InterVA-5 applies a Bayesian probabilistic approach, using a standardized set of symptoms and expert-derived conditional probabilities to assign the most likely COD based on maximum probability \citep{byassIntegratedApproachProcessing2019, byassStrengtheningStandardisedInterpretation2012, bayesEssaySolvingProblem1958}. InSilicoVA extends this approach by incorporating a hierarchical Bayesian framework and Markov Chain Monte Carlo (MCMC) methods \citep{brooksMarkovChainMonte1998, chibMarkovChainMonte2001, hanMarkovChainMonte2001}, allowing for quantification of uncertainty, individual-level probability estimates, and the integration of additional data sources \citep{mccormickProbabilisticCauseofdeathAssignment2016b}.GPT-3.5 \citep{brownLanguageModelsAre2020} and GPT-4 \citep{openaiGPT4TechnicalReport2023} are large language models (LLMs) based on transformer architectures \citep{vaswaniAttentionAllYou2017}. These models are trained using reinforcement learning from human feedback \citep{ouyangTrainingLanguageModels2022, christianoDeepReinforcementLearning2017, stiennonLearningSummarizeHuman2020, wirthSurveyPreferencebasedReinforcement2017}, enabling them to follow natural language instructions and generate human-level responses. GPT-4 introduces improvements over GPT-3.5, including more recent training data, enhanced reasoning capabilities, and multimodal input-output functionality (e.g. text, image, voice) \citep{wuBriefOverviewChatGPT2023}.

For GPT-3.5 and GPT-4, the following user prompt was used to instruct each model to produce COD assignments as ICD-10 codes, where \verb|<age>| and \verb|<sex>| from the questionnaire, and \verb|<narrative>| from the narratives, were replaced with values from the data:

\begin{lstlisting}
Determine the underlying cause of death and provide the most probable ICD-10 code for a verbal autopsy narrative of a <age> years old <sex> death in Sierra Leone:  <narrative>
\end{lstlisting}

\noindent InterVA-5 and InSilicoVA used structured questionnaire data, which were converted into OpenVA-compatible format \citep{liOpenVAToolkitVerbal2023}. Both models produced COD assignments coded using the WHO 2016 VA standard \citep{worldhealthorganizationVerbalAutopsyStandards2016}. To ensure comparability across models, all output CODs were mapped to the CGHR-10 classification system for evaluation relative to physician-assigned CODs. Further details on model input formats, output mappings, and code conversion procedures are provided in Appendix \ref{app-methods-model}.

\subsection{Performance Evaluation}\label{methods-eval}

Model performance was assessed at both the population and individual levels by comparing each model’s CGHR-10 COD assignments to those of physicians for all 6,939 records. Cause-Specific Mortality Fraction (CSMF) accuracy was used to evaluate agreement at the population level (see Appendix \ref{app-methods-csmfa}), while Partial Chance-Corrected Concordance (PCCC) was used to assess individual-level agreement (see Appendix \ref{app-methods-pccc}) \citep{murrayRobustMetricsAssessing2011}. Both metrics range from 0 to 1, where higher values indicate stronger similarity with physician assignment.

Given that model performance can vary by age and different CODs \citep{benaraEvaluationMethodsAssigning2023, murrayUsingVerbalAutopsy2014, setelValidityVerbalAutopsy2006}, both CSMF accuracy and PCCC were calculated overall and stratified by age group (adult, child, neonatal), CGHR-10 COD, and age at death. For adult and child groups, metrics were computed in five-year age bands for records with age at death of one year or older, and five-month bands for records between 28 days and one year. For the neonatal group, evaluations were conducted separately for age intervals of 0–6 days and 7–27 days. Additional details on the evaluation strategy and metric calculations are provided in Appendix \ref{app-methods-eval}.

\section{Results}\label{results}

This section presents the performance of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA in assigning CGHR-10 CODs, based on the methodology described in Section \ref{methods}. GPT-4 achieved the highest overall individual-level concordance, with a PCCC of 0.61, followed by GPT-3.5 (0.56). GPT-4 also demonstrated the highest PCCC across most age groups and CODs within the adult (12–69 years), child (28 days–11 years), and neonatal (under 28 days) categories. In contrast, GPT-3.5, InterVA-5, and InSilicoVA showed higher PCCC values for a limited subset of age groups and CODs. Summary results are presented in Section \ref{results-overall}, with stratified results by age group detailed in Sections \ref{results-adult}, \ref{results-child}, and \ref{results-neo}.

\subsection{Overall Performance}\label{results-overall}

Of all 6939 records, GPT-4 (0.61 PCCC) had the highest individual performance followed by GPT-3.5 (0.56 PCCC), InSilicoVA (0.44 PCCC), and InterVA-5 (0.44 PCCC) (Figure \ref{fig-pccc-csmf}). GPT-3.5 and GPT-4 had improvements ranging from 0.14-0.18 PCCC over InSilicoVA and InterVA-5, while GPT-4 slightly improved over GPT-3.5 by 0.05 PCCC. Population level performances were similar for all models (0.74-0.79 CSMF). Figure \ref{fig-pccc} shows the PCCC performance across three age groups (adult, child, and neonate). GPT-4 had the best individual performance for adult and neonatal records (0.64 and 0.58 PCCC), while GPT-3.5 had the best performance for child records (0.54 PCCC) with GPT-4 performing slightly worse (0.51 PCCC). InSilicoVA and InterVA-5 performed the worse for adult and child records ($\leq$0.5 PCCC), while GPT-3.5 performed the worse for neonatal records (0.42 PCCC). Performance varied less for child deaths (0.13 range) than for adult and neonatal deaths (0.24 and 0.22 range). Across ages, all models followed a similar pattern in individual performance (Figure \ref{fig-pccc-age}), where PCCC trended upwards for 1 month to 14 years ($\sim$0.1-0.75), and downwards for ages 15 to 69 years ($\sim$0.7-0.35). The highest and lowest performances were observed for ages 12-29 years ($\sim$0.4-0.7) and 1-11 months ($\sim$0.1-0.35) respectively.

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-pccc-csmf.pdf}
\caption{Overall model performance.}\label{fig-pccc-csmf}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-pccc.pdf}
\caption{Model performance by age group.}\label{fig-pccc}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-pccc-age.pdf}
\caption{Model performance by age range.}\label{fig-pccc-age}
\end{figure}

\subsection{Performance for 3826 Adult Records (12 to 69 years)}\label{results-adult}

Figure \ref{fig-pccc-cod-adult} presents model performance across 17 adult CODs, excluding suicide due to a low sample size (n=3, \textless 1\%). GPT-4 achieved the highest individual level performance for 10 of 17 CODs (0.35–0.99 PCCC), followed by GPT-3.5 for 5 CODs (0.43–0.94 PCCC), and InSilicoVA for 2 CODs (0.71 and 0.84 PCCC). InterVA-5 showed the lowest performance for 8 CODs (0–0.79 PCCC), InSilicoVA for 6 CODs (0.01–0.41 PCCC), and GPT-3.5 for 2 CODs (0.38 and 0.53 PCCC). The greatest improvements of GPT-3.5/4 over InSilicoVA and InterVA-5 were observed in chronic respiratory diseases (+0.74-0.94 PCCC), while the smallest improvements were for malaria (+0.09-0.17 PCCC). All models achieved PCCC values above 0.70 for maternal conditions (0.79–0.99), but remained below 0.50 for unspecified infections (0.35–0.49), malaria (0.26–0.43), and ill-defined CODs (0–0.35). GPT-4 showed performance improvements exceeding 0.20 PCCC over all other models for cancers (+0.25–0.36), stroke (+0.27–0.45), and diarrhoeal diseases (+0.37–0.51). GPT-3.5 demonstrated similar gains for liver and alcohol-related diseases (+0.27–0.52). Performance variability across models was most pronounced for chronic respiratory diseases (range: 0.94), while narrower differences were observed for maternal conditions (0.20), malaria (0.17), ischemic heart disease (0.15), and unspecified infections (0.14).


\begin{figure}[H]
\centering
\includegraphics[width=.9\textwidth]{../figures/fig-pccc-cod-adult.pdf}
\caption{Model performance for adult records by COD.}\label{fig-pccc-cod-adult}
\end{figure}

\subsection{Performance for 2636 Child Records (28 Days to 11 Years)}\label{results-child}

Figure \ref{fig-pccc-cod-child} shows individual-level performance across 8 child CODs, excluding congenital anomalies due to a low sample size (n=1, \textless 1\%). GPT-4 achieved the highest PCCC for 4 of the 8 CODs (0.65–0.94), followed by GPT-3.5 for 3 CODs (0.44–0.88), and InSilicoVA for 1 COD (0.78). InterVA-5 had the lowest performance for 4 CODs (0.09–0.79), InSilicoVA for 3 CODs (0–0.35), and GPT-3.5 for 1 COD (0.58). All models performed well for injuries, with PCCC values exceeding 0.70 (0.79–0.94), and showed lower performance for malaria (0.35–0.54) and other infections (0.29–0.44). GPT-4 demonstrated an improvement over other models for ill-defined CODs, with improvements greater than 0.30 PCCC (+0.38–0.65), and also showed stronger performance for injuries, with gains of +0.11–0.15 compared to +0.01–0.04 for other models. Performance differences exceeding 0.60 PCCC were observed for epilepsy, leukaemia, other communicable diseases (range: 0.73), ill-defined causes (0.65), and nutritional deficiencies (0.61). In contrast, narrower differences (less than 0.30 PCCC) were seen for malaria (0.20), injuries, and other infections (0.15).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-pccc-cod-child.pdf}
\caption{Model performance for child records by COD.}\label{fig-pccc-cod-child}
\end{figure}

\subsection{Performance for 477 Neonatal Records (Under 28 Days)}\label{results-neo}

Figure \ref{fig-pccc-cod-neo} shows model performance across 5 neonatal CODs, excluding congenital anomalies (n=2, \textless 1\%) and other causes (n=5, 1\%) due to limited sample sizes. GPT-4 achieved the highest PCCC for 3 of the 5 CODs (0.39–0.71), while GPT-3.5 and InSilicoVA had the highest PCCC for 1 COD each (0.57 and 0.86). GPT-3.5 showed the lowest PCCC for 3 CODs (0–0.13), and InterVA-5 for 2 CODs (0.01 and 0.48). Performance was similar across all models for stillbirths (0.48–0.57 PCCC), though only GPT-4 achieved a PCCC greater than 0 for prematurity-related deaths. InSilicoVA outperformed all other models for neonatal infections, with gains of +0.18–0.73 PCCC. Performance differences greater than 0.6 PCCC were observed for infections (range: 0.73) and prematurity and low birthweight (0.7). Stillbirth showed minimal variation across models (range: 0.09).

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{../figures/fig-pccc-cod-neo.pdf}
\caption{Model performance for neonatal records by COD.}\label{fig-pccc-cod-neo}
\end{figure}

\section{Discussion}\label{discuss}

This section interprets and contextualizes the findings presented in Section \ref{results}. The comparative advantages and limitations of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA for COD assignment are discussed in Sections \ref{discuss-adv} and \ref{discuss-disadv}, respectively. Study limitations are outlined in Section \ref{discuss-limits}, and directions for future research are presented in Section \ref{discuss-opp}.

\subsection{Advantages}\label{discuss-adv}

This section outlines the strengths of the evaluated models in assigning CODs. Section \ref{discuss-adv-cod} discusses model advantages across specific CODs and age groups. Section \ref{discuss-adv-hscav} highlights the potential for improving efficiency in physician-assisted COD assignment through computational support. Section \ref{discuss-adv-nl} examines the benefits of leveraging natural language narratives in GPT models relative to traditional structured questionnaire data.

\subsubsection{Cause-specific Models}\label{discuss-adv-cod}

At the population level, all models demonstrated comparable performance to physicians (0.74-0.79 CSMF), indicating their potential for estimating COD distributions in large populations. While individual-level performance was lower overall (0.44–0.61 PCCC), several models showed strong performance compared with physicians for specific CODs (up to 0.99 PCCC). GPT-3.5/4 consistently outperformed InSilicoVA and InterVA-5 across most CODs, achieving the highest PCCC for 15 of 17 adult, 7 of 8 child, and 4 of 5 neonatal CODs. In contrast, InSilicoVA showed better performance for select CODs, including road and transport injuries (0.84 PCCC), tuberculosis (0.71), pneumonia (0.78), and neonatal infections (0.86). For CODs where high performance was observed, such as maternal conditions, chronic respiratory diseases, diabetes mellitus, and cancers for GPT-3.5/4 (0.91–0.99 PCCC), and road/transport injuries and neonatal infections for InSilicoVA (0.84 and 0.86 PCCC), the model outputs were more aligned with physician assignment. These findings support the potential utility of combining models based on their strengths for particular CODs. Evaluating performance at the COD level may allow for more targeted deployment of models, maximizing accuracy across disease categories. Table \ref{tab-leadcod} illustrates how different models align with leading CODs identified in prior Sierra Leone studies \citep{carshon-marshChildMaternalAdult2022, ansumanaReportCausesDeath2023}. For example, we may deploy models to estimate asthma and chronic respiratory diseases using GPT-3 (0.94 PCCC), while using GPT-4 and InSilicoVA for diarrhoea and tuberculosis respectively (0.79 and 0.71 PCCC).


\begin{table}[h]
    \caption{Top ten leading causes of death for Sierra Leone in 2023 and most relevant models.}\label{tab-leadcod}%
    \begin{tabular}{@{}llll@{}}
    \toprule
    \makecell{Top 10 Leading Cause of Death\footnotemark[1]\\($\sim$71\% of $\sim$76K deaths)} & \makecell{Deaths\\(\% of 76K)\footnotemark[2]} & \makecell{Best\\Model(s)} & \makecell{PCCC\footnotemark[3]} \\
    \midrule

    Malaria & 16,075 (21\%) & GPT-3.5/4 & 0.46 (n=2181) \\
    Infections & 11,777 (16\%) & GPT-3.5/4/InSilicoVA & 0.55 (n=1155) \\
    Ischaemic heart and other vascular & 5,747 (8\%) & GPT-4 & 0.65 (n=168) \\
    Diarrhoea & 4,285 (6\%) & GPT-4 & 0.79 (n=380) \\
    Stroke & 4,262 (6\%) & GPT-4 & 0.77 (n=331) \\
    Pneumonia & 3,074 (4\%) & GPT-4/InSilicoVA & 0.7 (n=186) \\
    Birth asphyxia and birth trauma & 2,431 (3\%) & GPT-4 & 0.63 (n=103) \\
    Tuberculosis & 2,399 (3\%) & InSilicoVA & 0.71 (n=171) \\
    Low birth weight/preterm & 1,570 (2\%) & GPT-4 & 0.71 (n=103) \\
    Asthma and chronic respiratory & 1,551 (2\%) & GPT-3 & 0.94 (n=75)\\

    \botrule
    \end{tabular}
    \footnotetext[1]{Other infections and severe systemic/localized infections were generalized into infections. Appendix, hernia, intestinal and Peptic ulcer/gastroesophageal causes did not have comparable CGHR-10 codes and were omitted from the top ten.}
    \footnotetext[2]{Percentage of $\sim$76 Thousand (K) total deaths \citep{ansumanaReportCausesDeath2023}. Numbers are rounded.}
    \footnotetext[3]{Adult, child, and neonate mean PCCC and summed n records if available.}
\end{table}

\subsubsection{Age-specific Performance Patterns}\label{discuss-adv-age}

Across age groups, all models exhibited a consistent upward trend in performance from 6 months to 14 years, followed by a general decline from ages 15 to 69 years. GPT-3.5/4 outperformed InSilicoVA and InterVA-5 throughout this range, while performance patterns from birth to 5 months were more variable (see Figure \ref{fig-pccc-age}). In adults, performance generally decreased with age, suggesting greater difficulty in assigning CODs among older adults, with a modest improvement observed after age 59. Among children and neonates, performance increased beyond 5 months, indicating greater model reliability as developmental age advanced. Although no model consistently achieved performances greater than 0.8 PCCC in any specific five-year age band, these age-related trends provide valuable insights. Specifically, they align with expectations from clinical literature, where physicians often face greater diagnostic uncertainty in neonatal cases \citep{rasmussenComplexityPhysiciansUnderstanding2019, faisonWhenUnknownUnknowable2023}. The observed patterns underscore the importance of considering developmental stage when interpreting model outputs and comparing them to physician-assigned CODs.


\subsubsection{Scalability and Availability}\label{discuss-adv-hscav}

The models evaluated in this study offer scalable and cost-effective support for physician-assigned CODs, particularly in resource-constrained settings. Similar to tools used in differential diagnosis, GPT and InSilicoVA models can provide alternative COD suggestions for physician review \citep{barnettComparativeAccuracyDiagnosis2019}, potentially reducing the proportion of ill-defined causes and physician disagreement. At the time of analysis, running GPT-3.5 on 6,939 records cost approximately \$1.60 USD (based on \$0.50 per million tokens), while GPT-4 cost approximately \$115 USD (at \$30 per million tokens) \citep{openaiPricing2024}. InterVA-5 and InSilicoVA were freely available as open-source software. These costs compare favorably to physician review, which may exceed \$3 USD per household in settings like India \citep{gomesNationwideMortalityStudies2017,jhaProspectiveStudyOne2005}, while the models can also process over 10,000 records within a single day. When physicians are unavailable, these models present a viable alternative for estimating population-level CODs. However, their application should be targeted to CODs where model performance is strong (see Table \ref{tab-leadcod}). Additionally, model outputs may be used to prioritize physician review, allocating less physician time to validating high-performing CODs (e.g. maternal conditions with 0.79–0.99 PCCC) and allocating more time to challenging cases (e.g. acute respiratory infections with 0.25–0.61 PCCC).


\subsubsection{Natural Language Input and Output}\label{discuss-adv-nl}

None of the models required training data for COD assignment, enabling their use without domain-specific datasets or expertise. A key advantage of GPT-3.5/4 is their ability to process and generate natural language text as input and output. Unlike InterVA-5 and InSilicoVA, GPT models are able to assign CODs using the ICD-10 standard, mirroring physician practice, and can potentially classify CODs in broader or alternative categories based on prompt design. In contrast, InterVA-5 and InSilicoVA rely exclusively on structured data from WHO VA 2016 questionnaires and assign CODs using WHO VA 2016 codes. This dependency necessitates ongoing maintenance and conversion between questionnaire versions (e.g., WHO VA 2012 to 2016) and coding systems (e.g., WHO VA 2016 to ICD-10), which reduces interoperability and comparability across models. The flexibility of GPT models in handling unstructured data allows them to capture latent and ambiguous information—such as health-seeking behaviors and social context, which are not encompassed by standardized VA codes \citep{jebleeAutomaticallyDeterminingCause2019, kingQualityDiagnosticValue2016}. For example, GPT-3.5/4 outperformed InterVA-5 and InSilicoVA by +0.35-0.65 PCCC on ill-defined CODs across age groups. They also demonstrated higher performance (+0.11-0.61 PCCC) on rarer CODs, such as nutritional deficiencies (n=11) and diabetes mellitus (n=27), which may be underrepresented in questionnaire data, but better contextualized through extensive knowledge embedded in GPT training corpora.

\subsection{Disadvantages}\label{discuss-disadv}

This subsection addresses the caveats of GPT models in COD assignment. Section \ref{discuss-disadv-reprod} examines challenges related to reproducibility of GPT outputs across repeated runs and their dependence on static training data. Section \ref{discuss-disadv-repriv} explores the substantial computational resources required by GPT models and the associated concerns regarding data privacy and security.

\subsubsection{Reproducibility and Timeliness}\label{discuss-disadv-reprod}

In this study, GPT models were run with the temperature parameter set to 0 to enhance reproducibility and consistency. However, a brief experiment (Appendix \ref{app-reprod}) showed that GPT-3.5 assigned the same COD for the same record in just over 60\% of repeated runs on a sample of 100 records. This variability indicates that GPT models do not consistently produce identical COD assignments for identical inputs, which raises concerns about reproducibility and reliability. For example, GPT models may correctly assign CODs by chance, but extensive testing with large numbers of reruns (e.g., 10,000) is cost-prohibitive, as rerunning increases costs substantially. By contrast, InterVA-5 and InSilicoVA are open-source and free, enabling unlimited reruns without additional expense. Moreover, these models provide COD assignments with probabilities for alternative causes, enhancing reproducibility and transparency despite lower overall performance. Another important limitation common to all models is their reliance on training data that reflect information only up to a fixed point in time. Consequently, they may not incorporate the most current data sources, such as recent scientific literature, social media, or emerging reports. This lag can limit their ability to detect new or emerging diseases (e.g., COVID-19) and shifts in COD distributions related to outbreaks or other public health changes unless regularly updated.

\subsubsection{Infrastructure and Data Privacy}\label{discuss-disadv-repriv}

GPT-3.5/4 require substantial computational infrastructure for training and inference, making local deployment impractical due to cost and model ownership constraints. Consequently, sensitive data, such as identifiable personal information, must be transmitted to external servers, raising significant privacy concerns. Data submitted via prompts, which include narrative content used for COD assignment, may be collected by service providers (e.g., OpenAI) and potentially misused \citep{taoOpeningPandoraBox2023}. There is risk that sensitive information could be exposed or exploited through malicious actors or poorly controlled data handling \citep{khowajaChatGPTNeedsSPADE2024, wuUnveilingSecurityPrivacy2024}. While jurisdictions, such as the European Union, enforce strict protections under the General Data Protection Regulation (GDPR), most low‑ and middle‑income countries are only beginning to formalize regulatory frameworks for data protection and artificial intelligence governance \citep{intersoftconsultingGeneralDataProtection2018,beckProtectingConfidentialitySecurity2016,kwarkyeWeKnowWhat2025}. In contrast, InterVA-5 and InSilicoVA can be run entirely on local systems, enabling data to remain under the control of the data owner. This approach reduces dependency on external services and better safeguards data privacy.

\subsection{Limitations}\label{discuss-limits}

This section outlines key limitations of the current study related to the use of GPT models. Section \ref{discuss-limits-phy} discusses the use of physician assignment as the reference standard for comparing models. Section \ref{discuss-limits-model} addresses the need for further model tuning and adjustments of model parameters and output, while Section \ref{discuss-limits-global} notes the importance of more globally diverse datasets for model evaluation.

\subsubsection{Physician Reference Standard}\label{discuss-limits-phy}

This study evaluated model performance using broad CGHR-10 categories rather than specific ICD-10 codes. In practice, physicians assign more detailed ICD-10 codes, but InterVA-5 and InSilicoVA generate only broader WHO VA codes and cannot assign ICD-10 codes directly, partly due to insufficient sample cases for many specific ICD-10 categories to support reliable modeling. For example, even broad CGHR-10 categories had fewer than 10 cases (e.g., congenital anomalies, suicide), and were excluded from evaluation. While GPT models assigned ICD-10 codes, lower performance can be expected, as even physicians show limited agreement on detailed ICD-10 coding, with only 6,939 (58\%) of 11,920 records in agreement, necessitating the use of broader categories (e.g., CMEA-10 codes) to assess equivalence. Reliance on physician assignment as the reference standard may introduce bias, as physician interpretations may be shaped by local epidemiological knowledge, particularly for more complex cases or ambiguous narratives \citep{leitaoComparisonPhysiciancertifiedVerbal2014}.

\subsubsection{Model Tuning and Interpretability}\label{discuss-limits-model}

GPT-3.5/4 were used with default parameters except for temperature, which was set to 0 to enhance consistency. However, tuning temperature and other settings could potentially improve performance \citep{openaiOpenAIPlatformAPI2024}, but was not explored due to the high cost of repeated runs needed for sensitivity analyses, as noted in Section \ref{discuss-disadv-reprod}. Despite temperature control, GPT outputs may still vary, highlighting the need to assess reliability and consistency to avoid coincidental results \citep{johnsonAssessingAccuracyReliability2023,jangConsistencyAnalysisChatGPT2023,krishnaEvaluationReliabilityRepeatability2024}. Unlike GPT models, InterVA-5 and InSilicoVA provide multiple COD assignments with associated probabilities to measure reliability. In addition, while GPT can be prompted to generate multiple CODs, this study evaluated only the most probable assignment. Considering multiple COD outputs may better capture alternative diagnoses and align more closely with physician assessments \citep{solemanVerbalAutopsyCurrent2006}. Notably, GPT models are capable of generating natural language justifications for their COD assignments, offering a form of qualitative interpretability that mimics physician reasoning. However, these explanations are not tied to explicit probabilistic scores or model certainty, which limits their use for structured reliability assessments in current VA workflows. Nonetheless, evaluation methods considering probability scores and justifications may identifying insights on model performance and behavior differences across CODs.

\subsubsection{Global Validity}\label{discuss-limits-global}

While this study rigorously compares computer algorithms for COD assignment in Sierra Leone, the extent to which these findings are applied to other geographic or epidemiological contexts remains limited. Variations in local mortality profiles, linguistic expression, health system infrastructure, and culturally specific interpretations of illness shape the content and structure of VA narratives and questionnaires \citep{setelScandalInvisibilityMaking2007,fottrellVerbalAutopsyMethods2010,byassImperfectWorldGlobal2010}. For example, the ways in which symptoms are described, terminology used, and aspects emphasized by respondents differ across languages and cultural settings. Moreover, Sierra Leone is predominantly driven by infectious diseases, such as malaria and respiratory infections, a pattern that contrasts with regions where non-communicable diseases typically constitute the leading CODs in North America and Europe, or where violence and road traffic injuries predominate in parts of Latin America and Asia \citep{murrayMortalityCauseEight1997,mathersGlobalRegionalCauses2009,vosGlobalBurden3692020}. Given ongoing efforts to scale and integrate VA systems for mortality surveillance across diverse low- and middle-income countries, further validation across globally representative VA datasets is essential to evaluate model robustness, adaptability, and operational utility in practice \citep{shawonRoutineMortalitySurveillance2021,maqungoCanVerbalAutopsies2024,onyangoUsingVerbalAutopsy2024}.

\subsection{Opportunities}\label{discuss-opp}

This section explores opportunities to enhance GPT models for assigning CODs. Section \ref{discuss-opp-peng} highlights improvements through prompt engineering and analysis of misclassified cases. Section \ref{discuss-opp-gsurveys} discusses leveraging GPT to improve household survey data quality. Section \ref{discuss-opp-cava} considers integrating GPT with InterVA-5 and InSilicoVA to support and enhance physician COD assignment within VA systems.

\subsubsection{Prompt Engineering and Custom Models}\label{discuss-opp-peng}

Prompt engineering, the design of input prompts to guide GPT models toward improved outputs \citep{wangPromptEngineeringHealthcare2024}, offers a key opportunity to enhance COD assignment performance. An exploratory analysis in Appendix \ref{app-misclass} of misclassified GPT-4 records for neonatal infections identified potential issues related to CGHR-10 code categorization, narrative information order, and COD assignment guidelines. Collaborating with domain experts (e.g., physicians, specialists) to review misclassified cases could inform prompt refinements that increase correct COD assignments or better align with broader COD categories. Furthermore, iterative prompt adjustments incorporating additional questionnaire data and physician manuals (e.g., via retrieval-augmented generation \citep{lewisRetrievalaugmentedGenerationKnowledgeintensive2020}) may improve model accuracy \citep{meskoPromptEngineeringImportant2023}. Sensitivity analyses can evaluate how prompt modifications affect performance and output consistency on a cause-specific basis. Additionally, GPT models can be customized to specific domains or contexts, adjusting objectives, behavior, data inputs, privacy considerations, and evaluation criteria to create specialized models optimized for particular CODs or settings \citep{almasreDevelopmentEvaluationCustom2024}.

\subsubsection{Guided and Monitored Household Surveys}\label{discuss-opp-gsurveys}

Verbal autopsies involve surveyors visiting households to collect information about the deceased from family, friends, or community members. While standardized questionnaires are used, important latent information within free-text narratives often goes uncaptured \citep{kingQualityDiagnosticValue2016,jebleeAutomaticallyDeterminingCause2019}. Narrative quality depends heavily on the surveyor’s social skills, cultural understanding, emotional capacity, and medical knowledge, all of which influence data completeness and potential bias \citep{solemanVerbalAutopsyCurrent2006,lohAddedValueOpen2021}. GPT models may support surveyors by suggesting improved or overlooked questions during interviews to elicit richer narratives. Moreover, as these models can assign CODs in real-time, they offer the opportunity to monitor data quality during collection. For example, by comparing estimated COD distributions with expected patterns for specific regions as a form of immediate quality control, where surveyors may be required to undergo review when estimated and expected COD distributions diverge significantly.

\subsubsection{Computer Assisted Verbal Autopsy (CAVA)}\label{discuss-opp-cava}

This study establishes a basis for integrating GPT, InterVA-5, and InSilicoVA models into VA systems to support physicians in assigning CODs. In dual-coded VA systems (Section \ref{methods-data}), two physicians independently assign CODs for each record and review each other’s assignments (reconciliation), while a senior physician adjudicates if disagreements persist. As noted in Section \ref{discuss-adv-hscav}, presenting alternative COD suggestions from GPT and InSilicoVA models may reduce physician disagreement and the frequency of ill-defined records, allowing physicians to focus on more complex cases. Model-generated COD suggestions can be offered to physicians after their initial assignment, enabling reconsideration or confirmation of CODs (step 2 and option 2b in Figure \ref{fig-discuss-phyassist}). Future work will evaluate the impact of these suggestions on improving VA data quality, including increasing physician agreement and reducing ill-defined deaths. GPT-4, InterVA-5, and InSilicoVA suggestions have been incorporated into the ongoing HEAL-SL study \citep{njalauniversityHealthySierraLeone2023}, aiming to improve physician agreement and lower ill-defined COD assignments.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../figures/fig-discuss-phyassist.pdf}
    \caption{Model suggestions integrated in the physician assignment process.}\label{fig-discuss-phyassist}
\end{figure}

\section{Conclusion}\label{conclude}

This study evaluated the performance of GPT-3.5, GPT-4, InterVA-5, and InSilicoVA models against physicians in assigning CODs for 6,939 VA records from Sierra Leone (2019–2022). At the population level, all models achieved similar CSMF accuracy (0.74–0.79). At the individual level, GPT-4 had the highest performance (0.61 PCCC), followed by GPT-3.5 (0.58), and InSilicoVA/InterVA-5 (0.44). By COD, GPT-4 performed best for 10 of 17 adult, 4 of 8 child, and 3 of 5 neonatal causes, while GPT-3.5 led in 5 adult, 3 child, and 1 neonatal CODs, and InSilicoVA led in 2 adult, 1 child, and 1 neonatal cause. Performance increased ($\sim$0.1–0.75 PCCC) as children and neonates matured (0 days to 14 years) and decreased ($\sim$0.7–0.35) with adult aging (15 to 69 years). These findings suggest that combining models tailored to specific CODs and age groups may optimize performance relative to physicians. All models demonstrated scalability and on-demand availability, enabling COD estimation and alternative diagnoses in low-resource or physician-scarce settings. GPT models’ natural language processing capability allowed flexible data input and output, aligning closer to physician reasoning, but issues remain with reproducibility, reliance on historical training data, computational demands, and data privacy. Study limitations included challenges comparing ICD-10 codes across models, limited sensitivity analyses due to costs, and exclusion of multiple COD assignment evaluation. Future research opportunities include prompt engineering and custom GPT models to improve accuracy, guided household surveys to enhance narrative quality, and CAVA systems integrating GPT and other models to support physicians by suggesting alternative COD assignments. GPT-4, InterVA-5, and InSilicoVA have been incorporated into ongoing HEAL-SL study since 2022 to provide second-opinion support for physician COD assignment. Evaluating the impact of computer-assisted VA on physician agreement and reduction of ill-defined deaths will be critical to advancing accurate, efficient VA systems worldwide.

% Conclusions may be used to restate your hypothesis or research question, restate your major findings, explain the relevance and the added value of your work, highlight any limitations of your study, describe future directions for research and recommendations. 

% In some disciplines use of Discussion or 'Conclusion' is interchangeable. It is not mandatory to use both. Please refer to Journal-level guidance for any specific requirements. 

\backmatter

\bmhead{Supplementary information}

% If your article has accompanying supplementary file/s please state so here. 

% Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

% Please refer to Journal-level guidance for any specific requirements.

Additional file 1 (.csv) titled "Central Medical Evaluation Agreement 10 (CMEA-10) codes" with description "ICD-10 code ranges considered in physician agreement" was used to supplement this study.

\bmhead{Acknowledgments}

% Acknowledgments are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

% Please refer to Journal-level guidance for any specific requirements.

TBD.

\section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval 
% \item Consent to participate
% \item Consent for publication
% \item Availability of data and materials
% \item Code availability 
% \item Authors' contributions
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

\subsection*{Funding}

TBD.

\subsection*{Competing interests}

Not applicable.

\subsection*{Ethics approval}

Not applicable.

\subsection*{Consent for publication}

Not applicable.

\subsection*{Availability of data and materials}

The datasets supporting the conclusions of this article are included within the article (and its additional files), at \url{https://openmortality.org} (available upon request). Verbal Autopsy (VA) narrative and questionnaire data by age group and survey rounds available at \url{https://openmortality.org/dataset/heal-sl}. Cause of death code mappings to convert between ICD-10, WVA-2016, and CGHR-10 codes available at \url{https://openmortality.org/dataset/icd}.

\subsection*{Code availability}

All code for this paper is available at \url{https://github.com/cghr-toronto/healsl-gpt-paper}.

\subsection*{Authors' contributions}

PJ and PB are the study Principal Investigators. ATA and RK implemented the data collection procedures. RW, TKSN, and CM processed, documented, and prepared the data. RW, ASL, and RK ran the models. RW wrote the paper and conducted the analysis. AB and RCM provided medical domain guidance and feedback. All authors reviewed the results and contributed to the report. All authors read and approved the final manuscript.

\begin{appendices}

% Fix figure hyperrefs for appendix
\setcounter{figure}{0}
\renewcommand{\thefigure}{\thesection\arabic{figure}}
\renewcommand{\theHfigure}{\thesection\arabic{figure}}

%\section{Section title of first appendix}\label{secA1}

%An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.
    
%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\section{Centre for Global Health Research 10 (CGHR-10) Codes}\label{app-cghr10}

Tables \ref{tab-codes-cghr10-adult} to \ref{tab-codes-cghr10-neo} provide grouped ICD-10 ranges in each CGHR-10 code by age group.

\begin{table}[!h]
    \caption{CGHR-10 codes for adults (12-69 years).}\label{tab-codes-cghr10-adult}%
    \begin{tabular}{p{0.3\textwidth}p{0.65\textwidth}}
    \toprule
    Adult CGHR-10 Code & ICD-10 Range\\

    \midrule
    
    Acute respiratory infections & H65-H68, H70-H71, J00-J22, J32, J36, J85-J86, P23 \\ 
    Tuberculosis & A15-A16, B90, J65 \\ 
    Diarrhoeal & A00-A09 \\ 
    Unspecified infections & A17-A33, A35-A99, B00-B17, B19-B49, B55-B89, B91-B99, C46, D64, D84, G00-G09, H10, H60, I30, I32-I33, K02, K04-K05, K61, K65, K67, K81, L00-L04, L08, M00-M01, M60, M86, N10, N30, N34, N41, N49, N61, N70-N74, P35-P39, R50, R75, ZZ21 \\ 
    Malaria & B50-B54 \\ 
    Maternal conditions & A34, F53, O00-O08, O10-O16, O20-O99 \\ 
    Nutritional deficiencies & D50-D53, E00-E02, E40-E46, E50-E64, X53-X54 \\ 
    Chronic respiratory & J30-J31, J33-J35, J37-J64, J66-J84, J90-J99, R04-R06, R84, R91 \\ 
    Cancers & C00-C26, C30-C45, C47-C58, C60-C97, D00-D48, D91, N60, N62-N64, N87, R59 \\ 
    Ischemic heart & I20-I25, R55 \\ 
    Stroke & G45-G46, G81-G83, I60-I69 \\ 
    Diabetes mellitus & E10-E14 \\ 
    Other cardiovascular & I00-I03, I05-I15, I26-I28, I31, I34-I52, I70-I99, R00-R01, R03, ZZ23 \\ 
    Liver and alcohol related & B18, F10, K70-K77, R16-R18, X45, Y15, Y90-91 \\ 
    Other noncommunicable & D55-D63, D65-D83, D86, D89, E03-E07, E15-E35, E65-E68, E70-E90, F00-F09, F11-F52, F54-F99, G10-G37, G40-G41, G43-G44, G50-G80, G84-G99, H00-H06, H11-H59, H61-H62, H69, H72-H95, K00-K01, K03, K06-K14, K20-K31, K35-K38, K40-K60, K62-K64, K66, K78-K80, K82-K93, L05, L10-L99, M02-M54, M61-M85, M87-M99, N00-N08, N11-N29, N31-N33, N35-N40, N42-N48, N50-N59, N75-N86, N88-N99, Q00-Q99, R10-R15, R19-R23, R26-R27, R29-R49, R56, R63, R70-R74, R76-R77, R80-R82, R85-R87, R90, ZZ25 \\ 
    Road and transport injuries & V01-V99, Y85 \\ 
    Suicide & X60-X84 \\ 
    Other injuries & S00-S99, T00-T99, W00-W99, X00-X44, X46-X52, X55-X59, X85-X99, Y00-Y14, Y16-Y84, Y86-Y89, Y92-Y98, ZZ27 \\ 
    Ill-defined & R02, R07-R09, R25, R51-R54, R57-R58, R60-R62, R64-R69, R78-R79, R83, R89, R92-R94, R96, R98-R99 \\ 

    \botrule
    \end{tabular}
\end{table}

\begin{table}[!htbp]
    \caption{CGHR-10 codes for children (28 days to 11 years).}\label{tab-codes-cghr10-child}%
    \begin{tabular}{p{0.25\textwidth}p{0.7\textwidth}}
    \toprule
    Child CGHR-10 Code & ICD-10 Range\\

    \midrule
    
    Pneumonia & A37, H65-H68, H70-H71, J00-J22, J32, J36, J85-J86, P23, U04 \\ 
    Diarrhoeal & A00-A09 \\ 
    Malaria & B50-B54 \\ 
    Other infections & A15-A28, A30-A36, A38-A44, A46, A48-A71, A74-A75, A77-A99, B00-B09, B15-B27, B30, B33-B49, B55-B60, B64-B83, B85-B92, B94-B97, B99, G00-G09, H10, H60, I30, I32-I33, I39-I41, J65, K02, K04-K05, K61, K65, K67, K81, L00-L04, L08, M00-M01, M60, M86, N10, N30, N34, N41, N49, N61, N70-N74, P35-P39, R50, R75, U00, Y95, ZZ11 \\ 
    Congenital anomalies & P01, P05, P07, P21, Q00-Q99 \\ 
    Epilepsy, leukaemia, and other noncommunicable & C00-C97, D01-D48, D55-D89, E03-E35, E65-E90, F00-F02, F73, G10-G99, H00-H06, H11-H59, H61-H62, H69, H72-H95, I00-I28, I31, I34-I38, I42-I99, J30-J31, J33-J35, J37-J47, J60, J64, J66-J70, J80-J82, J84, J90-J99, K00-K01, K03, K06-K60, K62-K63, K70-K80, K82-K93, L05, L10-L99, M02-M54, M61-M85, M87-M99, N00-N08, N11-N29, N31-N33, N35-N40, N42-N48, N50-N51, N60, N62-N64, N75-N99, P04, P08, P27, P51, P53-P60, P70-P72, P74-P76, P78, P80-P83, P92-P94, R00-R01, R03-R06, R11-R23, R26-R27, R29-R49, R55-R56, R59, R63, R70-R74, R76-R77, R80-R82, R84-R87, R90-R91, ZZ12-ZZ13, ZZ15 \\ 
    Injuries & S00-S99, T00-T98, V01-V99, W00-W99, X00-X52, X57-X99, Y00-Y91, Y97-Y98 \\ 
    Nutritional deficiencies & D50-D53, E00-E02, E40-E46, E50-E56, E59-E61, E63-E64, X53-X54 \\ 
    Other & D00, F03-F72, F74-F99, P00, P02-P03, P10-P15, P20, P22, P24-P26, P28-P29, P50, P52, P61, P77, P90-P91 \\ 
    Ill-defined & P96, R02, R07, R09-R10, R25, R51-R54, R57-R58, R60-R62, R64, R68-R69, R78-R79, R83, R89, R92-R99 \\ 

    \botrule
    \end{tabular}
\end{table}

\begin{table}[!htbp]
    \caption{CGHR-10 codes for neonates (less than 28 days).}\label{tab-codes-cghr10-neo}%
    \begin{tabular}{p{0.35\textwidth}p{0.6\textwidth}}
    \toprule
    Neonate CGHR-10 Code & ICD-10 Range\\

    \midrule
    
    Prematurity \& low birthweight & D64, O60, P01, P05, P07, P22, P25-P28, P52, P61, P77, P80, P92, R04 \\ 
    Neonatal infections & A00-A09, A20-A28, A32-A35, A37-A44, A46, A48-A49, A68-A70, A74-A75, A77-A79, A81-A90, B54, B95-B96, G00-G09, H10, H60, H65-H68, H70-H71, I30, I32-I33, I39-I41, J00-J22, J32, J36, J85-J86, K65, K67, K81, L00-L04, L08, M00-M01, M60, M86, N10, N30, N34, N41, N49, N61, O85, P23, P35-P39, P58-P59, P63, U04 \\ 
    Birth asphyxia and birth trauma & G40, P00, P02-P03, P10-P15, P20-P21, P24, P29, P50-P51, P90-P91, R06, W79, Z37 \\ 
    Stillbirth & P95 \\ 
    Congenital anomalies & C76, Q00-Q99 \\ 
    Other & A15-A19, A30-A31, A36, A50-A67, A71, A80, A91-A99, B00-B09, B15-B27, B30, B33-B53, B55-B60, B64-B83, B85-B92, B94, B97, B99, C00-C75, C77-C97, D00-D48, D50-D53, D55-D63, D65-D89, E00-E35, E40-E46, E50-E56, E59-E61, E63-E90, F00-F99, G10-G39, G41-G99, H00-H06, H11-H59, H61-H62, H69, H72-H95, I00-I28, I31, I34-I38, I42-I99, J30, J31, J33-J35, J37-J47, J60, J64-J70, J80-J82, J84, J90-J99, K00-K63, K70-K80, K82-K93, L05, L10-L99, M02-M54, M61-M85, M87-M99, N00-N08, N11-N29, N31-N33, N35-N40, N42-N48, N50-N51, N60, N62-N64, N70-N99, P04, P08, P53-P57, P60,P70-P72, P74-P76, P78, P81-P83, P93-P94, R00-R01, R03-R05, R11-R23, R26-R27, R29-R36, R39-R50, R55-R56, R59, R63, R70-R77, R80-R82, R84-R87, R90-R91, S00-S99, T00-T98, U00, V01-V99, W00-W78, W80-W99, X00-X54, X57-X99, Y00-Y91, Y95, Y97-Y98 \\ 
    Ill-defined & P96, R02, R07, R09-R10, R25, R51-R54, R57-R58, R60-R62, R64, R68-R69, R78-R79, R83, R89, R92-R99 \\

    \botrule
    \end{tabular}
\end{table}

\section{Details on Methods}\label{app-methods}

This section provides additional details on the methods described in Section \ref{methods}. An overview of the methods used in this study is seen in Figure \ref{fig-methods} as a five-step process. Section \ref{app-methods-data} provides details on the preprocessed data used for modelling. Section \ref{app-methods-model} describes the data and parameter inputs and outputs for each model, while Section \ref{app-methods-eval} details the evaluation of model outputs at the individual and population level across different CODs, age groups, and ages.

\begin{figure}[!h]
\centering
\includegraphics[width=.7\textwidth]{../figures/fig-methods.pdf}
\caption{Detailed study methods.}\label{fig-methods}
\end{figure}

\subsection{CGHR-10 Physician Agreed Records}\label{app-methods-data}

Initially, 11,920 records were collected from dual-coded EVA in the HEAL-SL study. Physicians were able to assign CODs for 11,820 of the 11,920 records, where 100 of these records could not be assigned a COD due to missing or inadequate information (e.g. low quality narrative, data loss). The 11,820 physician coded records were further filtered for records where both physicians agreed on the assigned codes (records that were not reconciled or adjudicated) resulting in 6942 physician agreed records (based on comparisons using CMEA-10 codes, see Additional File 1). The 6942 records were converted into CGHR-10 codes (see Appendix \ref{app-cghr10}) that generalized ICD-10 codes into 19, 10, and 7 categories for the adult (12 to 69 years), child (28 days to 11 years), and neonatal (under 28 days) age groups. After conversion, a final total of 6939 physician agreed records (3826 adult, 2636 child, and 477 neonatal) were used for modelling and performance evaluation, where three records were removed as their ICD-10 codes did not have a matching CGHR-10 code.

The 6939 physician agreed records were collected using VA from the HEAL-SL study between 2019-2022, where records were collected using nation wide samples across Sierra Leone provinces seen in Figure \ref{fig-map}. More populous areas (e.g. southern and north east provinces with $\sim$197,000 and $\sim$135,000 population respectively) had more sampling areas versus less populous areas (e.g. north west and eastern provinces with $\sim$50,000 and $\sim$69,000 people respectively). The distribution of the study data are shown by CGHR-10 causes of death in Table \ref{tab-data-cod}. All age groups had relatively evenly distributed female and male records (44-55\% of 6939 records each). Across CODs, there were noticeably more female records for cancers (65\%), and maternal conditions (100\%), while more male records for chronic respiratory diseases (61\%), other noncommunicable diseases (61\%), other injuries (77\%), road and transport injuries (71\%), and tuberculosis (68\%). Most records were coded by physicians as malaria for adults (20\%) and children (52\%), and stillbirth (36\%) and neonatal infections (21\%) for neonates. Suicide, congenital anomalies, nutritional deficiencies, and other had low sample sizes for each age group (\textless 1\% of total records for each age group). Table \ref{tab-data-age} shows the distribution of the study data by age. Across ages, there were more male records for 50-59 years (60-62\%), while all other records had between 49-59\% female and male records. Most records were in the 65-69 years age range for adults (15\%), 1-5 years for children (62\%), and 0-6 days for neonates (83\%).

\begin{figure}[H]
\centering
\includegraphics[width=.75\textwidth]{../figures/fig-map.pdf}
\caption{Study data sampling areas.}\label{fig-map}
\end{figure}

\begin{table}
\caption{Study data by cause of death.}\label{tab-data-cod}
\begin{tabular}{@{}lllll@{}}
    \toprule%
    Age Group  &  CGHR-10 Cause of Death (COD)  &  Female  &  Male  &  Total  \\
    \midrule
    \multirow{18}{*}{\makecell[l]{Adult, 18 CODs\\(n=3826, 55.1\%)\\Adult Female\\(n=1681, 43.9\%)\\Adult Male\\(n=2145, 56.1\%)}}  &  Acute Respiratory Infections  &  48 (45.7\%)  &  57 (54.3\%)  &  105 (2.7\%)  \\ 
        &  Cancers  &  32 (65.3\%)  &  17 (34.7\%)  &  49 (1.3\%)  \\ 
        &  Chronic Respiratory Diseases  &  29 (38.7\%)  &  46 (61.3\%)  &  75 (2\%)  \\ 
        &  Diabetes Mellitus  &  14 (51.9\%)  &  13 (48.1\%)  &  27 (0.7\%)  \\ 
        &  Diarrhoeal Diseases  &  102 (49.8\%)  &  103 (50.2\%)  &  205 (5.4\%)  \\ 
        &  Ill-Defined  &  56 (47.9\%)  &  61 (52.1\%)  &  117 (3.1\%)  \\ 
        &  Ischemic Heart Disease  &  89 (53\%)  &  79 (47\%)  &  168 (4.4\%)  \\ 
        &  Liver And Alcohol Related Diseases  &  58 (45.3\%)  &  70 (54.7\%)  &  128 (3.3\%)  \\ 
        &  Malaria  &  372 (46.6\%)  &  427 (53.4\%)  &  799 (20.9\%)  \\ 
        &  Maternal Conditions  &  130 (100\%)  &  N/A  &  130 (3.4\%)  \\ 
        &  Other Cardiovascular Diseases  &  59 (55.1\%)  &  48 (44.9\%)  &  107 (2.8\%)  \\ 
        &  Other Noncommunicable Diseases  &  160 (38.6\%)  &  254 (61.4\%)  &  414 (10.8\%)  \\ 
        &  Other Injuries  &  83 (23.2\%)  &  274 (76.8\%)  &  357 (9.3\%)  \\ 
        &  Road And Transport Injuries  &  73 (29.1\%)  &  178 (70.9\%)  &  251 (6.6\%)  \\ 
        &  Stroke  &  147 (44.4\%)  &  184 (55.6\%)  &  331 (8.7\%)  \\ 
        &  Suicide  &  N/A  &  3 (100\%)  &  3 (0.1\%)  \\ 
        &  Tuberculosis  &  54 (31.6\%)  &  117 (68.4\%)  &  171 (4.5\%)  \\ 
        &  Unspecified Infections  &  175 (45\%)  &  214 (55\%)  &  389 (10.2\%)  \\
    \midrule
    \multirow{9}{*}{\makecell[l]{Child, 9 CODs\\(n=2636, 38\%)\\Child Female\\(n=1290, 48.9\%)\\Child Male\\(n=1346, 51.1\%)}}  &  Congenital Anomalies  &  1 (100\%)  &  N/A  &  1 (0\%)  \\ 
        &  Diarrhoeal Diseases  &  79 (45.1\%)  &  96 (54.9\%)  &  175 (6.6\%)  \\ 
        &  \makecell[l]{Epilepsy, Leukaemia, And\\Other Noncommunicable Diseases}  &  61 (53.5\%)  &  53 (46.5\%)  &  114 (4.3\%)  \\ 
        &  Ill-Defined  &  34 (48.6\%)  &  36 (51.4\%)  &  70 (2.7\%)  \\ 
        &  Injuries  &  51 (37.8\%)  &  84 (62.2\%)  &  135 (5.1\%)  \\ 
        &  Malaria  &  680 (49.2\%)  &  702 (50.8\%)  &  1382 (52.4\%)  \\ 
        &  Nutritional Deficiencies  &  7 (63.6\%)  &  4 (36.4\%)  &  11 (0.4\%)  \\ 
        &  Other Infections  &  338 (50.7\%)  &  329 (49.3\%)  &  667 (25.3\%)  \\ 
        &  Pneumonia  &  39 (48.1\%)  &  42 (51.9\%)  &  81 (3.1\%)  \\
    \midrule
    \multirow{7}{*}{\makecell[l]{Neonate, 7 CODs\\(n=477, 6.9\%)\\Neonate Female\\(n=227, 47.6\%)\\Neonate Male\\(n=250, 52.4\%)}}  &  Birth Asphyxia And Birth Trauma  &  38 (36.9\%)  &  65 (63.1\%)  &  103 (21.6\%)  \\ 
        &  Congenital Anomalies  &  2 (100\%)  &  N/A  &  2 (0.4\%)  \\ 
        &  Ill-Defined  &  11 (47.8\%)  &  12 (52.2\%)  &  23 (4.8\%)  \\ 
        &  Neonatal Infections  &  49 (49.5\%)  &  50 (50.5\%)  &  99 (20.8\%)  \\ 
        &  Other  &  2 (40\%)  &  3 (60\%)  &  5 (1\%)  \\ 
        &  Prematurity And Low Birthweight  &  39 (53.4\%)  &  34 (46.6\%)  &  73 (15.3\%)  \\ 
        &  Stillbirth  &  86 (50\%)  &  86 (50\%)  &  172 (36.1\%)  \\
    \botrule
\end{tabular}
\end{table}

\begin{table}
\caption{Study data by age range.}\label{tab-data-age}
\begin{tabular}{@{}lllll@{}}
\toprule%
    Age Group  &  Age Range  &  Female  &  Male  &  Total  \\
    \midrule
        \multirow{12}{*}{\makecell[l]{Adult (n=3826, 55.1\%)\\Adult Female (n=1681, 43.9\%)\\Adult Male (n=2145, 56.1\%)}}  &  12-14 Years  &  51 (37.8\%)  &  84 (62.2\%)  &  135 (3.5\%)  \\ 
        &  15-19 Years  &  115 (42.8\%)  &  154 (57.2\%)  &  269 (7\%)  \\ 
        &  20-24 Years  &  146 (53.1\%)  &  129 (46.9\%)  &  275 (7.2\%)  \\ 
        &  25-29 Years  &  159 (45.2\%)  &  193 (54.8\%)  &  352 (9.2\%)  \\ 
        &  30-34 Years  &  174 (50.9\%)  &  168 (49.1\%)  &  342 (8.9\%)  \\ 
        &  35-39 Years  &  153 (45.4\%)  &  184 (54.6\%)  &  337 (8.8\%)  \\ 
        &  40-44 Years  &  134 (42\%)  &  185 (58\%)  &  319 (8.3\%)  \\ 
        &  45-49 Years  &  148 (47\%)  &  167 (53\%)  &  315 (8.2\%)  \\ 
        &  50-54 Years  &  134 (39.6\%)  &  204 (60.4\%)  &  338 (8.8\%)  \\ 
        &  55-59 Years  &  96 (37.6\%)  &  159 (62.4\%)  &  255 (6.7\%)  \\ 
        &  60-64 Years  &  128 (40.8\%)  &  186 (59.2\%)  &  314 (8.2\%)  \\ 
        &  65-69 Years  &  243 (42.3\%)  &  332 (57.7\%)  &  575 (15\%)  \\
        \midrule
        \multirow{4}{*}{\makecell[l]{Child (n=2636, 38\%)\\Child Female (n=1290, 48.9\%)\\Child Male (n=1346, 51.1\%)}}  &  1-5 Months  &  146 (47.4\%)  &  162 (52.6\%)  &  308 (11.7\%)  \\ 
        &  6-11 Months  &  160 (50.8\%)  &  155 (49.2\%)  &  315 (11.9\%)  \\ 
        &  1-5 Years  &  822 (50.3\%)  &  811 (49.7\%)  &  1633 (61.9\%)  \\ 
        &  6-11 Years  &  162 (42.6\%)  &  218 (57.4\%)  &  380 (14.4\%)  \\
        \midrule
        \multirow{4}{*}{\makecell[l]{Neonate (n=477, 6.9\%)\\Neonate Female (n=227, 47.6\%)\\Neonate Male (n=250, 52.4\%)}}  &  0-6 Days  &  184 (46.6\%)  &  211 (53.4\%)  &  395 (82.8\%)  \\ 
        &  7-27 Days  &  43 (52.4\%)  &  39 (47.6\%)  &  82 (17.2\%)  \\\\\\
    \botrule
\end{tabular}
\end{table}

\subsection{Modelling Details}\label{app-methods-model}

Each model (GPT-3.5, GPT-4, InSilicoVA, and InterVA-5) required pre-processing of the 6939 records into input data, and standardization of output COD codes from models for performance evaluation as not all models produced comparable codes across outputs. Although each model can assign multiple CODs per record, only the first generated COD response from GPT-3.5 and GPT-4, and the most probable COD from InterVA-5 and InSilicoVA were used for evaluation. Section \ref{app-methods-input} describes the input data and parameters for each model, while Section \ref{app-methods-output} details the outputs from running each model.

\subsubsection{Input Data and Preprocessing}\label{app-methods-input}

For GPT-3.5 and GPT-4, 6939 text prompts were generated for each physician agreed record as input to instruct the models to assign CODs based on the open narratives. Two types of text prompts were used: user prompts and system prompts. System prompts contained textual instructions to assign the role of a physician ICD-10 coder with expertise in Sierra Leone. The following system prompt was used for each record:

\begin{lstlisting}
You are a physician with expertise in determining underlying causes of death in Sierra Leone by assigning the most probable ICD-10 code for each death using verbal autopsy narratives. Return only the ICD-10 code without description. E.g. A00. If there are multiple ICD-10 codes, show one code per line.
\end{lstlisting}

\noindent User prompts contained textual instructions to perform coding of VA records based on the age, sex, and narrative of the deceased. The following template was used to generate user prompts for each record, where \verb|<age>| and \verb|<sex>| from the questionnaire, and \verb|<narrative>| from the narratives, were replaced with values from the data:

\begin{lstlisting}
Determine the underlying cause of death and provide the most probable ICD-10 code for a verbal autopsy narrative of a <age> years old <sex> death in Sierra Leone:  <narrative>
\end{lstlisting}

\noindent For InterVA-5 and InSilicoVA, the standardized questionnaire data from the HEAL-SL EVA were first converted into 2016 World Health Organization (WHO) VA questionnaire revision 1.5.1 Open Data Kit (ODK) format \citep{worldhealthorganizationODKVerbalAutopsy2022,nafundiODKCollectData2023} consisting of 526 variables \citep{dipasqualeReleaseODK20162016}, followed by further conversion into OpenVA format \citep{liOpenVAToolkitVerbal2023} consisting of 353 variables \citep{byassInterVA5UserGuide2020} using the \verb|pyCrossVA| version 0.97 Python package \citep{thomasPycrossvaPrepareData}. The 6939 records were all converted into OpenVA formatted records for InterVA-5 and InSilicoVA.

\subsubsection{Models and Parameters}\label{methods-models-params}

The GPT-3.5 and GPT-4 Application Programming Interface (API) was accessed using Python version 3.11.4 and used to assign CODs for each record. GPT-3.5 used the \verb|gpt-3.5-turbo| model, while GPT-4 used the \verb|gpt-4-0613| model. The parameter \verb|temperature| for GPT-3.5 and GPT-4, representing the sampling temperature ranging from 0 to 2 (default of 1), was set to 0 to produce more deterministic outputs \citep{openaiOpenAIPlatformAPI2024}. Higher values closer to 2 may produce less deterministic outputs, while lower values closer to 0 produce more deterministic outputs.

The \verb|openVA| R package was used to run InterVA-5 and InSilicoVA models to assign CODs for each record in R version 4.3.1. The \verb|openVA| package version 1.1.1 used dependent packages \verb|InterVA5| version 1.1.3 and \verb|InSilicoVA| version 1.4.0. The \verb|Nsim| (number of iterations to run) parameter \citep{liInSilicoVAProbabilisticVerbal2022} for InSilicoVA was set to 9500, while the \verb|HIV| (level of prevalence of human immunodeficiency virus) and \verb|Malaria| (level of prevalence of Malaria) parameters \citep{thomasInterVA5ReplicateAnalyse2021} for InterVA-5 were both set to \verb|'h'| (high) reflecting HIV and Malaria disease assumptions in Sierra Leone \citep{yendewaHIVAIDSSierra2018,walkerMalariaMorbidityMortality2015}. Note that the default value of \verb|Nsim=10000| for InSilicoVA ran until 9500 iterations before it stopped due to errors, thus \verb|Nsim=9500| was used and ran successfully for all iterations.

\subsubsection{Output Data and Code Conversion}\label{app-methods-output}

Of the 6939 input records, GPT-3.5, GPT-4, InterVA-5, and InSilicoVA were able to assign CODs for 6939 (100\%), 6935 (\textgreater 99\%), 6830 (98\%), 6830 (98\%) records respectively. All 6830 (100\%) InterVA-5 and InSilicoVA records with WHO VA 2016 v1.5 output codes \citep{worldhealthorganizationVerbalAutopsyStandards2016} were converted into ICD-10 codes respectively. After all model outputs were converted to ICD-10 codes, they were further converted to CGHR-10 codes. The 6939 GPT-3.5 and 6935 GPT-4 output records with ICD-10 codes were converted into 6930 (\textgreater 99\%) and 6931 (\textgreater 99) records with CGHR-10 codes, where \textless 1\% (9 and 8) records did not have matching CGHR-10 codes respectively. The 6830 InterVA-5 and InSilicoVA records with ICD-10 codes were converted into 6802 (\textgreater 99\%) and 6726 (98\%) records with CGHR-10 codes respectively, where 28 (\textless 1\%) and 104 (1\%) of records could not be converted into CGHR-10 codes.

\subsection{Performance Evaluation Details}\label{app-methods-eval}

The performance of GPT-3.5, GPT-4, InSilicoVA, and InterVA-5 models were evaluated with metrics at the population and individual level by comparing their CGHR-10 COD outputs for 6939 records to physician COD assignments. Section \ref{app-methods-csmfa} describes CSMF accuracy in detail for evaluating models on the population level,  Section \ref{app-methods-pccc} describes PCCC for evaluating models on the individual level. Records that were assigned a COD by physicians, but not by a model were considered to be an incorrect COD assignment by the model. CSMF accuracy and PCCC were calculated for each model overall and by three age groups (adult, child, and neonatal), then further into age and COD for each age group.

\subsubsection{Cause Specific Mortality Fraction (CSMF) Accuracy}\label{app-methods-csmfa}

CSMF accuracy measures the performance of models at the population level, comparing distributions of CODs between the physicians and the models \citep{murrayRobustMetricsAssessing2011}. To calculate CSMF accuracy, $CSMF_j$ was calculated as is the fraction of physician or model records for cause $j$, given by dividing the number of records for cause $j$ with the total number of records as seen in Equation \ref{eq-csmf}. Then, the $CSMFMaximumError$, representing the worst possible model, is calculated using Equation \ref{eq-csmferr}. Finally, the CSMF accuracy is given by Equation \ref{eq-csmfa}, where $k$ is the number of causes, $j$ is a cause, $CSMF^{true}_j$ is the true physician CSMF for cause $j$, and $CSMF^{pred}_j$ is the prediction model CSMF for cause $j$. CSMF accuracy ranges from 0 to 1, where 1 means that the model completely matched the physician COD distribution and 0 means that it did not match the distribution at all.

\begin{equation}\label{eq-csmf}
    CSMF_j = Records_j / Records
\end{equation}

\begin{equation}\label{eq-csmferr}
    CSMFMaximumError = 2(1 - Min(CSMF^{true}_j)
\end{equation}

\begin{equation}\label{eq-csmfa}
    CSMFAccuracy = 1 - \frac{\sum^{k}_{j=1}|CSMF^{true}_j - CSMF^{pred}_j|}{CSMFMaximumError}
\end{equation}

\subsubsection{Partial Chance Corrected Concordance (PCCC)}\label{app-methods-pccc}

PCCC measures the performance of models at the individual level, comparing COD assignments between the physicians and models on a record by record basis, correcting for COD assignments made purely by chance \citep{murrayRobustMetricsAssessing2011}. PCCC is given by Equation \ref{eq-pccc}, where $k$ is the number of top COD assignments from the model to consider, $N$ is number of causes, and $C$ is fraction of records where the physician COD assignment is one of the top COD assignments from the model. For this study, $k$ was set to 1, making $C$ equivalent to the fraction of true positives $TP$ or records where the physician COD assignment is equal to the model COD assignment as shown in Equation \ref{eq-pccc-c}. Higher PCCC values closer to 1 indicate that model COD assignments are similar to physician COD assignments, while values closer to 0 indicate that model COD assignments are not similar to physicians.

\begin{equation}\label{eq-pccc-c}
    C = \frac{TP}{Records}
\end{equation}

\begin{equation}\label{eq-pccc}
    PCCC(k) = \frac{C - \frac{k}{N}}{1 - \frac{k}{N}}
\end{equation}

\section{Experiment on Repeated Runs of GPT-3.5}\label{app-reprod}

A short experiment was conducted to test the consistency of GPT-3.5 outputs repeated on the same record. 100 records, sampled randomly with approximately equal proportions across age groups, CODs, and survey rounds 1 and 2, were used to test repeated runs of GPT-3.5. Each record from the 100 records was rerun 10 times through GPT-3.5, resulting in ten COD outputs per record. The ICD-10 codes were then converted to CGHR-10 codes and tested for consistency, where completely inconsistent results had different ICD-10 or CGHR-10 codes for each of the 10 reruns (1 times+), and completely consistent results had the same ICD-10 or CGHR-10 code for all 10 reruns (10 times), on the same record.

The results are shown in Table \ref{tab-reprod}. For all 100 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code for the same record 5 times or more out of 10. For 66 and 79 records, GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively for each record. This number increases to 94 (from 66) and 96 (from 79) when reducing the number of times out of 10 that GPT-3.5 assigns the same ICD-10 and CGHR-10 code respectively. Thus, GPT-3.5 does not always produce the same outputs when repeated on the same record (10 times out of 10), even when the temperature is set to 0, but does so for more than half the records. For most records (more than 90\%), GPT-3.5 will produce the same outputs for the same record 7 times or more out of 10.

\begin{table}[!htbp]
    \caption{Records with same GPT-3.5 outputs based on 10 repeated reruns of 100 records}\label{tab-reprod}%
    \begin{tabular}{@{}lll@{}}
    \toprule
    Times with Same GPT-3.5 Outputs & ICD-10 Records & CGHR-10 Records\\

    \midrule
    
    1 times+ (inconsistent) & 100  & 100\\
    2 times+ & 100  & 100\\
    3 times+ & 100  & 100\\
    4 times+ & 100  & 100\\
    5 times+ & 100  & 100\\
    6 times+ & 94  & 96\\
    7 times+ & 92  & 94\\
    8 times+ & 86  & 91\\
    9 times+ & 79  & 86\\
    10 times (consistent) & 66  & 79\\

    \botrule
    \end{tabular}
\end{table}

\section{Exploration of Neonatal Infections}\label{app-misclass}

An exploration of neonatal infections (n=99, 21\% of 477 records) was done to understand the low performance of GPT models (0.23 PCCC) for neonatal infections, and high performance of InSilicoVA (0.87 PCCC). In Table \ref{tab-misclass}, about half the records were assigned correctly, and a majority (n=33, 33\%) of the other records were misclassified as other, while prematurity and low birthweight, birth asphyxia \& birth trauma, and ill-defined make up the rest. On closer inspection of the 49 records with misclassified assignments, the ICD-10 code R50 was assigned in 20 records. R50 falls under unspecified infections in the adult CGHR-10 category, but in the other category for neonates. B50 was assigned in 4 records, falling under malaria, but a similar B54 falls under neonatal infections. P81 was assigned in 3 records, referring to fever of unknown origin, which falls under other, and P07 was assigned in 7 records, falling under prematurity and low birthweight.

In most misclassified records, there is mention of infections, but the misclassifications occur due to the finer details of the ICD-10 code classifications, the categorization decisions of the CGHR-10 codes, and missing information from the questionnaire. For R50 misclassifications, GPT may have confused descriptions across adult and neonatal age groups. Using the same definition of R50, but in the context of neonates, may result in codes closer to neonatal infections (e.g. B54). For B50 misclassifications, the similar B54 was categorized in CGHR-10 as neonatal infections, but B50 was categorized as other. P81 refers to fever of unknown origin, which may be difficult to differentiate between infection and other causes without information from the questionnaire. P07 refers to prematurity and low birthweight, where GPT initially assigned P07 as the age of the neonate was mentioned first, but later mentions infections as an alternative following the order of information in the narratives. Thus, it may be possible to improve the performance GPT models using better prompts based on the context of VA manuals and CGHR-10 codes, and by also including questionnaire information in the prompts.

\begin{table}[!htbp]
    \caption{GPT-4 CGHR-10 COD assignment for physician coded neonatal infections records.}\label{tab-misclass}%
    \begin{tabular}{@{}ll@{}}
    \toprule
    GPT-4 Assigned Cause of Death (CGHR-10) & Records\\

    \midrule
    
    Neonatal infections & 50 (51\%)\\
    Other & 33 (33\%)\\
    Prematurity and low birthweight & 9 (9\%)\\
    Birth asphyxia \& birth trauma & 5 (6\%)\\
    Ill-defined & 2 (2\%) \\

    \midrule

    Total & 99 (100\%)\\

    \botrule
    \end{tabular}
\end{table}

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\clearpage
\bibliography{bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

\end{document}
